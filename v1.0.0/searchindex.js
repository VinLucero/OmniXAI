Search.setIndex({"docnames": ["index", "omnixai", "omnixai.data", "omnixai.explainers", "omnixai.explainers.data", "omnixai.explainers.nlp", "omnixai.explainers.nlp.agnostic", "omnixai.explainers.nlp.counterfactual", "omnixai.explainers.nlp.specific", "omnixai.explainers.tabular", "omnixai.explainers.tabular.agnostic", "omnixai.explainers.tabular.counterfactual", "omnixai.explainers.tabular.specific", "omnixai.explainers.timeseries", "omnixai.explainers.timeseries.agnostic", "omnixai.explainers.timeseries.counterfactual", "omnixai.explainers.vision", "omnixai.explainers.vision.agnostic", "omnixai.explainers.vision.counterfactual", "omnixai.explainers.vision.specific", "omnixai.explanations", "omnixai.explanations.image", "omnixai.explanations.tabular", "omnixai.explanations.text", "omnixai.explanations.timeseries", "omnixai.preprocessing", "omnixai.visualization", "tutorials", "tutorials/data_analysis", "tutorials/misc/data_objects", "tutorials/misc/preprocessing", "tutorials/nlp", "tutorials/nlp/ce_classification", "tutorials/nlp/ce_qa", "tutorials/nlp/ig_tf", "tutorials/nlp/ig_torch", "tutorials/nlp/l2x", "tutorials/nlp/lime", "tutorials/nlp/shap", "tutorials/nlp_imdb", "tutorials/omnixai_in_ml_workflow", "tutorials/tabular/ale", "tutorials/tabular/ce", "tutorials/tabular/l2x", "tutorials/tabular/lime", "tutorials/tabular/linear", "tutorials/tabular/mace", "tutorials/tabular/pdp", "tutorials/tabular/ranking", "tutorials/tabular/sensitivity", "tutorials/tabular/shap", "tutorials/tabular/tree", "tutorials/tabular_classification", "tutorials/tabular_regression", "tutorials/timeseries", "tutorials/timeseries/mace", "tutorials/timeseries/shap", "tutorials/vision", "tutorials/vision/ce_imagenet", "tutorials/vision/ce_tf", "tutorials/vision/ce_torch", "tutorials/vision/cem_tf", "tutorials/vision/cem_torch", "tutorials/vision/feature_map_tf", "tutorials/vision/feature_map_torch", "tutorials/vision/feature_visualization_tf", "tutorials/vision/feature_visualization_torch", "tutorials/vision/gradcam_tf", "tutorials/vision/gradcam_torch", "tutorials/vision/gradcam_vlm", "tutorials/vision/ig_tf", "tutorials/vision/ig_torch", "tutorials/vision/ig_vlm", "tutorials/vision/l2x", "tutorials/vision/lime", "tutorials/vision/shap"], "filenames": ["index.rst", "omnixai.rst", "omnixai.data.rst", "omnixai.explainers.rst", "omnixai.explainers.data.rst", "omnixai.explainers.nlp.rst", "omnixai.explainers.nlp.agnostic.rst", "omnixai.explainers.nlp.counterfactual.rst", "omnixai.explainers.nlp.specific.rst", "omnixai.explainers.tabular.rst", "omnixai.explainers.tabular.agnostic.rst", "omnixai.explainers.tabular.counterfactual.rst", "omnixai.explainers.tabular.specific.rst", "omnixai.explainers.timeseries.rst", "omnixai.explainers.timeseries.agnostic.rst", "omnixai.explainers.timeseries.counterfactual.rst", "omnixai.explainers.vision.rst", "omnixai.explainers.vision.agnostic.rst", "omnixai.explainers.vision.counterfactual.rst", "omnixai.explainers.vision.specific.rst", "omnixai.explanations.rst", "omnixai.explanations.image.rst", "omnixai.explanations.tabular.rst", "omnixai.explanations.text.rst", "omnixai.explanations.timeseries.rst", "omnixai.preprocessing.rst", "omnixai.visualization.rst", "tutorials.rst", "tutorials/data_analysis.ipynb", "tutorials/misc/data_objects.ipynb", "tutorials/misc/preprocessing.ipynb", "tutorials/nlp.ipynb", "tutorials/nlp/ce_classification.ipynb", "tutorials/nlp/ce_qa.ipynb", "tutorials/nlp/ig_tf.ipynb", "tutorials/nlp/ig_torch.ipynb", "tutorials/nlp/l2x.ipynb", "tutorials/nlp/lime.ipynb", "tutorials/nlp/shap.ipynb", "tutorials/nlp_imdb.ipynb", "tutorials/omnixai_in_ml_workflow.ipynb", "tutorials/tabular/ale.ipynb", "tutorials/tabular/ce.ipynb", "tutorials/tabular/l2x.ipynb", "tutorials/tabular/lime.ipynb", "tutorials/tabular/linear.ipynb", "tutorials/tabular/mace.ipynb", "tutorials/tabular/pdp.ipynb", "tutorials/tabular/ranking.ipynb", "tutorials/tabular/sensitivity.ipynb", "tutorials/tabular/shap.ipynb", "tutorials/tabular/tree.ipynb", "tutorials/tabular_classification.ipynb", "tutorials/tabular_regression.ipynb", "tutorials/timeseries.ipynb", "tutorials/timeseries/mace.ipynb", "tutorials/timeseries/shap.ipynb", "tutorials/vision.ipynb", "tutorials/vision/ce_imagenet.ipynb", "tutorials/vision/ce_tf.ipynb", "tutorials/vision/ce_torch.ipynb", "tutorials/vision/cem_tf.ipynb", "tutorials/vision/cem_torch.ipynb", "tutorials/vision/feature_map_tf.ipynb", "tutorials/vision/feature_map_torch.ipynb", "tutorials/vision/feature_visualization_tf.ipynb", "tutorials/vision/feature_visualization_torch.ipynb", "tutorials/vision/gradcam_tf.ipynb", "tutorials/vision/gradcam_torch.ipynb", "tutorials/vision/gradcam_vlm.ipynb", "tutorials/vision/ig_tf.ipynb", "tutorials/vision/ig_torch.ipynb", "tutorials/vision/ig_vlm.ipynb", "tutorials/vision/l2x.ipynb", "tutorials/vision/lime.ipynb", "tutorials/vision/shap.ipynb"], "titles": ["Welcome to OmniXAI\u2019s documentation!", "OmniXAI: An Explanation Toolbox", "omnixai.data package", "omnixai.explainers package", "omnixai.explainers.data package", "omnixai.explainers.nlp package", "omnixai.explainers.nlp.agnostic package", "omnixai.explainers.nlp.counterfactual package", "omnixai.explainers.nlp.specific package", "omnixai.explainers.tabular package", "omnixai.explainers.tabular.agnostic package", "omnixai.explainers.tabular.counterfactual package", "omnixai.explainers.tabular.specific package", "omnixai.explainers.timeseries package", "omnixai.explainers.timeseries.agnostic package", "omnixai.explainers.timeseries.counterfactual package", "omnixai.explainers.vision package", "omnixai.explainers.vision.agnostic package", "omnixai.explainers.vision.counterfactual package", "omnixai.explainers.vision.specific package", "omnixai.explanations package", "omnixai.explanations.image package", "omnixai.explanations.tabular package", "omnixai.explanations.text package", "omnixai.explanations.timeseries package", "omnixai.preprocessing package", "omnixai.visualization package", "Tutorials &amp; Example Code", "DataAnalyzer for feature analysis", "Examples of data objects", "Examples of data preprocessing", "NLPExplainer for sentiment analysis", "Counterfactual explanation for text classification", "Counterfactual explanation for question answering", "Integrated-gradient on IMDB dataset (Tensorflow)", "Integrated-gradient on IMDB dataset (PyTorch)", "L2X (learning to explain) for text classification", "LIME for text classification", "SHAP for sentiment analysis", "NLPExplainer on IMDB dataset", "OmniXAI in a ML workflow", "Accumulated local effects (ALE)", "Counterfactual explanation on Diabetes dataset", "L2X (learning to explain) for income prediction", "LIME for income prediction", "Logistic regression for income prediction", "MACE counterfactual explanation for income prediction", "Paritial dependence plots", "Learning to Rank Expanations Demo", "Morris sensitivity analysis", "SHAP for income prediction", "Decision tree for income prediction", "TabularExplainer for income prediction (classification)", "TabularExplainer for house-price prediction (regression)", "TimeseriesExplainer for time series anomaly detection", "Counterfactual explanation on time series anomaly detection", "SHAP for time series anomaly detection", "VisionExplainer for image classification", "Counterfactual explanation on ImageNet", "Counterfactual explanation on MNIST (Tensorflow)", "Counterfactual explanation on MNIST (PyTorch)", "Contrastive explanation on MNIST (Tensorflow)", "Contrastive explanation on MNIST (PyTorch)", "Feature map visualization (Tensorflow)", "Feature map visualization (PyTorch)", "Feature visualization (Tensorflow)", "Feature visualization (PyTorch)", "Grad-CAM for image classification (Tensorflow)", "Grad-CAM for image classification (PyTorch)", "Grad-CAM for visual language tasks", "Integrated-gradient for image classification (Tensorflow)", "Integrated-gradient for image classification (PyTorch)", "Integrated-gradient for visual language tasks", "L2X (learning to explain) on MNIST", "LIME for image classification", "SHAP on MNIST"], "terms": {"short": [0, 1], "omni": [0, 1], "explain": [0, 1, 2, 21, 22, 23, 24, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75], "ai": [0, 1, 2], "i": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "python": [0, 1, 48, 69, 72, 75], "librari": [0, 2, 6, 28, 29, 30, 32, 33, 38, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 63, 69, 72], "xai": [0, 1], "offer": [0, 1, 36], "wai": [0, 1, 3, 25, 36, 48], "interpret": [0, 1, 6, 10, 17, 36, 43, 73], "machin": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 73, 74], "learn": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 27, 31, 37, 39, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 74], "address": [0, 1], "mani": [0, 1, 36], "pain": [0, 1], "point": [0, 1, 36, 54, 55, 56], "decis": [0, 1, 11, 12, 18, 22, 27, 42, 58, 59, 60], "made": [0, 1, 36], "model": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "practic": [0, 1, 3, 52, 53, 54, 57], "aim": [0, 1], "one": [0, 1, 2, 3, 6, 14, 15, 20, 21, 22, 23, 24, 25, 29, 30, 31, 36, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "stop": [0, 1], "comprehens": [0, 1], "make": [0, 1, 25, 36, 40, 54], "easi": [0, 1, 31, 39, 52, 53, 54, 57], "data": [0, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75], "scientist": [0, 1], "ml": [0, 1, 3, 4, 12, 27, 28, 31, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 75], "research": [0, 1, 69, 72], "practition": [0, 1], "who": [0, 1, 36], "need": [0, 1, 2, 3, 29, 31, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "explan": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "variou": [0, 1], "type": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 31, 34, 35, 36, 39, 41, 42, 43, 44, 47, 48, 50, 52, 53, 54, 56, 57, 65, 66, 67, 68, 70, 71, 73], "method": [0, 7, 17, 19, 21, 22, 25, 29, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 58, 59, 60, 61, 62, 65, 66, 70, 71, 73, 75], "differ": [0, 4, 5, 9, 11, 13, 16, 28, 36, 40, 41, 43, 44, 46, 47, 50, 52, 53, 65, 66, 73], "stage": [0, 1, 40], "process": [0, 1, 3, 8, 12, 18, 19, 25, 31, 34, 35, 39, 48, 52, 53, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 75], "includ": [0, 1, 2, 18, 19, 25, 57], "rich": [0, 1], "famili": [0, 1, 40, 44, 46, 50, 52], "integr": [0, 1, 8, 12, 19, 21, 27, 31, 39, 57], "unifi": [0, 1, 3, 31, 39, 52, 53, 54, 57], "interfac": [0, 1, 3, 31, 36, 39, 43, 52, 53, 54, 57, 73], "which": [0, 1, 2, 3, 5, 8, 9, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 72, 73, 75], "support": [0, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 16, 17, 19, 29, 30, 31, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 74, 75], "multipl": [0, 1, 2, 3, 4, 5, 9, 13, 16, 25, 28, 36, 40, 43, 65, 66, 73], "tabular": [0, 1, 3, 4, 20, 28, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "imag": [0, 1, 3, 11, 12, 16, 17, 18, 19, 20, 27, 36, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 72, 73, 75], "text": [0, 1, 3, 5, 6, 7, 8, 20, 22, 27, 31, 33, 34, 35, 38, 39, 48, 69, 72], "time": [0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 24, 27, 28, 36, 40], "seri": [0, 1, 2, 3, 13, 14, 15, 24, 27], "tradit": [0, 1], "scikit": [0, 1, 3, 5, 9, 10, 12, 13, 16, 31, 39, 47, 52, 53, 57], "deep": [0, 1, 19, 63, 67, 68], "pytorch": [0, 1, 3, 6, 10, 17, 27, 31, 36, 39, 43, 52, 53, 57, 69, 72, 73, 75], "tensorflow": [0, 1, 3, 5, 9, 13, 16, 27, 31, 39, 42, 48, 52, 53, 57, 66, 75], "rang": [0, 1, 18, 19, 25, 34, 35, 39, 57, 58, 60, 62, 63, 65, 66, 67, 68, 70, 71, 73, 74], "divers": [0, 1, 46], "specif": [0, 1, 3, 5, 9, 13, 16, 20, 21, 22, 23, 24, 31, 34, 35, 39, 40, 51, 52, 53, 54, 57, 63, 64, 65, 66, 67, 68, 69, 72], "agnost": [0, 1, 3, 5, 9, 11, 13, 15, 16, 35, 36, 39, 43, 44, 46, 48, 50, 73, 75], "attribut": [0, 1, 69, 72], "counterfactu": [0, 1, 5, 9, 13, 16, 20, 27, 31, 39, 40, 54, 57], "gradient": [0, 1, 8, 11, 12, 15, 18, 19, 21, 27, 31, 36, 39, 57, 67, 68, 69, 73], "base": [0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 31, 32, 33, 36, 38, 48, 49, 51, 53, 55, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 72, 73], "etc": [0, 1], "For": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 17, 19, 20, 22, 23, 25, 28, 29, 30, 34, 35, 36, 37, 40, 43, 45, 47, 51, 52, 53, 57, 65, 66, 69, 72, 73, 74], "provid": [0, 1, 2, 3, 20, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 39, 45, 51, 52, 53, 54, 57, 63, 64], "an": [0, 2, 3, 4, 6, 10, 11, 14, 15, 17, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "us": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "gener": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 31, 36, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 73, 75], "applic": [0, 1, 48, 63, 65, 67, 70], "onli": [0, 1, 2, 3, 6, 10, 11, 12, 17, 18, 19, 25, 28, 29, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "write": [0, 1, 36, 37], "few": [0, 1], "line": [0, 1, 36, 37, 54], "code": [0, 1, 57, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "also": [0, 1, 2, 29, 36, 48, 57, 64, 65, 66], "gui": [0, 1], "dashboard": [0, 3, 28, 31, 39, 40, 52, 53, 54, 57], "visual": [0, 3, 19, 20, 27, 28, 31, 39, 40, 42, 48, 52, 53, 54, 57, 67, 68], "obtain": [0, 1, 36], "more": [0, 3, 10, 11, 14, 15, 25, 28, 36, 37, 40, 43, 47, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 73], "insight": [0, 1], "about": [0, 1, 3, 36], "compar": [0, 12, 17, 19], "other": [0, 1, 28, 30, 36, 40, 41, 42, 43, 44, 46, 47, 50, 52, 53, 63, 64, 65, 66, 73], "exist": [0, 1, 25, 36, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "ibm": 0, "aix360": 0, "microsoft": 0, "interpretml": 0, "alibi": 0, "explainx": 0, "our": [0, 36, 46, 48, 55], "ha": [0, 1, 2, 3, 7, 21, 22, 23, 24, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 69, 72, 75], "list": [0, 1, 2, 3, 4, 5, 9, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 29, 48, 49, 53, 54, 55, 56, 65, 66], "uniqu": 0, "follow": [0, 1, 2, 3, 21, 22, 23, 24, 25, 29, 31, 34, 35, 36, 37, 39, 41, 43, 44, 46, 47, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75], "analysi": [0, 1, 4, 10, 22, 27, 32, 40, 53, 57], "explor": [0, 1, 28, 48], "analyz": [0, 1, 4, 28, 36, 40, 48, 49, 63, 64, 65, 66], "correl": [0, 1, 3, 20, 28, 40, 48], "check": [0, 4, 40, 48, 67, 70, 74], "imbal": [0, 1, 3, 20, 25, 28, 40], "issu": [0, 36, 40], "most": [0, 1, 11, 40, 54, 64], "popular": 0, "aspect": 0, "inform": [0, 1, 3, 4, 6, 10, 11, 17, 22, 24, 28, 36, 40, 42, 43, 47, 65, 66, 73], "chang": [0, 17, 46, 73], "current": [0, 25, 31, 39, 57, 64], "predict": [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 47, 48, 49, 55, 56, 57, 60, 62, 67, 70, 73, 74], "grad": [0, 1, 3, 16, 19, 21, 27, 34, 40, 44, 46, 50, 52, 57], "cam": [0, 1, 3, 16, 19, 21, 27, 57], "its": [0, 1, 3, 9, 10, 11, 12, 17, 29, 31, 34, 35, 39, 41, 43, 44, 46, 47, 48, 50, 52, 53, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 75], "variant": 0, "timeseri": [0, 1, 3, 20, 29, 54, 55, 56], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 37, 38, 39, 40, 43, 48, 54, 55, 56, 57, 58, 68, 69, 72, 73], "much": [0, 33, 36], "simpler": [0, 36], "user": [0, 1, 3, 4, 5, 9, 13, 16, 31, 33, 39, 48, 52, 53, 54, 57], "examin": [0, 40], "extend": [0, 36], "ad": 0, "new": [0, 1, 2, 17, 25, 36, 69, 72], "algorithm": [0, 48], "easili": [0, 29, 33], "implement": [0, 1, 7, 11, 19, 26, 32, 33, 36, 43, 73], "singl": [0, 2, 3, 25, 29, 30], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 57, 58, 60, 62, 67, 68, 69, 70, 71, 72, 73, 74], "deriv": [0, 3, 4, 5, 9, 13, 16, 25, 28], "from": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 16, 17, 19, 21, 22, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "show": [0, 1, 3, 20, 21, 22, 23, 26, 28, 29, 31, 32, 34, 35, 38, 39, 40, 47, 49, 52, 53, 54, 57], "we": [0, 1, 2, 3, 28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "continu": [0, 1, 2, 4, 9, 10, 11, 12, 25, 29, 30, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53], "improv": [0, 19], "thi": [0, 1, 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "futur": 0, "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "vision": [0, 1, 3, 21, 29, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "nlp": [0, 1, 3, 23, 31, 32, 33, 34, 35, 36, 37, 38, 39], "task": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "eda": 0, "na": [0, 36], "global": [0, 1, 3, 4, 10, 12, 22, 26, 28, 31, 39, 40, 45, 47, 49, 51, 52, 53, 57], "select": [0, 1, 2, 6, 10, 17, 28, 40, 52, 53, 57], "partial": [0, 1, 10, 17, 22, 42, 47, 52, 53], "depend": [0, 1, 10, 17, 22, 27, 36, 43, 52, 53, 73], "black": [0, 1, 3, 5, 9, 11, 13, 16, 18, 31, 40, 42, 44, 46, 50, 52, 53, 54, 57, 58, 59, 60], "box": [0, 1, 3, 5, 9, 11, 13, 16, 18, 31, 42, 46, 52, 53, 54, 57, 58, 59, 60], "sensit": [0, 1, 9, 20, 27, 53], "lime": [0, 1, 3, 5, 9, 16, 21, 27, 31, 39, 40, 43, 52, 53, 57], "local": [0, 1, 3, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 22, 26, 27, 31, 39, 40, 43, 44, 45, 46, 50, 51, 52, 53, 54, 56, 57, 67, 68], "shap": [0, 1, 3, 5, 9, 12, 13, 16, 21, 27, 31, 40, 43, 52, 53, 54], "torch": [0, 3, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 34, 35, 39, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "tf": [0, 1, 8, 11, 12, 17, 18, 19, 25, 30, 34, 35, 36, 37, 42, 48, 58, 59, 60, 61, 62, 63, 67, 68, 70, 71, 75], "contrast": [0, 1, 19, 20, 27], "linear": [0, 1, 6, 9, 10, 20, 35, 39, 45, 51, 60, 62, 73], "tree": [0, 1, 12, 20, 27], "accept": 0, "transform": [0, 1, 3, 5, 6, 9, 13, 16, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 54, 57, 58, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], "between": [0, 4, 33, 36, 40], "toolkit": 0, "literatur": 0, "eli5": 0, "captum": 0, "l2x": [0, 5, 9, 16, 27, 35, 39], "you": [0, 1, 29, 32, 34, 35, 36, 38, 48, 63, 64, 65, 66], "can": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 25, 28, 29, 30, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "pypi": [0, 1], "call": [0, 1, 2, 28, 30, 31, 34, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 73, 75], "pip": [0, 1, 48], "mai": [0, 1, 2, 25, 29, 36, 40, 41, 43, 44, 45, 46, 47, 50, 52, 63, 64, 65, 66, 73], "sourc": [0, 1], "clone": [0, 1], "repo": [0, 1], "navig": [0, 1], "root": [0, 1, 29, 60, 62, 73], "directori": [0, 1, 25], "edit": [0, 1], "mode": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 31, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 50, 52, 53, 54, 55, 56, 57, 67, 68, 70, 71, 73], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 28, 52, 53, 54], "plot": [0, 1, 10, 17, 20, 21, 22, 23, 24, 26, 27, 40, 43, 44, 46, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 73, 75], "To": [0, 1, 3, 28, 29, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75], "recommend": [0, 1, 3, 41, 43, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "link": [0, 1], "tutori": [0, 1, 3, 40], "exampl": [0, 2, 3, 4, 7, 11, 15, 21, 22, 24, 25, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "In": [0, 1, 3, 28, 29, 31, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 75], "tabularexplain": [0, 1, 3, 4, 9, 10, 11, 12, 27, 31, 39, 40, 57], "visionexplain": [0, 1, 3, 16, 27], "nlpexplain": [0, 1, 3, 5, 27], "timeseriesexplain": [0, 1, 3, 13, 27], "respect": [0, 1, 2, 3, 4, 29, 54], "specifi": [0, 1, 2, 3, 25, 26, 28, 29, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 63, 64, 65, 66, 73], "function": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75], "pre": [0, 1, 3, 8, 12, 19, 25, 34, 35], "convert": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 25, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75], "raw": [0, 1, 2, 3, 5, 8, 9, 12, 13, 16, 17, 18, 19, 21, 22, 28, 29, 31, 34, 35, 39, 52, 53, 54, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 75], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 31, 33, 34, 35, 39, 41, 42, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "post": [0, 1, 3, 36, 37], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24, 33, 52, 53, 54, 57], "output": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "probabl": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 16, 17, 20, 31, 32, 36, 37, 39, 41, 43, 44, 46, 47, 50, 52, 53, 57, 73, 74], "appli": [0, 1, 2, 3, 9, 10, 11, 12, 25, 28, 30, 31, 34, 35, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 57, 67, 70, 74], "mace": [0, 1, 3, 9, 13, 27, 40, 43, 52, 53, 54], "let": [0, 1, 30, 33, 36, 40, 48, 63, 64, 67, 70, 74], "take": [0, 1, 29, 31, 36, 39, 41, 43, 44, 46, 47, 50, 52, 53, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 75], "incom": [0, 1, 27, 28, 40, 41, 47], "dataset": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 17, 25, 27, 28, 29, 30, 36, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 73, 75], "http": [0, 1, 6, 7, 8, 10, 11, 12, 14, 17, 18, 19, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "archiv": [0, 1, 28, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "ic": [0, 1, 28, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "uci": [0, 1, 28, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "edu": [0, 1, 28, 37, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "adult": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "repres": [0, 1, 2, 14, 15, 29, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "creat": [0, 1, 2, 3, 28, 29, 33, 36, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 63, 64], "instanc": [0, 1, 2, 3, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 75], "given": [0, 1, 2, 3, 4, 9, 12, 25, 28, 29, 30, 31, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57], "panda": [0, 1, 2, 22, 24, 25, 28, 29, 30, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "datafram": [0, 1, 2, 10, 11, 12, 22, 24, 25, 28, 29, 30, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "categor": [0, 1, 2, 4, 9, 10, 11, 12, 25, 28, 29, 30, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "name": [0, 1, 2, 3, 4, 5, 9, 13, 16, 20, 21, 22, 23, 25, 26, 28, 31, 34, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 62, 67, 68, 70, 71, 73, 74], "target": [0, 1, 2, 4, 9, 11, 12, 19, 25, 28, 29, 30, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73], "label": [0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 17, 19, 21, 22, 23, 25, 26, 28, 29, 30, 32, 34, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 67, 68, 70, 71, 73, 74], "column": [0, 1, 2, 3, 22, 25, 28, 29, 30, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "import": [0, 1, 2, 4, 6, 8, 10, 12, 14, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "load": [0, 1, 3, 25, 28, 31, 33, 34, 35, 36, 37, 39, 40, 42, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75], "feature_nam": [0, 1, 3, 22, 28, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "ag": [0, 1, 3, 4, 26, 28, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52], "workclass": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "fnlwgt": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "educ": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "num": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "marit": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "statu": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "occup": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "relationship": [0, 1, 3, 9, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "race": [0, 1, 3, 9, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "sex": [0, 1, 3, 9, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "capit": [0, 1, 3, 9, 26, 28, 36, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "gain": [0, 1, 3, 4, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "loss": [0, 1, 3, 6, 9, 10, 11, 15, 17, 18, 19, 26, 28, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 59, 60, 61, 62, 69, 72, 73, 75], "hour": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "per": [0, 1, 3, 11, 26, 27, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "week": [0, 1, 3, 26, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "countri": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "df": [0, 1, 2, 29, 30, 40, 49, 52, 53, 54, 55, 56], "pd": [0, 1, 2, 10, 11, 12, 25, 29, 30, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "np": [0, 1, 2, 3, 9, 10, 11, 12, 15, 19, 25, 28, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 63, 67, 69, 70, 72, 75], "genfromtxt": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "delimit": [0, 1, 3, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "dtype": [0, 1, 3, 28, 34, 35, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52], "str": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 28, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 57, 58, 67, 68, 70, 71, 74], "tabular_data": [0, 1, 3, 25, 28, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "categorical_column": [0, 1, 2, 3, 25, 28, 29, 30, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "1": [0, 1, 2, 3, 11, 15, 16, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "3": [0, 1, 2, 3, 9, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "5": [0, 1, 3, 6, 7, 10, 11, 15, 17, 18, 19, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "6": [0, 1, 3, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70, 72, 73, 75], "7": [0, 1, 3, 28, 29, 30, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 67, 69, 70, 72, 73, 74, 75], "8": [0, 1, 3, 9, 10, 12, 28, 29, 30, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 59, 60, 61, 62, 67, 73, 75], "9": [0, 1, 3, 22, 28, 29, 30, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 59, 60, 61, 62, 69, 72, 73, 74, 75], "13": [0, 1, 3, 28, 29, 30, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 64], "target_column": [0, 1, 2, 3, 28, 29, 30, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "packag": [0, 1, 30, 31, 34, 35, 36, 37, 39, 48, 49, 52, 53, 54, 57, 69, 72, 75], "preprocess": [0, 3, 5, 9, 12, 13, 16, 17, 18, 19, 27, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 75], "sever": [0, 1, 29, 30, 36, 40, 45, 51, 52, 53], "tabulartransform": [0, 1, 3, 25, 30, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53], "special": [0, 1, 15, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53], "design": [0, 15, 17, 31, 39, 41, 43, 44, 46, 47, 50, 52, 53, 54, 57], "By": [0, 1, 41, 43, 44, 46, 47, 50, 52, 53, 57], "default": [0, 1, 2, 6, 10, 11, 17, 28, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "hot": [0, 1, 25, 30, 41, 43, 44, 46, 47, 50, 52, 53], "encod": [0, 1, 9, 12, 19, 30, 41, 43, 44, 46, 47, 48, 50, 52, 53, 69], "keep": [0, 1, 25, 41, 43, 44, 46, 47, 50, 52, 53], "valu": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 25, 29, 30, 31, 32, 34, 35, 36, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 59, 61, 69, 72, 73, 75], "numpi": [0, 1, 2, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75], "arrai": [0, 1, 2, 25, 28, 29, 30, 31, 32, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "If": [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 30, 34, 35, 36, 37, 38, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 56, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "last": [0, 1, 2, 3, 25, 28, 29, 30, 41, 43, 44, 46, 47, 50, 52, 53, 57], "after": [0, 1, 36, 40, 41, 43, 44, 46, 47, 48, 50, 52, 53, 73, 75], "train": [0, 1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 16, 17, 22, 25, 29, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 73, 75], "xgboost": [0, 1, 3, 12, 40, 41, 43, 44, 46, 47, 50, 52], "classifi": [0, 1, 11, 12, 36, 37, 40, 41, 43, 44, 46, 47, 50, 52], "fit": [0, 1, 3, 9, 12, 25, 30, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 59, 61, 75], "class_nam": [0, 1, 9, 20, 21, 22, 23, 25, 26, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 57, 58, 60, 62, 67, 68, 70, 71, 73, 74], "x": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 59, 60, 61, 62, 69, 72, 73, 75], "xgbclassifi": [0, 1, 3, 40, 41, 43, 44, 46, 47, 50, 52], "n_estim": [0, 1, 3, 36, 37, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53], "300": [0, 1, 3, 40, 41, 43, 44, 46, 47, 50, 52, 65, 66], "max_depth": [0, 1, 3, 40, 41, 43, 44, 46, 47, 50, 51, 52], "initi": [0, 1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "set": [0, 1, 2, 10, 11, 15, 23, 28, 29, 31, 34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "paramet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75], "pdp": [0, 1, 3, 9, 16, 20, 26, 40, 47, 52, 53], "too": [0, 1, 36, 41, 44, 46, 47, 49, 50, 52, 53, 69, 72], "larg": [0, 1, 9, 10, 11, 12, 40, 41, 42, 44, 46, 47, 49, 50, 52, 53], "subset": [0, 1, 2, 9, 10, 11, 12, 25, 29, 36, 37, 41, 42, 44, 46, 47, 49, 50, 52, 53], "sampler": [0, 1, 9, 10, 11, 12, 41, 42, 44, 46, 47, 49, 50, 52, 53], "subsampl": [0, 1, 9, 10, 11, 12, 25, 41, 42, 44, 46, 47, 49, 50, 52, 53], "postprocess": [0, 1, 3, 5, 9, 13, 16, 17, 31, 39, 52, 53, 54, 57], "form": [0, 1, 3, 5, 9, 13, 16, 31, 39, 52, 53, 54, 57], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 31, 39, 40, 52, 53, 54, 55, 56, 57, 65, 66, 67, 70], "classif": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 22, 23, 25, 27, 29, 31, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 53, 58, 59, 60, 61, 62, 73, 75], "regress": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 16, 17, 19, 20, 21, 22, 23, 25, 27, 31, 34, 35, 36, 39, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 57, 67, 68, 70, 71, 73], "consum": [0, 1, 31, 39, 52, 53, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 75], "simpli": [0, 1, 31, 39, 41, 43, 44, 46, 47, 50, 52, 53, 57, 58, 59, 60, 61, 62, 75], "lambda": [0, 1, 3, 31, 36, 37, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 52, 53, 57, 58, 59, 60, 61, 62, 64, 68, 69, 71, 72, 73, 75], "z": [0, 1, 3, 25, 30, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53, 69, 72], "param": [0, 1, 3, 4, 5, 9, 13, 16, 26, 28, 39, 40, 52, 53, 54, 57], "ignored_featur": [0, 1, 3, 9, 11, 40, 46, 48, 52], "while": [0, 1, 40, 52, 53], "return": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 32, 33, 34, 35, 39, 42, 48, 51, 52, 53, 54, 55, 56, 60, 62, 63, 67, 69, 70, 72, 73, 74], "three": [0, 1, 6, 10, 25, 29, 40, 52, 57], "test": [0, 1, 9, 12, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 75], "explain_glob": [0, 1, 3, 9, 28, 40, 52, 53], "hide": [0, 1, 52, 53], "all": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 31, 36, 39, 40, 42, 48, 52, 53, 54, 57], "detail": [0, 1, 3, 36, 43, 52, 53, 58, 59, 60, 61, 62, 73], "behind": [0, 1, 52, 53], "so": [0, 1, 36, 40, 42, 52, 53], "two": [0, 1, 2, 3, 28, 29, 30, 34, 35, 36, 39, 40, 42, 52, 53, 59, 60, 61, 62, 73, 75], "test_inst": [0, 1, 40, 44, 46, 50, 52, 53, 54], "local_explan": [0, 1, 3, 5, 9, 13, 16, 26, 31, 39, 40, 52, 53, 54, 57], "global_explan": [0, 1, 3, 9, 26, 28, 40, 52, 53], "launch": [0, 1, 28, 31, 39, 40, 52, 53, 54, 57], "dash": [0, 1, 20, 21, 22, 23, 24, 26, 28, 31, 39, 40, 52, 53, 54, 57], "app": [0, 1, 28, 31, 39, 40, 52, 53, 54, 57], "open": [0, 1, 2, 11, 18, 25, 29, 30, 36, 42, 48, 57, 58, 59, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74], "browser": [0, 1], "see": [0, 1, 36, 40, 48, 73], "thank": [0, 1, 36], "your": [0, 1, 36, 69, 72, 75], "interest": [0, 1, 36], "befor": [0, 1, 36], "run": [0, 1, 28, 31, 36, 39, 40, 52, 53, 54, 57], "commit": [0, 1], "ensur": [0, 1], "file": [0, 1, 25, 48], "ar": [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 17, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 61, 64, 73, 74, 75], "format": [0, 1, 2, 3, 7, 21, 22, 23, 24, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 57, 60, 62, 73], "correctli": [0, 1], "contain": [0, 1, 2, 3, 4, 5, 9, 11, 13, 16, 20, 22, 26, 29, 30, 36, 45, 54, 55, 56, 59, 60, 61, 62, 73, 75], "appropri": [0, 1, 63], "licens": [0, 1], "header": [0, 1], "whenev": [0, 1], "add": [0, 1, 21, 22, 23, 24, 25, 36, 42, 59, 61, 75], "step": [0, 1, 8, 12, 15, 19, 25, 34, 40, 42, 57, 58, 59, 60, 61, 62, 65, 66, 73, 75], "below": [0, 1, 36], "choos": [0, 1, 3, 4, 5, 9, 13, 16, 28, 40, 63, 64, 65, 66], "script": [0, 1, 48], "folder": [0, 1], "put": [0, 1], "under": [0, 1, 25], "inherit": [0, 1, 3, 25], "explainerbas": [0, 1, 3, 4, 6, 7, 8, 9, 11, 14, 15, 17, 18, 19], "constructor": [0, 1, 3], "__init__": [0, 1, 3, 34, 35, 39, 60, 62, 69, 72, 73], "self": [0, 1, 2, 3, 25, 34, 35, 39, 40, 44, 46, 50, 52, 60, 62, 69, 73], "predict_funct": [0, 1, 3, 6, 7, 9, 10, 11, 14, 15, 17, 32, 33, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 50, 55, 56, 73, 74], "kwarg": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 39], "preprocess_funct": [0, 1, 3, 5, 8, 9, 12, 13, 16, 17, 18, 19, 34, 35, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 75], "postprocess_funct": [0, 1, 3, 5, 16], "requir": [0, 1, 3, 5, 16, 54], "some": [0, 1, 3, 25, 29, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53], "whether": [0, 1, 2, 3, 15, 22, 36, 40, 54, 55, 56], "differenti": [0, 1, 3], "resiz": [0, 1, 3, 25, 30, 57, 58, 63, 64, 67, 68, 69, 70, 71, 72, 74], "224": [0, 1, 3, 29, 30, 57, 58, 63, 64, 65, 66, 67, 68, 70, 71, 74], "normal": [0, 1, 3, 9, 12, 30, 36, 41, 43, 44, 46, 47, 50, 52, 53, 57, 58, 59, 61, 64, 68, 71, 74, 75], "pixel": [0, 1, 3, 17, 19, 21, 25, 30, 59, 61, 75], "logit": [0, 1, 3, 12, 34, 39, 43, 46, 57, 73, 74], "explanation_typ": [0, 1, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19], "string": [0, 1, 2, 3, 29, 31], "both": [0, 1, 2, 3, 12, 22, 24, 29, 45, 51], "alia": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "where": [0, 1, 20, 22, 23, 24, 36, 46, 65, 66], "py": [0, 1, 48, 69, 72, 75], "regist": [0, 1, 3], "automat": [0, 1, 2, 3, 10, 11, 12], "via": [0, 1, 2, 4, 6, 10, 17, 19, 57, 58, 60, 62, 67, 68, 70, 71], "defin": [0, 1, 29, 30, 42, 48, 57, 58, 60, 62, 68, 69, 71, 72, 73], "toolbox": 0, "modul": [0, 29, 34, 35, 39, 47, 53, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 75], "fill": [0, 1, 30], "pipelin": [0, 1, 6, 31, 32, 33, 38, 48], "result": [0, 3, 18, 19, 21, 22, 23, 24, 26, 31, 33, 39, 40, 48, 52, 53, 54, 57], "categori": [0, 1, 25, 36, 37], "basic": [0, 11, 15, 42], "object": [0, 2, 3, 9, 11, 12, 15, 19, 20, 25, 26, 27, 30, 31, 34, 35, 36, 37, 39, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 73, 75], "dataanalyz": [0, 4, 27, 40], "hous": [0, 27], "price": [0, 27], "sentiment": [0, 1, 27, 32, 34, 35, 39], "imdb": [0, 1, 27], "anomali": [0, 1, 14, 15, 27], "detect": [0, 1, 14, 15, 27], "workflow": [0, 27], "accumul": [0, 27], "effect": [0, 27], "al": [0, 7, 11, 15, 19, 27, 32, 33, 46, 67, 68], "diabet": [0, 27], "logist": [0, 12, 27], "pariti": [0, 27, 48], "rank": [0, 27], "expan": [0, 27], "demo": [0, 27], "kei": [0, 1, 22, 27], "takeawai": [0, 27], "queri": [0, 22, 24, 27], "valid": [0, 27, 45, 51], "morri": [0, 10, 22, 27], "imagenet": [0, 1, 27, 57, 67, 68, 70, 71, 74], "mnist": [0, 17, 27, 29], "map": [0, 8, 10, 27, 34, 35], "languag": [0, 27, 36], "question": [0, 7, 27, 36], "answer": [0, 7, 27, 36], "index": [0, 2, 12, 20, 21, 22, 23, 24, 26, 29, 33, 37, 40, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75], "search": [0, 17], "page": 0, "capabl": 1, "featur": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 75], "five": [1, 6], "subpackag": [1, 3], "simpl": [1, 10, 34, 35, 39, 48, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 73, 75], "pillow": [1, 2, 29, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "One": [1, 25, 30, 31, 36, 39, 43, 45, 57, 73], "ordin": [1, 9, 12, 25, 30], "kbin": [1, 25], "standard": [1, 9, 12, 22, 25, 30, 40, 41, 43, 44, 46, 47, 48, 50, 52, 53], "min": [1, 11, 25, 30, 34, 35, 39], "max": [1, 11, 25, 30, 34, 35, 39, 60, 62, 73], "rescal": [1, 18, 19, 25], "nan": [1, 25, 30], "recal": 1, "idf": [1, 25, 30, 36, 37], "token": [1, 2, 6, 8, 23, 29, 30, 33, 34, 35, 39, 69, 72], "id": [1, 6, 8, 20, 25, 30, 34, 35, 39], "combin": [1, 65, 66], "togeth": [1, 25, 36], "conveni": [1, 25], "particular": [1, 17, 36, 57], "main": [1, 25], "four": [1, 28], "group": [1, 36, 48], "It": [1, 2, 3, 4, 5, 6, 10, 11, 12, 16, 18, 19, 21, 22, 23, 24, 25, 42, 57, 75], "further": [1, 40], "handl": [1, 12], "without": [1, 2, 11, 18, 36, 42, 58, 59, 60], "know": [1, 36], "either": [1, 2, 11, 12, 31, 39, 46], "feature_import": [1, 20], "store": [1, 2, 3, 21, 22, 23, 24, 25, 29, 57], "matplotlib": [1, 20, 21, 22, 23, 24, 59, 60, 61, 62, 75], "plotly_plot": [1, 20, 21, 22, 23, 24], "ipython_plot": [1, 20, 21, 22, 23, 24, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "ipython": [1, 20, 21, 22, 23, 24, 28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "word": [1, 6, 8, 23, 25, 31, 34, 35, 36, 39], "plotli": [1, 20, 21, 22, 23, 24, 26, 28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "figur": [1, 20, 21, 22, 23, 24, 26], "demonstr": [1, 63, 64, 65, 66], "architectur": 1, "autoexplainerbas": [1, 3, 4, 5, 9, 13, 16, 28], "act": [1, 3, 31, 39, 52, 53, 54, 57], "factori": [1, 3, 31, 39, 52, 53, 54, 57], "": [1, 2, 6, 10, 17, 30, 31, 36, 40, 43, 48, 54, 55, 56, 63, 64, 67, 70, 73, 74], "next": [1, 36, 40], "resnet": [1, 3, 57, 58, 63, 65, 66, 68, 71], "arxiv": [1, 6, 10, 11, 17, 18, 19, 36, 42, 43, 48, 58, 59, 60, 61, 62, 67, 68, 73], "org": [1, 6, 10, 11, 17, 18, 19, 36, 42, 43, 47, 48, 53, 58, 59, 60, 61, 62, 67, 68, 69, 72, 73], "ab": [1, 6, 10, 11, 17, 18, 19, 36, 42, 43, 48, 58, 59, 60, 61, 62, 67, 68, 73], "1512": 1, "03385": 1, "pretrain": [1, 3, 33, 57, 58, 64, 66, 68, 69, 71, 72, 74], "www": [1, 69, 72], "net": [1, 36], "here": [1, 7, 10, 29, 31, 36, 42, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 68, 71, 74], "sampl": [1, 6, 9, 10, 12, 15, 17, 19, 25, 34, 35, 39, 48], "ig": [1, 3, 5, 9, 16, 34, 35, 39, 57, 72], "gradcam": [1, 3, 16, 57, 67, 68, 69], "0": [1, 2, 3, 6, 9, 10, 11, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75], "2": [1, 22, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "resnet50": [1, 3, 57, 58, 64, 68], "layer": [1, 6, 8, 10, 19, 34, 35, 39, 42, 48, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75], "target_lay": [1, 3, 16, 19, 57, 63, 64, 65, 66, 67, 68, 69, 72], "layer4": [1, 3, 16, 57, 68], "test_img": [1, 59, 61, 73, 75], "y": [1, 6, 8, 10, 11, 12, 17, 19, 25, 30, 33, 35, 39, 42, 60, 62, 67, 70, 73], "281": [1, 67, 70], "correspond": [1, 2, 6, 7, 9, 10, 11, 14, 15, 17, 19, 21, 22, 23, 24, 26, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 50, 55, 56, 57, 58, 73, 74], "tiger_cat": [1, 67, 70], "top": [1, 6, 8, 10, 12, 17, 19, 67, 68, 70, 71, 74], "bull_mastiff": [1, 67, 70], "These": [1, 29, 45, 48, 51], "highlight": 1, "region": 1, "note": [1, 18, 19, 25, 34, 35, 36, 39, 40], "besid": [1, 29], "same": [1, 3, 4, 5, 9, 13, 16, 28, 34, 36, 40, 43, 73], "gradcam0": 1, "gradcam3": 1, "first": [1, 2, 8, 21, 22, 23, 24, 28, 29, 34, 35, 36, 39, 40, 43, 44, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65, 66, 73, 75], "second": [1, 2, 29, 46, 65, 66], "consid": [1, 4, 31, 40, 42, 48, 57, 58, 65, 66, 68, 71], "goal": [1, 48], "review": [1, 34, 35, 39], "posit": [1, 19, 21, 25, 31, 32, 34, 35, 36, 38, 39, 40, 42, 61, 62], "neg": [1, 4, 12, 19, 21, 31, 32, 34, 35, 38, 39, 40, 42, 61, 62], "cnn": [1, 34, 35, 36, 39, 60, 62, 63, 64, 65, 66, 73], "suppos": [1, 29, 30, 36], "want": [1, 28, 29, 36, 41, 43, 44, 46, 47, 50, 52, 53], "do": [1, 28, 30, 31, 33, 36, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 57], "polyjuic": [1, 5, 31, 32, 33, 39], "embed": [1, 8, 10, 34, 35, 39, 48, 72], "embedding_lay": [1, 8, 34, 35, 39, 72], "id2token": [1, 8, 34, 35, 39], "id_to_token": 1, "wa": [1, 29, 31, 32, 34, 35, 36, 38, 39], "fantast": [1, 29, 32, 34, 35, 38, 39], "perform": [1, 29, 32, 34, 35, 38, 39, 60, 62, 63, 73], "clearli": [1, 40], "largest": 1, "score": [1, 8, 12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 31, 32, 40, 45, 48, 54, 55, 56, 59, 61, 75], "impli": [1, 14, 15, 40, 55, 56], "sentenc": [1, 2, 25, 29, 30, 34, 35, 36, 37, 39, 69, 72], "becaus": [1, 2, 25, 28, 31, 36, 39, 40], "horribl": [1, 29, 32, 34, 35, 38, 39], "help": 1, "u": [1, 36, 52, 53], "understand": [1, 36], "behavior": [1, 40, 64, 73], "univari": [1, 2, 54, 55, 56], "statist": 1, "detector": [1, 54, 55, 56], "window": [1, 54, 55, 56], "accord": [1, 30, 36], "threshold": [1, 15, 54, 55, 56], "estim": [1, 3, 4, 6, 9, 10, 11, 12, 17, 19, 25, 36, 41, 43, 44, 46, 47, 50, 73], "have": [1, 2, 18, 19, 25, 29, 30, 32, 34, 35, 36, 38, 40, 51], "train_df": [1, 54, 55, 56], "test_df": [1, 54, 55, 56], "anomaly_detect": [1, 13, 14, 15, 24, 54, 55, 56], "from_pd": [1, 2, 29, 54, 55, 56], "none": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 36, 42, 43, 54, 64, 73], "001": [1, 6, 10, 15, 17, 54, 55], "timestamp": [1, 2, 29, 54, 55, 56], "metric": [1, 2, 29, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 50, 52, 54, 59, 61, 75], "20": [1, 6, 17, 22, 29, 36, 40, 44, 46, 48, 50, 52, 54, 55, 56, 60, 62, 66, 73], "00": [1, 31, 38, 54, 55, 56], "around": [1, 36, 54], "reason": 1, "why": [1, 36], "indic": [1, 2, 3, 22, 28, 29, 43, 44, 46, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 73, 75], "explanationbas": [1, 20, 21, 22, 23, 24], "avail": 1, "cannot": [1, 20, 21, 22, 24], "fulfil": 1, "should": [1, 2, 6, 10, 11, 12, 14, 15, 17, 28, 34, 35, 36, 43, 55, 56, 73], "auto": [1, 3, 19], "mutual_info": [1, 3], "chi_squar": [1, 3], "pixel_import": [1, 20], "mask": [1, 6, 20, 34, 35, 39], "word_import": [1, 20], "feature_column": [2, 3, 28, 29, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51], "batch": [2, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 22, 29, 30, 31, 34, 35, 36, 37, 39, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "shape": [2, 29, 30, 35, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 73, 75], "batch_siz": [2, 6, 10, 15, 17, 29, 34, 35, 39, 42, 57, 59, 60, 61, 62, 73, 75], "height": [2, 29, 57], "width": [2, 29, 48, 57], "channel": [2, 25, 29, 57, 65, 66], "true": [2, 3, 4, 11, 15, 19, 21, 22, 23, 25, 29, 31, 32, 34, 35, 36, 38, 39, 42, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 70, 71, 73, 74, 75], "channel_last": 2, "dimens": [2, 15], "fals": [2, 4, 21, 22, 23, 29, 34, 35, 39, 48, 60, 62, 73, 75], "instead": [2, 28, 31, 36, 39, 40, 48, 52, 53, 54, 55, 56, 57, 64, 75], "number": [2, 4, 6, 7, 10, 11, 12, 15, 17, 18, 19, 20, 22, 23, 24, 25, 29, 40, 48], "4": [2, 20, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "pil": [2, 25, 29, 30, 57, 58, 63, 64, 67, 68, 69, 70, 71, 72, 74], "pilimag": [2, 25, 29, 30, 57, 58, 63, 64, 67, 68, 69, 70, 71, 72, 74], "im": [2, 3, 29, 57, 58, 60, 62, 63, 64, 67, 68, 70, 71, 73], "an_imag": 2, "jpg": [2, 25, 29, 30, 57, 58, 68, 69, 72], "hello": [2, 25, 30, 36], "m": [2, 25, 30, 48], "And": [2, 25, 30, 48], "anoth": [2, 22, 25, 30, 36, 67, 70], "veri": [2, 25, 30, 36], "allow": [2, 3, 4, 5, 9, 13, 16, 36, 52, 53, 57, 65, 66], "split": [2, 9, 12, 33, 54, 55, 56], "nltk": 2, "word_token": 2, "variabl": [2, 24, 29, 54, 55, 56], "num_vari": [2, 29], "construct": [2, 3, 12, 17, 28, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "2017": [2, 29, 65, 66], "12": [2, 29, 30, 31, 36, 40, 44, 46, 48, 50, 52, 69, 72], "27": [2, 29, 36, 40, 44, 46, 48, 50, 52], "1263": [2, 29], "94091": [2, 29], "394": [2, 29], "507": [2, 29], "16": [2, 29, 42, 53, 54, 55, 56], "530": [2, 29], "28": [2, 29, 40, 44, 46, 50, 52, 59, 61, 75], "1299": [2, 29], "86398": [2, 29], "506": [2, 29], "424": [2, 29], "14": [2, 29, 30, 63], "162": [2, 29], "date": [2, 29, 64], "consumpt": [2, 29], "wind": [2, 29], "solar": [2, 29], "set_index": [2, 29, 48, 54, 55, 56], "to_datetim": [2, 29, 54, 55, 56], "t": [2, 5, 15, 16, 34, 35, 36, 39, 40, 46, 54, 55, 56, 69, 72], "abstract": [2, 3, 20, 25], "differet": 2, "properti": [2, 3, 25], "data_typ": 2, "union": [2, 11, 22, 23, 24, 25], "ndarrai": [2, 9, 10, 11, 12, 15, 19, 25], "num_sampl": [2, 74], "num_featur": [2, 10, 22], "when": [2, 6, 7, 8, 9, 10, 11, 12, 17, 19, 20, 21, 22, 23, 24, 29, 36, 40, 53, 73], "int": [2, 4, 6, 7, 10, 11, 17, 25, 34, 35, 39, 54, 55, 56], "iloc": [2, 54, 55, 56], "row": [2, 29, 40, 44, 46, 48, 50, 52, 53, 54, 55, 56], "slice": [2, 48], "integ": [2, 25, 28], "tupl": [2, 25, 39, 67, 70, 74], "get": [2, 3, 20, 21, 22, 23, 24, 25, 29, 34, 35, 39, 48, 64], "continuous_column": [2, 29], "except": 2, "sequenc": [2, 4, 25, 48], "to_pd": [2, 29, 41, 43, 44, 46, 47, 48, 50, 52, 53], "copi": [2, 48], "otherwis": 2, "to_numpi": [2, 29, 42, 57, 59, 61, 75], "remove_target_column": [2, 46], "remov": [2, 30, 40, 48, 49, 64, 75], "get_continuous_median": 2, "absolut": [2, 36], "median": [2, 11, 25, 30, 42], "dict": [2, 3, 4, 5, 8, 9, 13, 16, 20, 21, 22, 23, 24, 26, 33], "get_continuous_bound": 2, "upper": [2, 11, 15], "lower": [2, 11, 15], "bound": [2, 11, 15], "grayscal": 2, "rgb": [2, 29, 30, 57, 58, 63, 64, 67, 68, 69, 70, 71, 72, 74], "h": [2, 25, 40, 44, 46, 50, 52], "w": [2, 25, 69, 72], "ignor": [2, 3, 8, 10, 11, 12, 17, 19, 21, 22, 23, 40, 46], "bool": [2, 6, 10, 17], "size": [2, 6, 10, 17, 22, 25, 29, 30, 69, 72], "color": [2, 29], "argument": [2, 36, 64, 75], "image_shap": [2, 29, 65, 66], "hwc": [2, 29], "keepdim": [2, 29], "kept": [2, 36], "squeez": [2, 35, 39, 48], "to_pil": [2, 3, 29, 30, 57, 58, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74], "callabl": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 42], "to_token": [2, 29], "to_str": 2, "sep": [2, 7, 33, 34, 35, 39, 72], "maxsplit": 2, "variable_nam": 2, "multivari": [2, 54, 55, 56], "whose": [2, 8, 11, 12, 17, 19, 22, 30, 34, 35], "ts_len": [2, 15, 29], "length": [2, 15, 29, 31, 32, 33, 39], "datetimeindex": 2, "classmethod": 2, "rtype": 2, "kernel_width": [3, 9, 10, 40, 52, 53], "nsampl": [3, 9, 10, 17, 40, 50, 52, 53], "100": [3, 9, 10, 34, 35, 36, 39, 40, 43, 50, 52, 53, 57, 58, 60, 62, 65, 66, 73], "similar": [3, 25, 31, 39, 42, 51, 57], "img": [3, 16, 25, 29, 30, 57, 58, 63, 64, 67, 68, 70, 71, 74], "mainli": 3, "gbtree": [3, 40, 41, 43, 44, 46, 47, 50, 52], "predict_proba": [3, 9, 36, 37, 41, 43, 44, 46, 47, 50], "shaptabular": [3, 10, 50, 75], "training_data": [3, 4, 6, 9, 10, 11, 12, 14, 15, 17, 36, 41, 42, 43, 44, 46, 47, 48, 49, 50, 55, 56, 73], "compos": [3, 57, 58, 60, 62, 64, 68, 71, 73, 74], "256": [3, 6, 10, 17, 34, 35, 39, 42, 48, 57, 58, 64, 68, 71, 74], "centercrop": [3, 57, 58, 64, 68, 71, 74], "totensor": [3, 57, 58, 60, 62, 64, 68, 71, 73, 74], "mean": [3, 12, 21, 22, 23, 25, 26, 29, 30, 35, 36, 39, 43, 44, 46, 49, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 68, 71, 73, 74, 75], "485": [3, 57, 58, 64, 68, 71, 74], "456": [3, 57, 58, 64, 68, 71, 74], "406": [3, 57, 58, 64, 68, 71, 74], "std": [3, 22, 25, 35, 39, 57, 58, 64, 68, 71, 74], "229": [3, 57, 58, 64, 68, 71, 74], "225": [3, 57, 58, 64, 68, 71, 74], "stack": [3, 57, 58, 60, 62, 64, 68, 69, 71, 72, 73, 74], "found": [3, 15, 69, 72], "explainerabcmeta": 3, "classnam": 3, "cls_dict": 3, "autodocabcmeta": 3, "meta": 3, "_explain": 3, "collect": [3, 4, 5, 9, 13, 16], "empti": [3, 5, 16, 19], "ani": [3, 5, 9, 12, 13, 16, 36], "param_1": [3, 4, 5, 9, 13, 16], "lime_explan": 3, "shap_explan": 3, "ordereddict": 3, "pdp_explan": 3, "explainer_nam": 3, "static": [3, 4, 5, 9, 12, 13, 16, 25], "list_explain": [3, 4, 5, 9, 13, 16], "mutual": [4, 28, 36, 40], "n_bin": [4, 25], "10": [4, 6, 10, 11, 15, 17, 18, 19, 21, 22, 29, 30, 34, 35, 39, 40, 48, 49, 54, 55, 56, 59, 60, 61, 62, 63, 70, 73, 75], "imbalanceanalyz": 4, "count": [4, 22], "appear": [4, 22], "gender": [4, 42], "comput": [4, 12, 15, 19, 30, 36, 69, 72], "male": [4, 29, 30, 40, 42, 44, 46, 50, 52], "femal": [4, 29, 30, 40, 42, 44, 46, 50, 52], "separ": [4, 36, 43, 73], "cross": [4, 22, 28], "bin": [4, 15, 25], "discret": [4, 10, 25], "imbalanceexplan": [4, 22], "correlationanalyz": 4, "matrix": [4, 22], "scipi": 4, "stat": [4, 40], "spearmanr": 4, "correlationexplan": [4, 22], "mutualinform": 4, "globalfeatureimport": [4, 22], "chisquar": 4, "chi": [4, 28, 40], "squar": [4, 28, 40], "non": 4, "chi2": [4, 28, 40], "qa": [5, 7, 31, 33], "those": [5, 16, 30, 46], "don": [5, 16, 40, 46], "limetext": [6, 37], "pleas": [6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "cite": [6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 46, 49, 50, 56, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75], "origin": [6, 8, 10, 12, 14, 17, 18, 19, 22, 24, 25, 34, 35, 36, 37, 38, 43, 44, 50, 56, 61, 62, 70, 71, 73, 74, 75], "work": [6, 7, 8, 10, 12, 14, 17, 19, 32, 33, 34, 35, 36, 37, 38, 40, 43, 44, 50, 56, 61, 62, 70, 71, 73, 74, 75], "github": [6, 7, 8, 10, 12, 14, 17, 19, 32, 33, 34, 35, 37, 38, 44, 49, 50, 56, 70, 71, 74, 75], "com": [6, 7, 8, 10, 12, 14, 17, 19, 32, 33, 34, 35, 37, 38, 44, 49, 50, 56, 69, 70, 71, 72, 74, 75], "marcotcr": [6, 10, 17, 37, 44, 74], "lime_text": 6, "limetextexplain": 6, "refer": [6, 10, 11, 17, 36, 43, 47, 48, 58, 59, 60, 61, 62, 73], "doc": [6, 10, 17, 28, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "explain_inst": [6, 10, 17], "wordimport": [6, 8, 23], "shaptext": [6, 38], "slundberg": [6, 10, 12, 14, 17, 38, 50, 56, 75], "textclassificationpipelin": [6, 38], "text_classif": 6, "defaultselectionmodel": [6, 10, 17, 36, 43, 73], "_defaultmodelbas": [6, 10, 17], "consist": [6, 40], "1d": 6, "convolut": [6, 19, 57, 59, 60, 61, 62, 67, 68, 73, 75], "l2xtext": [6, 36], "hidden_s": [6, 10, 34, 35, 39], "hidden": [6, 10, 42, 59, 60, 61, 62, 73, 75], "kernel_s": [6, 34, 35, 39, 59, 60, 61, 62, 73, 75], "kernel": 6, "forward": [6, 10, 17, 35, 39, 60, 62, 73], "defaultpredictionmodel": [6, 10, 17, 36, 43, 73], "weight": [6, 10, 11, 15, 17, 18, 19, 35, 36, 39, 42, 64, 65, 66, 67, 70], "gumbel": [6, 10, 17], "softmax": [6, 10, 17, 39, 57, 74], "tau": [6, 10, 17, 48], "k": [6, 10, 17, 34, 35, 39, 48, 57, 58, 67, 68, 70, 71, 74], "selection_model": [6, 10, 17, 36, 43, 73], "prediction_model": [6, 10, 17, 36, 43, 73], "loss_funct": [6, 10, 17, 69, 72], "optim": [6, 10, 11, 15, 17, 18, 19, 34, 35, 39, 42, 48, 55, 58, 59, 60, 61, 62, 63, 65, 66, 73, 75], "learning_r": [6, 10, 11, 15, 17, 18, 19, 34, 35, 39, 42, 60, 62, 73], "num_epoch": [6, 10, 17, 34, 35, 39, 48, 60, 62, 73], "theoret": [6, 10, 17, 36, 43, 73], "perspect": [6, 10, 17, 36, 43, 73], "jianbo": [6, 10, 17, 36, 43, 73], "chen": [6, 10, 17, 36, 43, 73], "le": [6, 10, 17, 36, 43, 73], "song": [6, 10, 17, 36, 43, 73], "martin": [6, 10, 17, 36, 43, 73], "j": [6, 10, 17, 36, 43, 48, 73], "wainwright": [6, 10, 17, 36, 43, 73], "michael": [6, 10, 17, 36, 43, 73], "jordan": [6, 10, 17, 36, 43, 73], "1802": [6, 10, 17, 19, 36, 43, 61, 62, 73], "07814": [6, 10, 17, 36, 43, 73], "float": [6, 9, 10, 12, 15, 17, 25, 34, 48, 60, 62, 73], "maximum": [6, 7, 10, 11, 15, 17, 18, 19, 20, 22, 23, 24, 31, 32, 33, 39, 48], "p": [6, 10, 17, 36, 43, 73, 74], "q": [6, 10, 17, 36, 43, 48, 73], "x_": [6, 10, 17, 36, 43, 73], "nn": [6, 8, 10, 11, 12, 17, 18, 19, 34, 35, 39, 57, 58, 59, 60, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75], "crossentropyloss": [6, 10, 17, 35, 39, 60, 62, 73], "adamw": [6, 35, 39], "rate": [6, 10, 11, 15, 17, 18, 19, 48], "pick": [6, 10, 17], "32": [6, 10, 17, 35, 39, 53, 59, 61, 73, 75], "64": [6, 10, 17, 42, 48, 59, 61, 75], "128": [6, 10, 17, 34, 35, 39, 42, 59, 60, 61, 62, 75], "epoch": [6, 10, 17, 34, 42, 59, 60, 61, 62, 73, 75], "develop": [7, 11, 15, 28, 31, 32, 33, 39, 40, 46, 52, 53, 54, 57], "wu": [7, 32, 33], "et": [7, 11, 15, 19, 32, 33, 46, 67, 68], "tongshuangwu": [7, 32, 33], "pr": 7, "model_path": 7, "cuda": [7, 35, 39, 57, 60, 62, 66, 69, 71, 72, 73, 74], "max_number_exampl": [7, 11], "context": [7, 33, 48], "concaten": [7, 25, 35, 39, 49, 53, 57, 63, 67, 70], "seper": [7, 33], "ce_typ": 7, "perturb": 7, "blank": 7, "cfexplan": [7, 11, 15, 18, 21, 22, 24], "integratedgradienttext": [8, 34, 35], "ankurtali": [8, 12, 19, 34, 35, 70, 71], "kera": [8, 11, 12, 17, 18, 19, 34, 35, 42, 48, 58, 59, 60, 61, 62, 63, 65, 67, 68, 70, 71, 75], "must": [8, 34, 35, 39, 40], "integrated_gradi": [8, 12, 19], "integratedgradi": [8, 12, 16, 19, 72], "compute_integrated_gradi": [8, 12, 19], "sklearnbas": [9, 12], "cate_encod": [9, 12], "onehot": [9, 12, 25, 30], "cont_encod": [9, 12], "target_encod": [9, 12], "labelencod": [9, 12, 25, 30], "baseestim": 9, "transformbas": [9, 12, 25], "ident": [9, 12, 25, 49, 53], "minmax": [9, 12, 25, 30, 41, 43, 44, 46, 47, 50, 52, 53], "scale": [9, 12, 25, 30], "train_siz": [9, 12, 40, 41, 43, 44, 46, 47, 49, 50, 52, 53], "proport": [9, 12], "ce": [9, 13, 16, 57], "decision_tre": [9, 51], "shap_tre": 9, "limetabular": [10, 44], "lime_tabular": 10, "limetabularexplain": 10, "featureimport": [10, 12, 14, 22, 24], "kernelexplain": [10, 14], "shap_valu": [10, 14], "partialdependencetabular": [10, 47], "stabl": [10, 47, 48, 53], "partial_depend": [10, 17, 47], "html": [10, 47, 48, 53], "grid_resolut": [10, 17], "candid": 10, "dure": [10, 11, 15, 18, 19], "pdpexplan": [10, 22], "sensitivityanalysistabular": [10, 49], "salib": [10, 49], "sa": 10, "sensitivityexplan": [10, 22], "feedforward": [10, 42], "neural": [10, 59, 60, 61, 62, 63, 73, 75], "network": [10, 19, 36, 42, 43, 59, 60, 61, 62, 63, 67, 68, 73, 75], "l2xtabular": [10, 43], "adam": [10, 17, 34, 59, 60, 61, 62, 73, 75], "Not": [10, 12, 18, 40, 44, 46, 50, 52], "maceexplain": [11, 15, 46, 55], "yang": [11, 15, 46], "paper": [11, 15, 18, 19, 42, 46, 58, 59, 60], "effici": [11, 15, 46], "framework": [11, 15, 33, 46], "cfretriev": 11, "gld": 11, "retriev": 11, "desir": [11, 25, 73], "counterfactualoptim": [11, 15], "x0": [11, 15, 19], "c": [11, 15, 18, 19, 25, 28, 29, 30, 31, 36, 39, 40, 52, 53, 54, 57, 74], "kappa": [11, 15, 18, 19], "binary_search_step": [11, 15, 18, 19, 57, 58, 59, 60, 61, 62], "01": [11, 15, 18, 19, 35, 39, 54, 55, 56], "num_iter": [11, 15, 18, 19, 57, 58, 59, 60, 61, 62, 65, 66], "1000": [11, 15, 18, 19, 49, 67, 70, 74], "grad_clip": [11, 15, 18, 19], "gamma": [11, 15, 19], "autom": [11, 18, 42, 58, 59, 60], "gdpr": [11, 18, 42, 58, 59, 60], "sandra": [11, 18, 42, 58, 59, 60], "wachter": [11, 18, 42, 58, 59, 60], "brent": [11, 18, 42, 58, 59, 60], "mittelstadt": [11, 18, 42, 58, 59, 60], "chri": [11, 18, 42, 58, 59, 60], "russel": [11, 18, 42, 58, 59, 60], "1711": [11, 18, 42, 58, 59, 60], "00399": [11, 18, 42, 58, 59, 60], "hing": [11, 15, 18, 19], "term": [11, 15, 18, 19], "iter": [11, 15, 18, 19], "adjust": [11, 15, 18, 19], "clip": [11, 15, 18, 19], "denomin": [11, 15], "regular": [11, 15, 19], "verbos": [11, 15, 19, 35, 39, 42, 59, 61, 75], "counterfactualexplain": [11, 15, 18, 42, 58, 59, 60, 62], "extract": [11, 21, 22, 25, 42], "inp": 12, "baselin": [12, 19], "output_index": 12, "50": [12, 34, 35, 39, 40, 44, 46, 50, 52, 60, 62, 73], "integratedgradienttabular": 12, "num_random_tri": [12, 19], "trial": [12, 19], "_sample_baselin": 12, "linearbas": 12, "coeffici": [12, 22, 45], "linearexplan": [12, 22], "linearregress": [12, 45], "lasso": 12, "linear_regress": 12, "logisticregress": [12, 45], "logistic_regress": 12, "treebas": 12, "random": [12, 25, 36, 37, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "forest": [12, 36, 37, 49, 53], "structur": [12, 22, 31, 36, 43, 51, 59, 61, 73], "path": [12, 22, 28, 36, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56], "treeexplan": [12, 22], "treeregressor": [12, 51], "regressor": [12, 53], "sklearn": [12, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53], "decisiontreeregressor": 12, "tree_regressor": 12, "treeclassifi": [12, 51], "decisiontreeclassifi": 12, "tree_classifi": 12, "shaptreetabular": 12, "forecast": [13, 14, 15, 24, 54, 56], "shaptimeseri": [14, 56], "higher": [14, 15, 40, 54, 55, 56], "anomal": [14, 15, 54, 55, 56], "smooth_weight": 15, "grid_siz": 15, "reshap": [15, 49, 53, 59, 61, 75], "determin": [15, 36, 48, 54, 55, 56], "smooth": 15, "numer": [15, 48], "revis": 15, "version": [15, 31, 36, 39, 69, 72], "rl": 15, "cem": 16, "limeimag": [17, 74], "top_label": 17, "limeimageexplain": 17, "maskexplan": [17, 21], "shapimag": [17, 75], "background_data": [17, 19], "background": [17, 19], "pixelimport": [17, 19, 21], "partialdependenceimag": 17, "segment": 17, "quickshift": 17, "measur": 17, "averag": [17, 22, 34, 35, 36, 37, 39, 65, 66], "replac": [17, 42], "grid": [17, 22], "resolut": 17, "n_segment": 17, "l2ximag": [17, 73], "upsampl": [17, 73], "been": [18, 19, 36, 69, 72], "255": [18, 19, 30, 59, 61, 75], "integratedgradientimag": [19, 70, 71], "randomli": 19, "selvaraju": [19, 67, 68], "1610": [19, 67, 68], "02391": [19, 67, 68], "gradcamplu": 19, "chattopadhyai": 19, "pdf": 19, "1710": 19, "11063": 19, "cemoptim": 19, "beta": 19, "ae_model": 19, "07623": [19, 61, 62], "l1": 19, "ae": 19, "pn_optim": 19, "pertin": [19, 21, 61, 62], "pp_optim": 19, "contrastiveexplain": [19, 61, 62], "contrastiveexplan": [19, 21], "get_explan": [20, 21, 22, 23, 24, 48], "compon": [20, 36], "dashfigur": 20, "to_html_div": 20, "to_html": 20, "predictedresult": 20, "classfic": 20, "max_num_subplot": [20, 22, 23], "subplot": [20, 22, 23], "use_heatmap": 21, "item": [21, 22, 23, 24, 60, 62, 73], "entri": [21, 22, 23], "target_label": [21, 22, 23], "heatmap": 21, "importance_scor": [21, 22, 23, 24], "dog": [21, 22, 23, 26, 57, 69, 72], "cat": [21, 22, 23, 26, 35, 36, 39], "boundari": 21, "pn": 21, "pn_label": 21, "pp": 21, "pp_label": 21, "cf": [21, 22, 24], "cf_label": 21, "counterfactualexplan": 21, "feature_valu": 22, "sort": [22, 23, 30], "font_siz": 22, "font": 22, "tabl": 22, "deviat": [22, 25], "pdp_mean": 22, "pdp_std": 22, "plot_std": 22, "shown": [22, 23], "mu": 22, "mu_star": 22, "sigma": 22, "mu_star_conf": 22, "plot_coeffici": 22, "tick": 22, "binari": [22, 34, 35, 36, 37, 39, 42, 57, 58, 59, 60, 61, 62, 63], "add_glob": 22, "whole": [22, 36], "add_loc": 22, "decision_path": 22, "node_ind": 22, "node": 22, "figsiz": 22, "15": [22, 29, 36, 40, 44, 46, 50, 52, 54, 55, 56, 64, 65], "fontsiz": 22, "num_tokens_per_class": 23, "max_length": [23, 31, 32, 33, 34, 35, 39], "512": 23, "figure_typ": 24, "max_num_variables_to_plot": 24, "25": [24, 48, 53], "bar": 24, "invert": [25, 30, 40, 44, 50, 52, 53], "invers": [25, 30, 40, 44, 50, 52, 53], "b": [25, 29, 30], "d": [25, 29, 30, 32], "cate_transform": [25, 30], "cont_transform": [25, 30, 41, 43, 44, 46, 47, 50, 52, 53], "fillnan": 25, "fillnantabular": [25, 30], "pseudo": 25, "recov": 25, "some_imag": 25, "360": 25, "240": [25, 30, 74], "tfidf": [25, 30, 34, 35, 36, 37, 39], "vector": [25, 30, 36, 37], "drop": [25, 40, 42, 49, 54, 55, 56], "get_feature_nam": [25, 30], "input_featur": 25, "zero": [25, 34, 35, 39], "unit": [25, 40, 42, 44, 46, 48, 50, 52, 54, 55, 56], "varianc": 25, "ratio": 25, "miss": 25, "chosen": 25, "itself": 25, "dump": [25, 28], "save": [25, 48], "target_transform": [25, 30, 49, 53], "decompos": 25, "hold": [25, 36], "expect": 25, "ith": 25, "00392156862745098": 25, "round2int": 25, "round": 25, "resampl": 25, "bilinear": [25, 73], "smaller": 25, "edg": 25, "match": 25, "strategi": 25, "word2id": [25, 30, 34, 35, 39], "remove_punctu": 25, "pad": [25, 34, 35, 39], "start": [25, 36, 48], "unk": [25, 30], "vocab_s": [25, 34, 35, 39], "re": [25, 36, 37], "sub": 25, "over": 25, "fraction": 25, "random_st": [25, 42], "guarante": 25, "seed": [25, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52], "undersampl": 25, "balanc": 25, "minor": 25, "decreas": [25, 40], "major": 25, "oversampl": 25, "increas": [25, 36, 40], "host": [26, 37], "127": [26, 28, 31, 39, 40, 52, 53, 54, 57], "port": 26, "8050": [26, 28, 31, 39, 40, 52, 53, 54, 57], "omnixai": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "render": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "sphinx": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "delet": [28, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "cell": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "io": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "pio": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "png": [28, 31, 32, 33, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], "o": [28, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 63, 64, 69, 72], "join": [28, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56], "now": [28, 34, 35, 36, 39, 40, 48, 52, 53, 57, 60, 62, 73], "than": [28, 33, 36, 64], "onc": [28, 36], "n": [28, 29, 34, 35, 39, 48], "append": [28, 32, 35, 39, 54, 55, 56, 63, 67, 70], "print": [28, 29, 30, 31, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 70, 73, 74, 75], "serv": [28, 31, 39, 40, 52, 53, 54, 57], "flask": [28, 31, 39, 40, 52, 53, 54, 57], "34": [28, 29, 30, 31, 39, 40, 52, 53, 54, 57], "lazi": [28, 31, 39, 40, 52, 53, 54, 57], "environ": [28, 31, 33, 39, 40, 48, 52, 53, 54, 57], "product": [28, 31, 39, 40, 52, 53, 54, 57], "warn": [28, 31, 36, 39, 40, 52, 53, 54, 57, 75], "server": [28, 31, 39, 40, 52, 53, 54, 57], "deploy": [28, 31, 39, 40, 52, 53, 54, 57], "wsgi": [28, 31, 39, 40, 52, 53, 54, 57], "debug": [28, 31, 39, 40, 52, 53, 54, 57], "off": [28, 31, 36, 39, 40, 52, 53, 54, 57], "press": [28, 31, 39, 40, 52, 53, 54, 57], "ctrl": [28, 31, 39, 40, 52, 53, 54, 57], "quit": [28, 31, 39, 40, 52, 53, 54, 57], "notebook": [29, 48], "how": [29, 36, 40, 48], "f": [29, 30, 34, 48], "39": [29, 30, 40, 44, 46, 48, 50, 52, 53, 64, 67, 70, 74], "ye": [29, 30, 36, 42], "swap": 29, "digit": [29, 59, 60, 61, 62, 73, 75], "torchvis": [29, 57, 58, 60, 62, 64, 66, 68, 71, 73, 74], "test_data": [29, 60, 62, 73], "download": [29, 60, 62, 69, 72, 73], "10000": [29, 54, 55, 56], "11": [29, 30, 36, 40, 48, 49, 75], "displai": [29, 30], "loop": 29, "camera": [29, 30, 57, 58, 68], "what": [29, 31, 32, 33, 34, 35, 36, 38], "great": [29, 31, 32, 34, 35, 36, 38, 39], "movi": [29, 31, 32, 34, 35, 38, 39], "tast": [29, 32, 34, 35, 38], "best": [29, 32, 34, 35, 38, 39], "film": [29, 32, 34, 35, 38, 39], "ever": [29, 32, 34, 35, 38, 39], "ve": [29, 32, 34, 35, 38, 39], "never": [29, 32, 34, 35, 38, 39, 40, 44, 46, 50, 52], "watch": [29, 32, 34, 35, 38, 39], "someth": [29, 32, 34, 35, 36, 38, 39], "bad": [29, 32, 34, 35, 36, 38, 39], "len": [29, 34, 35, 39, 57, 58, 63, 67, 68, 70, 71, 74], "17": [29, 38, 53, 54, 55, 56], "18": [29, 36, 48, 53], "29": 29, "1319": 29, "76541": 29, "610": 29, "314": 29, "173": 29, "19": [29, 36, 48], "ts_a": 29, "ts_b": 29, "try": [30, 41, 43, 44, 46, 47, 48, 50, 52, 53], "22474487": 30, "120": 30, "6227660078332259": 30, "4736296010332684": 30, "5178561161676974": 30, "680918560398684": 30, "7265094189091538": 30, "3632547094545769": 30, "2762645695949752": 30, "unknown": 30, "xxx": 30, "lt": [30, 40, 44, 46, 50, 52], "gt": [30, 40, 44, 46, 50, 52], "limit": [31, 39], "interview": 31, "neither": 31, "funni": 31, "nor": 31, "witti": 31, "even": [31, 36], "like": [31, 36], "overal": [31, 36], "distilbert": [31, 32, 38], "uncas": [31, 32, 38], "finetun": [31, 32, 38], "sst": [31, 32, 38], "english": [31, 32, 38], "return_all_scor": [31, 32, 38], "ss": 31, "There": [31, 39, 57], "partit": [31, 36, 38], "3it": 31, "70": 31, "info": [31, 32, 33, 39, 48], "polyjuice_wrapp": [31, 32, 33, 39], "setup": [31, 32, 33, 39], "spaci": [31, 32, 33, 39], "processor": [31, 32, 33, 39, 69, 72], "perplex": [31, 32, 33, 39], "scorer": [31, 32, 33, 39], "ask": [31, 32, 33, 36, 39], "truncat": [31, 32, 33, 39], "predefin": [31, 32, 33, 39], "werkzeug": [31, 39], "idx2label": [32, 57, 58, 67, 68, 70, 71, 74], "build": [32, 33, 40, 60, 62, 69, 72], "def": [32, 33, 34, 35, 39, 42, 48, 54, 55, 56, 60, 62, 63, 67, 69, 70, 72, 73, 74], "_predict": [32, 33], "pred": 32, "els": [32, 34, 35, 36, 39, 57, 59, 60, 61, 62, 66, 71, 73, 74, 75], "unittest": [33, 34, 45, 69, 72, 74], "model_nam": 33, "deepset": 33, "roberta": 33, "squad2": 33, "isinst": [33, 48], "farm": 33, "give": [33, 36], "freedom": 33, "peopl": [33, 36], "switch": 33, "covers": 33, "electr": 33, "vehicl": 33, "emit": 33, "less": [33, 36], "harm": 33, "pollut": 33, "convent": 33, "ultim": 33, "cleaner": [33, 40, 44, 46, 50, 52], "human": [33, 36], "beings": 33, "eletr": 33, "fetch_20newsgroup": [34, 35, 36, 37, 39], "textmodel": [34, 35, 39], "num_embed": [34, 35, 39], "num_class": [34, 35, 39, 59, 61, 75], "super": [34, 35, 39, 60, 62, 73], "embedding_s": [34, 35, 39], "embeddings_initi": 34, "randomuniform": 34, "minval": 34, "maxval": 34, "conv_lay": [34, 35, 39, 60, 62, 73], "conv1d": [34, 35, 39], "activ": [34, 35, 36, 39, 42, 48, 59, 61, 75], "relu": [34, 35, 39, 48, 59, 60, 61, 62, 73, 75], "dropout": [34, 35, 39, 48, 59, 60, 61, 62, 73, 75], "output_lay": [34, 35, 39], "dens": [34, 42, 48, 59, 60, 61, 62, 73, 75], "expand_dim": [34, 48, 59, 61, 63, 67, 70, 75], "axi": [34, 35, 39, 42, 48, 49, 53, 59, 61, 63, 67, 70, 75], "reduce_max": 34, "concat": 34, "relat": [34, 35, 36, 37, 39], "train_data": [34, 35, 39, 60, 62, 73], "read_csv": [34, 35, 39, 42, 48, 54, 55, 56], "home": [34, 35, 39, 69, 72, 75], "ywz": [34, 35, 39, 69, 72, 75], "labeledtraindata": [34, 35, 39], "tsv": [34, 35, 39], "x_train": [34, 35, 36, 37, 39, 42, 49, 53, 59, 60, 61, 62, 75], "y_train": [34, 35, 36, 37, 39, 42, 49, 53, 59, 60, 61, 62, 75], "astyp": [34, 35, 39, 42, 54, 55, 56, 59, 61, 75], "x_test": [34, 35, 36, 37, 39, 42, 49, 53, 59, 60, 61, 62, 75], "y_test": [34, 35, 36, 37, 39, 42, 49, 53, 59, 60, 61, 62, 75], "max_len": [34, 35, 39], "float32": [34, 35, 39, 42, 48, 59, 61, 75], "evalu": [34, 35, 39, 42, 59, 60, 61, 62, 73, 75], "1e": [34, 35, 39, 60, 62, 73], "loss_fn": 34, "sparsecategoricalcrossentropi": 34, "from_logit": [34, 42, 59, 61, 75], "train_dataset": 34, "from_tensor_slic": 34, "shuffl": [34, 35, 39, 60, 62, 73], "buffer_s": 34, "1024": 34, "enumer": [34, 60, 62, 73], "gradienttap": 34, "tape": 34, "trainable_weight": 34, "apply_gradi": 34, "zip": [34, 60, 62, 73, 74], "200": [34, 42, 53], "6866752505302429": 34, "4109169542789459": 34, "21237820386886597": 34, "1540527492761612": 34, "08126655220985413": 34, "02999718114733696": 34, "008433952927589417": 34, "009998280555009842": 34, "0030068857595324516": 34, "001554026734083891": 34, "argmax": [34, 35, 39], "accuraci": [34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 59, 60, 61, 62, 73, 75], "f1_score": [34, 35, 36, 37, 39], "8560798903465829": 34, "id_to_word": [34, 35, 39], "util": [35, 39, 42, 59, 60, 61, 62, 73, 75], "trainer": [35, 39], "inputdata": [35, 39, 60, 62, 73], "dataload": [35, 39, 60, 62, 73], "normal_": [35, 39], "modulelist": [35, 39], "unsqueez": [35, 39, 74], "dim": [35, 39, 57, 74], "permut": [35, 39], "devic": [35, 39, 57, 60, 62, 66, 71, 73, 74], "is_avail": [35, 39, 57, 60, 62, 66, 71, 73, 74], "cpu": [35, 39, 57, 60, 62, 63, 66, 71, 73, 74], "optimizer_class": [35, 39], "loss_func": [35, 39, 60, 62, 73], "train_x": [35, 39], "train_i": [35, 39], "complet": [35, 36, 39, 43, 73], "0008": 35, "eval": [35, 39, 60, 62, 73, 74], "data_load": [35, 39], "collate_fn": [35, 39], "collate_func": [35, 39], "detach": [35, 39, 73, 74], "8458027386386188": 35, "advantag": [36, 43, 73], "fast": [36, 43, 73], "disadvantag": [36, 43, 73], "qualiti": [36, 43, 73], "highli": [36, 40, 43, 73], "affect": [36, 43, 73], "factor": [36, 43, 73], "hyperparamet": [36, 43], "ensembl": [36, 37, 45, 49, 52, 53], "alt": [36, 37], "atheism": [36, 37], "soc": [36, 37], "religion": [36, 37], "christian": [36, 37], "newsgroups_train": [36, 37], "newsgroups_test": [36, 37], "tfdif": [36, 37], "train_vector": [36, 37], "test_vector": [36, 37], "randomforestclassifi": [36, 37], "500": [36, 37], "925233644859813": 36, "idx": [36, 37], "83": [36, 37, 69, 72], "0039": 36, "8674698795180723": 36, "subject": [36, 37], "request": 36, "darwin": 36, "fish": 36, "organ": [36, 37], "univers": 36, "mexico": 36, "albuquerqu": 36, "recent": 36, "seen": 36, "anyon": [36, 37], "contact": 36, "email": 36, "me": 36, "john": 36, "dan": 36, "rose": 36, "aros": 36, "nation": [36, 37], "repent": 36, "my": 36, "own": [36, 40, 44, 46, 50, 52], "view": [36, 48], "63": 36, "mcovingt": 36, "covington": 36, "heard": 36, "radio": 36, "todai": 36, "student": 36, "confer": 36, "were": 36, "america": 36, "sin": [36, 37], "sexual": 36, "promiscu": 36, "repli": 36, "ca": 36, "claim": 36, "someon": 36, "am": 36, "fact": 36, "him": 36, "jesu": 36, "equip": 36, "judg": 36, "lewi": 36, "essai": 36, "world": 36, "war": 36, "ii": 36, "leader": 36, "britain": 36, "urg": 36, "horror": 36, "strongli": 36, "disagre": 36, "turn": 36, "behav": 36, "incredibli": 36, "toward": 36, "god": 36, "encourag": 36, "forc": 36, "folk": 36, "particip": 36, "directli": [36, 45], "oppos": 36, "written": 36, "far": 36, "abov": [36, 40, 42, 60, 62, 73], "luxuri": 36, "live": 36, "land": 36, "slaughter": 36, "children": 36, "million": 36, "stricken": 36, "out": 36, "honor": 36, "due": 36, "everi": 36, "ow": 36, "apologi": 36, "bit": [36, 40], "public": 36, "said": [36, 37], "decai": 36, "bibl": 36, "quiz": 36, "distribut": 36, "articl": 36, "healta": 36, "tammi": 36, "r": [36, 57, 58, 67, 68, 69, 70, 71, 72, 74], "heali": 36, "coven": 36, "he": 36, "idol": 36, "worship": 36, "high": 36, "priest": 36, "could": 36, "enter": 36, "holi": 36, "year": 36, "dai": 36, "aton": 36, "familiar": 36, "knowledg": 36, "believ": 36, "translat": 36, "would": 36, "had": 36, "think": 36, "wrong": 36, "again": 36, "just": 36, "suggest": 36, "correct": 36, "dean": 36, "danb": 36, "babcock": 36, "thought": 36, "commun": 36, "compani": 36, "voic": 36, "bil": 36, "bill": 36, "conner": 36, "jame": 36, "felder": 36, "spbach": 36, "wrote": 36, "logic": 36, "alert": 36, "incredul": 36, "hard": 36, "doe": 36, "liar": 36, "pursuas": 36, "look": [36, 48], "koresh": 36, "yourself": 36, "basi": 36, "reject": 36, "account": 36, "thing": 36, "madalyn": 36, "face": 36, "silli": 36, "okai": 36, "disbeliev": 36, "admit": 36, "fallaci": 36, "awar": 36, "reader": 36, "assert": 36, "mam": 36, "mike": 36, "mcangu": 36, "american": 36, "evolut": 36, "mat": 36, "tin": 36, "pl9": 36, "53": [36, 40, 44, 46, 50, 52], "tue": 36, "apr": 36, "1993": 36, "gmt": 36, "robert": 36, "singleton": 36, "bob": 36, "sure": 36, "exclus": 36, "lend": 36, "notion": 36, "posterior": 36, "atheist": 36, "pitch": 36, "thu": 36, "necessarili": 36, "reduc": 36, "quantiti": 36, "theist": 36, "divin": 36, "fall": 36, "prei": 36, "ockham": 36, "razor": 36, "phenomenon": 36, "being": 36, "satisfactorili": 36, "independ": 36, "evid": 36, "occam": 36, "law": 36, "natur": 36, "often": 36, "end": 36, "seem": 36, "odd": 36, "simultan": 36, "condemn": 36, "primit": 36, "unscientif": 36, "childish": 36, "yet": [36, 48], "complex": 36, "scientif": 36, "straightforeward": 36, "appar": 36, "cute": 36, "character": 36, "howev": 36, "inconsist": 36, "statement": 36, "still": 36, "unnecessari": 36, "level": 36, "idea": 36, "themselv": 36, "thei": [36, 40], "unnecessarili": 36, "descript": 36, "part": 36, "sfp": 36, "sheila": 36, "patterson": 36, "mari": 36, "assumpt": 36, "cornel": 36, "cit": 36, "22": [36, 40, 44, 46, 50, 52, 53], "mpaul": 36, "marxhausen": 36, "paul": 36, "feel": 36, "better": 36, "phrase": 36, "sai": 36, "parent": 36, "sanctifi": 36, "beyond": 36, "sound": 36, "inabl": 36, "grasp": 36, "grace": 36, "incarn": 36, "through": 36, "alwai": [36, 48], "impress": 36, "chose": 36, "woman": 36, "bring": 36, "himself": 36, "prove": 36, "down": 36, "hi": 36, "perfect": 36, "touch": 36, "ah": 36, "wonder": 36, "ithaca": 36, "ny": 36, "mark": 36, "boston": [36, 49], "asid": 36, "moder": 36, "rick": 36, "granberri": 36, "wo": 36, "quot": 36, "error": 36, "opinion": 36, "writer": 36, "plain": 36, "confus": 36, "come": [36, 48], "lexington": 36, "church": 36, "brought": 36, "team": 36, "actual": 36, "il": 36, "up": [36, 48, 64], "friend": 36, "tell": 36, "go": [36, 69, 72], "northeast": 36, "wast": 36, "talent": 36, "realli": 36, "kind": [36, 52, 53], "insid": 36, "joke": 36, "took": 36, "well": [36, 65, 66], "inde": 36, "misinform": 36, "sun": 36, "ok": 36, "mail": 36, "marshal": 36, "kevin": 36, "death": 36, "penalti": 36, "polit": 36, "virginia": 36, "tech": [36, 40, 44, 46, 50, 52], "scienc": 36, "dept": 36, "blacksburg": 36, "va": 36, "46": 36, "fascin": 36, "argu": 36, "abort": 36, "defend": 36, "homosexu": 36, "popul": [36, 53], "control": 36, "insist": 36, "biolog": 36, "punish": 36, "benedikt": 36, "contardictori": 36, "case": [36, 48], "excel": 36, "growth": 36, "sorri": 36, "escap": 36, "assum": 36, "alik": 36, "vari": 36, "greatli": 36, "attack": 36, "presum": 36, "present": 36, "person": 36, "right": 36, "regardless": 36, "arrog": 36, "individu": 36, "bodi": 36, "domain": 36, "jcj": 36, "becom": [36, 40], "huh": 36, "whuzzat": 36, "muirm": 36, "maxwel": 36, "muir": 36, "candor": 36, "happi": 36, "proven": 36, "problem": 36, "broken": 36, "went": 36, "journei": 36, "lukewarm": 36, "agnostic": 36, "although": 36, "faith": 36, "jeff": 36, "johnson": 36, "9230769230769231": 37, "nntp": 37, "murder": 37, "7it": 38, "51": [38, 40, 42], "0010": 39, "8492442322991249": 39, "tensor": [39, 57, 58, 60, 62, 68, 71], "preprocess_func": [39, 59, 61, 75], "postprocess_func": 39, "state": [40, 44, 46, 50, 52], "gov": [40, 44, 46, 50, 52], "77516": [40, 44, 46, 50, 52], "bachelor": [40, 44, 46, 50, 52], "emp": [40, 44, 46, 50, 52], "inc": [40, 44, 46, 50, 52], "83311": [40, 44, 46, 50, 52], "38": [40, 44, 46, 50, 52], "privat": [40, 44, 46, 50, 52], "215646": [40, 44, 46, 50, 52], "234721": [40, 44, 46, 50, 52], "11th": [40, 44, 46, 50, 52], "338409": [40, 44, 46, 50, 52], "32556": [40, 44, 46, 50, 52], "257302": [40, 44, 46, 50, 52], "assoc": [40, 44, 46, 50, 52], "acdm": [40, 44, 46, 50, 52], "32557": [40, 44, 46, 50, 52], "40": [40, 44, 46, 50, 52], "154374": [40, 44, 46, 50, 52], "32558": [40, 44, 46, 50, 52], "58": [40, 44, 46, 50, 52], "151910": [40, 44, 46, 50, 52], "32559": [40, 44, 46, 50, 52], "201490": [40, 44, 46, 50, 52], "32560": [40, 44, 46, 50, 52], "52": [40, 44, 46, 50, 52, 53], "287927": [40, 44, 46, 50, 52], "marri": [40, 44, 46, 50, 52], "adm": [40, 44, 46, 50, 52], "cleric": [40, 44, 46, 50, 52], "white": [40, 44, 46, 50, 52], "civ": [40, 44, 46, 50, 52], "spous": [40, 44, 46, 50, 52], "exec": [40, 44, 46, 50, 52], "manageri": [40, 44, 46, 50, 52], "husband": [40, 44, 46, 50, 52], "divorc": [40, 44, 46, 50, 52], "handler": [40, 44, 46, 48, 50, 52], "prof": [40, 44, 46, 50, 52], "specialti": [40, 44, 46, 50, 52], "wife": [40, 44, 46, 50, 52], "op": [40, 44, 46, 50, 52], "inspct": [40, 44, 46, 50, 52], "widow": [40, 44, 46, 50, 52], "unmarri": [40, 44, 46, 50, 52], "child": [40, 44, 46, 50, 52], "2174": [40, 44, 46, 50, 52], "50k": [40, 44, 46, 50, 52], "cuba": [40, 44, 46, 50, 52], "15024": [40, 44, 46, 50, 52], "32561": [40, 44, 46, 50, 52], "lead": 40, "potenti": 40, "sociolog": 40, "bia": 40, "observ": 40, "strong": 40, "matrit": 40, "imbalanc": 40, "among": 40, "therefor": 40, "avoid": 40, "rough": 40, "educt": 40, "least": 40, "them": [40, 57, 63, 67, 70], "rel": 40, "low": 40, "12345": 40, "labels_train": [40, 43, 44, 46, 47, 50, 52], "labels_test": [40, 43, 44, 46, 47, 50, 52], "model_select": [40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53], "train_test_split": [40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53], "80": [40, 41, 43, 44, 46, 47, 49, 50, 52, 53], "accuracy_scor": [40, 41, 43, 44, 46, 47, 50, 52], "26048": [40, 41, 43, 44, 46, 47, 50, 52], "6513": [40, 41, 43, 44, 46, 47, 50, 52], "8593582066635959": 40, "describ": 40, "longer": [40, 75], "But": 40, "causal": 40, "caus": 40, "unclear": 40, "back": [40, 44, 48, 50, 52, 53], "1653": [40, 43, 44, 50, 51, 52], "1658": [40, 52], "ocup": 40, "train_label": [41, 59, 61, 73, 75], "test_label": [41, 59, 61, 73, 75], "108": [41, 43, 44, 46, 47, 50, 52], "8668816213726394": [41, 43, 44, 46, 47, 50, 52], "standardscal": 42, "diabetes_data": 42, "file_path": 42, "to_replac": 42, "No": 42, "polyuria": 42, "polydipsia": 42, "sudden": 42, "weak": 42, "polyphagia": 42, "genit": 42, "thrush": 42, "blur": 42, "itch": 42, "irrit": 42, "delai": 42, "heal": 42, "paresi": 42, "muscl": 42, "stiff": 42, "alopecia": 42, "obes": 42, "x_train_un": 42, "x_test_un": 42, "test_siz": 42, "stratifi": 42, "sc": 42, "fit_transform": 42, "train_tf_model": 42, "to_categor": [42, 59, 61, 75], "sequenti": [42, 59, 60, 61, 62, 73, 75], "softplu": 42, "schedul": 42, "exponentialdecai": 42, "initial_learning_r": 42, "decay_step": 42, "decay_r": 42, "99": [42, 48, 57, 58, 59, 60, 62, 73], "staircas": 42, "sgd": 42, "momentum": 42, "nesterov": 42, "categoricalcrossentropi": [42, 59, 61, 75], "compil": [42, 48, 59, 61, 63, 69, 72, 75], "train_loss": 42, "train_accuraci": 42, "test_loss": 42, "test_accuraci": 42, "4f": 42, "csv": [42, 48, 54, 55, 56], "416": 42, "104": 42, "0631": 42, "9856": [42, 59], "0568": 42, "9808": 42, "necessari": [43, 44, 46, 52, 53], "1953": 43, "8647768803169436": 43, "test_x": [43, 44, 45, 50, 51, 55, 56], "1655": [44, 50], "pprint": 45, "8518347919545525": 45, "fix": 46, "pdo": 47, "instal": [48, 69, 72], "ml4ir": 48, "ltr": 48, "order": 48, "document": [48, 73], "pointwis": 48, "listwis": 48, "record": 48, "infer": 48, "validityrankingexplain": 48, "singh": 48, "khosla": 48, "anand": 48, "2020": [48, 75], "2004": 48, "13972": 48, "upgrad": 48, "nbformat": 48, "df_train": 48, "file_0": 48, "head": 48, "query_id": 48, "query_text": 48, "text_match_scor": 48, "page_views_scor": 48, "quality_scor": 48, "click": 48, "domain_id": 48, "domain_nam": 48, "name_match": 48, "query_2": 48, "mhs7a7rjb1y4bjt": 48, "473730": 48, "000000": 48, "00000": 48, "domain_2": 48, "063190": 48, "205381": 48, "30103": 48, "query_5": 48, "knjnwv": 48, "368108": 48, "030636": 48, "domain_0": 48, "370628": 48, "041261": 48, "366700": 48, "082535": 48, "333836": 48, "042572": 48, "325021": 48, "046478": 48, "featureconfig": 48, "yaml": 48, "config": 48, "activate_2020": 48, "feature_config": 48, "tfrecord": 48, "usag": 48, "charact": 48, "bilstm": 48, "vocablookup": 48, "modelconfig": 48, "model_config": 48, "read": 48, "architecture_kei": 48, "dnn": 48, "first_dens": 48, "first_dropout": 48, "second_dens": 48, "final_dens": 48, "null": 48, "data_format": 48, "data_dir": 48, "execution_mod": 48, "train_inference_evalu": 48, "loss_kei": 48, "softmax_cross_entropi": 48, "models_dir": 48, "explain_demo_2022": 48, "logs_dir": 48, "log": 48, "run_id": 48, "activate_demo": 48, "readi": [48, 52, 53], "model_dir": 48, "local_io": 48, "localio": 48, "file_io": 48, "fileio": 48, "sequenceexamplefeatureconfig": 48, "relevance_model": 48, "relevancemodel": 48, "tfrecordtypekei": 48, "logger": 48, "getlogg": 48, "get_logg": 48, "setlevel": 48, "autograph": 48, "set_verbos": 48, "tf_cpp_min_log_level": 48, "get_inst": 48, "tfrecord_typ": 48, "sequence_exampl": 48, "feature_config_dict": 48, "read_yaml": 48, "get_train_featur": 48, "saniti": 48, "model_fil": 48, "final": 48, "output_nam": 48, "relevance_scor": 48, "is_compil": 48, "retrain": 48, "kmodel": 48, "load_model": 48, "infer_fn": 48, "signatur": 48, "serving_tfrecord": 48, "tfrecord_help": 48, "get_sequence_example_proto": 48, "features_df": 48, "fillna": 48, "renam": [48, 54, 55, 56], "serving_info": 48, "context_featur": 48, "sequence_featur": 48, "context_feature_nam": 48, "proto": 48, "groupbi": 48, "ranking_scor": 48, "se": 48, "constant": 48, "serializetostr": 48, "predicted_scor": 48, "reset_index": 48, "362720": 48, "tlaud": 48, "venv": 48, "lib": [48, 69, 72, 75], "python3": [48, 69, 72, 75], "site": [48, 69, 72, 75], "ipykernel_launch": 48, "settingwithcopywarn": 48, "loc": 48, "row_index": 48, "col_index": 48, "caveat": 48, "pydata": 48, "user_guid": 48, "versu": 48, "cwd": 48, "sy": 48, "11998416": 48, "19389412": 48, "20375773": 48, "17943792": 48, "11195529": 48, "1909707": 48, "5671": 48, "query_1487": 48, "qcz4xhln": 48, "227694": 48, "5672": 48, "016954": 48, "5673": 48, "query_1490": 48, "wynff89": 48, "474600": 48, "190735": 48, "5674": 48, "620355": 48, "143310": 48, "5675": 48, "508362": 48, "5676": 48, "similarli": 48, "sample_queri": 48, "wish": 48, "trainabl": 48, "ranking_explain": 48, "21": [48, 53], "23": [48, 53], "top_featur": 48, "dict_kei": 48, "kendalltauresult": 48, "9999999999999999": 48, "pvalu": 48, "002777777777777778": 48, "kendal": 48, "grade": 48, "fig": 48, "ipython_figur": 48, "update_layout": 48, "autos": 48, "1800": 48, "load_boston": 49, "rf": [49, 53], "randomforestregressor": [49, 53], "mserror": [49, 53], "404": 49, "102": 49, "215751067843145": 49, "8446184553968985": 51, "some_transform": [52, 53], "fetch_california_h": 53, "medinc": 53, "houseag": 53, "averoom": 53, "avebedrm": 53, "aveoccup": 53, "latitud": 53, "3252": 53, "41": 53, "984127": 53, "023810": 53, "322": 53, "555556": 53, "37": 53, "88": 53, "3014": 53, "238137": 53, "971880": 53, "2401": 53, "109842": 53, "86": 53, "2574": 53, "288136": 53, "073446": 53, "496": 53, "802260": 53, "85": 53, "6431": 53, "817352": 53, "073059": 53, "558": 53, "547945": 53, "8462": 53, "281853": 53, "081081": 53, "565": 53, "181467": 53, "20635": 53, "5603": 53, "045455": 53, "133333": 53, "845": 53, "560606": 53, "48": [53, 63], "20636": 53, "5568": 53, "114035": 53, "315789": 53, "356": 53, "122807": 53, "49": 53, "20637": 53, "7000": 53, "205543": 53, "120092": 53, "1007": 53, "325635": 53, "43": 53, "20638": 53, "8672": 53, "329513": 53, "171920": 53, "741": 53, "123209": 53, "20639": 53, "3886": 53, "254717": 53, "162264": 53, "1387": 53, "616981": 53, "longitud": 53, "122": 53, "526": 53, "585": 53, "24": 53, "521": 53, "413": 53, "422": 53, "121": 53, "09": [53, 63], "781": 53, "771": 53, "923": 53, "847": 53, "894": 53, "20640": 53, "16512": 53, "4128": 53, "3075597163231951": 53, "24209091231809937": 53, "sythent": [54, 55, 56], "horizont": [54, 55, 56], "1970": [54, 55, 56], "928031": [54, 55, 56], "05": [54, 55, 56], "156620": [54, 55, 56], "390650": [54, 55, 56], "400804": [54, 55, 56], "874490": [54, 55, 56], "02": [54, 55, 56], "04": [54, 55, 56], "55": [54, 55, 56], "362724": [54, 55, 56], "657373": [54, 55, 56], "472341": [54, 55, 56], "033154": [54, 55, 56], "950466": [54, 55, 56], "9150": [54, 55, 56], "9300": [54, 55, 56], "percentil": [54, 55, 56], "90": [54, 55, 56], "anomaly_scor": [54, 55, 56], "sum": [54, 55, 56, 69, 72], "98": [54, 55, 60, 62, 73], "json": [57, 58, 67, 68, 70, 71, 74], "img_1": 57, "dog_cat": [57, 64, 71, 74], "img_2": 57, "img_3": 57, "visul": 57, "imagenet_class_index": [57, 58, 67, 68, 70, 71, 74], "read_fil": [57, 58, 67, 68, 70, 71, 74], "class_idx": [57, 58, 67, 68, 70, 71, 74], "sent": 57, "purpos": 58, "pyplot": [59, 60, 61, 62, 75], "plt": [59, 60, 61, 62, 75], "img_row": [59, 61, 75], "img_col": [59, 61, 75], "load_data": [59, 61, 75], "backend": [59, 61, 75], "image_data_format": [59, 61, 75], "channels_first": [59, 61, 75], "input_shap": [59, 61, 75], "train_img": [59, 61, 73, 75], "conv2d": [59, 60, 61, 62, 73, 75], "maxpooling2d": [59, 61, 75], "pool_siz": [59, 61, 75], "flatten": [59, 60, 61, 62, 73, 75], "validation_data": [59, 61, 75], "469": [59, 61, 75], "5m": [59, 61, 75], "1696": 59, "9492": 59, "val_loss": [59, 61, 75], "0436": 59, "val_accuraci": [59, 61, 75], "9855": [59, 75], "0478": 59, "0352": 59, "9882": 59, "0324": 59, "9896": [59, 61], "0315": 59, "9892": [59, 61], "0223": 59, "9929": 59, "0320": 59, "9887": [59, 61], "0179": 59, "9940": 59, "0314": 59, "9901": 59, "0141": 59, "9952": 59, "0365": 59, "9888": 59, "0113": 59, "9960": 59, "9903": [59, 75], "0109": [59, 61, 75], "9965": 59, "0297": [59, 61], "9918": 59, "0083": 59, "9972": 59, "0337": 59, "0072": [59, 75], "9976": 59, "0382": 59, "9895": [59, 61], "03824701905250549": 59, "9894999861717224": 59, "__len__": [60, 62, 73], "__getitem__": [60, 62, 73], "mnistnet": [60, 62, 73], "maxpool2d": [60, 62, 73], "fc_layer": [60, 62, 73], "320": [60, 62, 73], "train_load": [60, 62, 73], "test_load": [60, 62, 73], "lr": [60, 62, 73], "zero_grad": [60, 62, 73], "backward": [60, 62, 73], "correct_pr": [60, 62, 73], "total_pr": [60, 62, 73], "_": [60, 62, 73], "correct_count": [60, 62, 73], "1f": [60, 62, 73], "97": [60, 62], "1712": 61, "9493": 61, "0509": 61, "9837": 61, "0467": 61, "9857": 61, "0364": 61, "9880": 61, "0331": 61, "0323": [61, 75], "9884": 61, "0226": 61, "9927": 61, "0345": 61, "9890": 61, "0171": 61, "9942": 61, "0371": 61, "0150": 61, "9949": [61, 75], "9906": [61, 75], "9966": 61, "0428": 61, "0101": 61, "9967": 61, "0356": 61, "0086": 61, "9969": 61, "0393": 61, "0065": [61, 75], "9977": 61, "0399": 61, "9898": 61, "03988948091864586": 61, "989799976348877": 61, "vgg16": [63, 65, 66], "feature_visu": [63, 64, 65, 66], "featuremapvisu": [63, 64], "dog_cat_2": [63, 67, 70], "img_to_arrai": [63, 67, 70], "preprocess_input": [63, 67, 70], "2022": 63, "08": 63, "038022": 63, "core": 63, "platform": 63, "cpu_feature_guard": 63, "cc": 63, "193": 63, "oneapi": 63, "onednn": 63, "instruct": [63, 75], "critic": 63, "oper": 63, "avx2": 63, "fma": 63, "enabl": 63, "rebuild": 63, "flag": 63, "vgg": 64, "deprec": [64, 75], "sinc": [64, 73], "enum": 64, "equival": 64, "pass": [64, 75], "resnet50_weight": 64, "imagenet1k_v1": 64, "layer2": 64, "neuron": [65, 66], "direct": [65, 66], "visit": [65, 66], "distil": [65, 66], "pub": [65, 66], "featurevisu": [65, 66], "maxim": [65, 66], "mobilenet_v2": [67, 70], "mobilenetv2": [67, 70], "include_top": [67, 70], "input_img": [67, 74], "top_indic": [67, 70], "argsort": [67, 70], "243": [67, 70], "242": [67, 70], "boxer": [67, 70], "282": [67, 70], "tabbi": [67, 70], "292": [67, 70], "tiger": [67, 70], "lavi": [69, 72], "releas": [69, 72], "soon": [69, 72], "multi_input": [69, 72], "multiinput": [69, 72], "vision_languag": [69, 72], "blipitm": [69, 72], "load_processor": [69, 72], "anaconda3": [69, 72, 75], "env": [69, 72], "conda_env_py3": [69, 72], "userwarn": [69, 72], "nvidia": [69, 72], "driver": [69, 72], "system": [69, 72], "old": [69, 72, 73], "10010": [69, 72], "updat": [69, 72, 75], "gpu": [69, 72], "url": [69, 72], "aspx": [69, 72], "altern": [69, 72], "trigger": [69, 72], "intern": [69, 72], "c10": [69, 72], "cudafunct": [69, 72], "cpp": [69, 72], "109": [69, 72], "480": [69, 72], "girl_dog": [69, 72], "girl": [69, 72], "plai": [69, 72], "her": [69, 72], "beach": [69, 72], "blip": [69, 72], "pretrained_path": [69, 72], "storag": [69, 72], "googleapi": [69, 72], "sfr": [69, 72], "model_base_retrieval_coco": [69, 72], "pth": [69, 72], "vit": [69, 72], "image_processor": [69, 72], "blip_image_ev": [69, 72], "image_s": [69, 72], "384": [69, 72], "text_processor": [69, 72], "blip_capt": [69, 72], "init_token": [69, 72], "text_encod": [69, 72], "base_model": 69, "crossattent": 69, "attention_probs_lay": 69, "inception_v3": [71, 74], "word_embed": 72, "cl": 72, "96": 73, "align_corn": 73, "2665": 73, "8901166666666667": 73, "incept": 74, "probs_top_5": 74, "topk": 74, "93592954": 74, "239": [74, 75], "bernese_mountain_dog": 74, "038448237": 74, "241": 74, "entlebuch": 74, "023756476": 74, "appenzel": 74, "0018181928": 74, "238": 74, "greater_swiss_mountain_dog": 74, "113302e": 74, "06": 74, "214": 74, "gordon_sett": 74, "batch_predict": 74, "prob": 74, "hide_color": 74, "1724": 75, "9487": 75, "0458": 75, "0466": 75, "9852": 75, "0333": 75, "9885": 75, "0298": 75, "9891": 75, "0207": 75, "9933": 75, "0286": 75, "0158": 75, "0295": 75, "9907": 75, "0125": 75, "9962": 75, "0290": 75, "9904": 75, "9963": 75, "0283": 75, "9902": 75, "0090": 75, "9970": 75, "9978": 75, "0317": 75, "9912": 75, "9974": 75, "0359": 75, "9915": 75, "03591015189886093": 75, "9915000200271606": 75, "_deep": 75, "deep_tf": 75, "set_learning_phas": 75, "__call__": 75}, "objects": {"": [[1, 0, 0, "-", "omnixai"]], "omnixai": [[2, 0, 0, "-", "data"], [3, 0, 0, "-", "explainers"], [20, 0, 0, "-", "explanations"], [25, 0, 0, "-", "preprocessing"], [26, 0, 0, "-", "visualization"]], "omnixai.data": [[2, 0, 0, "-", "base"], [2, 0, 0, "-", "image"], [2, 0, 0, "-", "tabular"], [2, 0, 0, "-", "text"], [2, 0, 0, "-", "timeseries"]], "omnixai.data.base": [[2, 1, 1, "", "Data"]], "omnixai.data.base.Data": [[2, 2, 1, "", "data_type"], [2, 3, 1, "", "values"]], "omnixai.data.image": [[2, 1, 1, "", "Image"]], "omnixai.data.image.Image": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "image_shape"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pil"], [2, 2, 1, "", "values"]], "omnixai.data.tabular": [[2, 1, 1, "", "Tabular"]], "omnixai.data.tabular.Tabular": [[2, 2, 1, "", "categorical_columns"], [2, 2, 1, "", "columns"], [2, 2, 1, "", "continuous_columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "feature_columns"], [2, 3, 1, "", "get_continuous_bounds"], [2, 3, 1, "", "get_continuous_medians"], [2, 3, 1, "", "iloc"], [2, 3, 1, "", "remove_target_column"], [2, 2, 1, "", "shape"], [2, 2, 1, "", "target_column"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "values"]], "omnixai.data.text": [[2, 1, 1, "", "Text"]], "omnixai.data.text.Text": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "split"], [2, 3, 1, "", "to_str"], [2, 3, 1, "", "to_tokens"], [2, 2, 1, "", "values"]], "omnixai.data.timeseries": [[2, 1, 1, "", "Timeseries"]], "omnixai.data.timeseries.Timeseries": [[2, 2, 1, "", "batch_size"], [2, 2, 1, "", "columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "from_pd"], [2, 2, 1, "", "index"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "ts_len"], [2, 2, 1, "", "values"]], "omnixai.explainers": [[3, 0, 0, "-", "base"], [4, 0, 0, "-", "data"]], "omnixai.explainers.base": [[3, 1, 1, "", "AutoExplainerBase"], [3, 1, 1, "", "ExplainerABCMeta"], [3, 1, 1, "", "ExplainerBase"]], "omnixai.explainers.base.AutoExplainerBase": [[3, 3, 1, "", "explain"], [3, 3, 1, "", "explain_global"], [3, 2, 1, "", "explainer_names"], [3, 3, 1, "", "list_explainers"]], "omnixai.explainers.base.ExplainerBase": [[3, 3, 1, "", "explain"], [3, 2, 1, "", "explanation_type"]], "omnixai.explainers.data": [[4, 1, 1, "", "ChiSquare"], [4, 1, 1, "", "CorrelationAnalyzer"], [4, 1, 1, "", "DataAnalyzer"], [4, 1, 1, "", "ImbalanceAnalyzer"], [4, 1, 1, "", "MutualInformation"], [4, 0, 0, "-", "auto"], [4, 0, 0, "-", "chi_square"], [4, 0, 0, "-", "correlation"], [4, 0, 0, "-", "imbalance"], [4, 0, 0, "-", "mutual_info"]], "omnixai.explainers.data.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.DataAnalyzer": [[4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.auto": [[4, 1, 1, "", "DataAnalyzer"]], "omnixai.explainers.data.auto.DataAnalyzer": [[4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.chi_square": [[4, 1, 1, "", "ChiSquare"]], "omnixai.explainers.data.chi_square.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.correlation": [[4, 1, 1, "", "CorrelationAnalyzer"]], "omnixai.explainers.data.correlation.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.imbalance": [[4, 1, 1, "", "ImbalanceAnalyzer"]], "omnixai.explainers.data.imbalance.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.mutual_info": [[4, 1, 1, "", "MutualInformation"]], "omnixai.explainers.data.mutual_info.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp": [[6, 0, 0, "-", "agnostic"], [5, 0, 0, "-", "auto"], [7, 0, 0, "-", "counterfactual"], [8, 0, 0, "-", "specific"]], "omnixai.explainers.nlp.agnostic": [[6, 0, 0, "-", "l2x"], [6, 0, 0, "-", "lime"], [6, 0, 0, "-", "shap"]], "omnixai.explainers.nlp.agnostic.l2x": [[6, 1, 1, "", "DefaultPredictionModel"], [6, 1, 1, "", "DefaultSelectionModel"], [6, 1, 1, "", "L2XText"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultPredictionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultSelectionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.L2XText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.lime": [[6, 1, 1, "", "LimeText"]], "omnixai.explainers.nlp.agnostic.lime.LimeText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.shap": [[6, 1, 1, "", "ShapText"]], "omnixai.explainers.nlp.agnostic.shap.ShapText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.auto": [[5, 1, 1, "", "NLPExplainer"]], "omnixai.explainers.nlp.auto.NLPExplainer": [[5, 3, 1, "", "list_explainers"]], "omnixai.explainers.nlp.counterfactual": [[7, 0, 0, "-", "polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice": [[7, 1, 1, "", "Polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice.Polyjuice": [[7, 4, 1, "", "alias"], [7, 3, 1, "", "explain"], [7, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.specific": [[8, 0, 0, "-", "ig"]], "omnixai.explainers.nlp.specific.ig": [[8, 1, 1, "", "IntegratedGradientText"]], "omnixai.explainers.nlp.specific.ig.IntegratedGradientText": [[8, 4, 1, "", "alias"], [8, 3, 1, "", "explain"], [8, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular": [[10, 0, 0, "-", "agnostic"], [9, 0, 0, "-", "auto"], [9, 0, 0, "-", "base"], [11, 0, 0, "-", "counterfactual"], [12, 0, 0, "-", "specific"]], "omnixai.explainers.tabular.agnostic.L2X": [[10, 0, 0, "-", "l2x"]], "omnixai.explainers.tabular.agnostic.L2X.l2x": [[10, 1, 1, "", "DefaultPredictionModel"], [10, 1, 1, "", "DefaultSelectionModel"], [10, 1, 1, "", "L2XTabular"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultPredictionModel": [[10, 3, 1, "", "forward"], [10, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultSelectionModel": [[10, 3, 1, "", "forward"], [10, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.L2XTabular": [[10, 4, 1, "", "alias"], [10, 3, 1, "", "explain"], [10, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic": [[10, 0, 0, "-", "lime"], [10, 0, 0, "-", "pdp"], [10, 0, 0, "-", "sensitivity"], [10, 0, 0, "-", "shap"]], "omnixai.explainers.tabular.agnostic.lime": [[10, 1, 1, "", "LimeTabular"]], "omnixai.explainers.tabular.agnostic.lime.LimeTabular": [[10, 4, 1, "", "alias"], [10, 3, 1, "", "explain"], [10, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.pdp": [[10, 1, 1, "", "PartialDependenceTabular"]], "omnixai.explainers.tabular.agnostic.pdp.PartialDependenceTabular": [[10, 4, 1, "", "alias"], [10, 3, 1, "", "explain"], [10, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.sensitivity": [[10, 1, 1, "", "SensitivityAnalysisTabular"]], "omnixai.explainers.tabular.agnostic.sensitivity.SensitivityAnalysisTabular": [[10, 4, 1, "", "alias"], [10, 3, 1, "", "explain"], [10, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.shap": [[10, 1, 1, "", "ShapTabular"]], "omnixai.explainers.tabular.agnostic.shap.ShapTabular": [[10, 4, 1, "", "alias"], [10, 3, 1, "", "explain"], [10, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.auto": [[9, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.auto.TabularExplainer": [[9, 3, 1, "", "list_explainers"]], "omnixai.explainers.tabular.base": [[9, 1, 1, "", "SklearnBase"], [9, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.base.SklearnBase": [[9, 3, 1, "", "class_names"], [9, 3, 1, "", "fit"], [9, 3, 1, "", "predict"], [9, 3, 1, "", "predict_proba"]], "omnixai.explainers.tabular.counterfactual": [[11, 0, 0, "-", "ce"]], "omnixai.explainers.tabular.counterfactual.ce": [[11, 1, 1, "", "CounterfactualExplainer"], [11, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualExplainer": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualOptimizer": [[11, 3, 1, "", "optimize"]], "omnixai.explainers.tabular.counterfactual.mace": [[11, 0, 0, "-", "mace"]], "omnixai.explainers.tabular.counterfactual.mace.mace": [[11, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.tabular.counterfactual.mace.mace.MACEExplainer": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific": [[12, 0, 0, "-", "decision_tree"], [12, 0, 0, "-", "ig"], [12, 0, 0, "-", "linear"], [12, 0, 0, "-", "shap_tree"]], "omnixai.explainers.tabular.specific.decision_tree": [[12, 1, 1, "", "TreeBase"], [12, 1, 1, "", "TreeClassifier"], [12, 1, 1, "", "TreeRegressor"]], "omnixai.explainers.tabular.specific.decision_tree.TreeBase": [[12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"], [12, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.decision_tree.TreeClassifier": [[12, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.decision_tree.TreeRegressor": [[12, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.ig": [[12, 1, 1, "", "IntegratedGradient"], [12, 1, 1, "", "IntegratedGradientTabular"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradient": [[12, 3, 1, "", "compute_integrated_gradients"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradientTabular": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific.linear": [[12, 1, 1, "", "LinearBase"], [12, 1, 1, "", "LinearRegression"], [12, 1, 1, "", "LogisticRegression"]], "omnixai.explainers.tabular.specific.linear.LinearBase": [[12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"], [12, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.linear.LinearRegression": [[12, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.linear.LogisticRegression": [[12, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.shap_tree": [[12, 1, 1, "", "ShapTreeTabular"]], "omnixai.explainers.tabular.specific.shap_tree.ShapTreeTabular": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"], [12, 3, 1, "", "fit"]], "omnixai.explainers.timeseries": [[14, 0, 0, "-", "agnostic"], [13, 0, 0, "-", "auto"], [15, 0, 0, "-", "counterfactual"]], "omnixai.explainers.timeseries.agnostic": [[14, 0, 0, "-", "shap"]], "omnixai.explainers.timeseries.agnostic.shap": [[14, 1, 1, "", "ShapTimeseries"]], "omnixai.explainers.timeseries.agnostic.shap.ShapTimeseries": [[14, 4, 1, "", "alias"], [14, 3, 1, "", "explain"], [14, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.auto": [[13, 1, 1, "", "TimeseriesExplainer"]], "omnixai.explainers.timeseries.auto.TimeseriesExplainer": [[13, 3, 1, "", "list_explainers"]], "omnixai.explainers.timeseries.counterfactual": [[15, 0, 0, "-", "ce"], [15, 0, 0, "-", "mace"]], "omnixai.explainers.timeseries.counterfactual.ce": [[15, 1, 1, "", "CounterfactualExplainer"], [15, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualExplainer": [[15, 4, 1, "", "alias"], [15, 3, 1, "", "explain"], [15, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualOptimizer": [[15, 3, 1, "", "optimize"]], "omnixai.explainers.timeseries.counterfactual.mace": [[15, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.timeseries.counterfactual.mace.MACEExplainer": [[15, 4, 1, "", "alias"], [15, 3, 1, "", "explain"], [15, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision": [[17, 0, 0, "-", "agnostic"], [16, 0, 0, "-", "auto"], [18, 0, 0, "-", "counterfactual"], [19, 0, 0, "-", "specific"]], "omnixai.explainers.vision.agnostic": [[17, 0, 0, "-", "l2x"], [17, 0, 0, "-", "lime"], [17, 0, 0, "-", "pdp"], [17, 0, 0, "-", "shap"]], "omnixai.explainers.vision.agnostic.l2x": [[17, 1, 1, "", "DefaultPredictionModel"], [17, 1, 1, "", "DefaultSelectionModel"], [17, 1, 1, "", "L2XImage"]], "omnixai.explainers.vision.agnostic.l2x.DefaultPredictionModel": [[17, 3, 1, "", "forward"], [17, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.DefaultSelectionModel": [[17, 3, 1, "", "forward"], [17, 3, 1, "", "postprocess"], [17, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.L2XImage": [[17, 4, 1, "", "alias"], [17, 3, 1, "", "explain"], [17, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.lime": [[17, 1, 1, "", "LimeImage"]], "omnixai.explainers.vision.agnostic.lime.LimeImage": [[17, 4, 1, "", "alias"], [17, 3, 1, "", "explain"], [17, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.pdp": [[17, 1, 1, "", "PartialDependenceImage"]], "omnixai.explainers.vision.agnostic.pdp.PartialDependenceImage": [[17, 4, 1, "", "alias"], [17, 3, 1, "", "explain"], [17, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.shap": [[17, 1, 1, "", "ShapImage"]], "omnixai.explainers.vision.agnostic.shap.ShapImage": [[17, 4, 1, "", "alias"], [17, 3, 1, "", "explain"], [17, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.auto": [[16, 1, 1, "", "VisionExplainer"]], "omnixai.explainers.vision.auto.VisionExplainer": [[16, 3, 1, "", "list_explainers"]], "omnixai.explainers.vision.counterfactual": [[18, 0, 0, "-", "ce"]], "omnixai.explainers.vision.counterfactual.ce": [[18, 1, 1, "", "CounterfactualExplainer"]], "omnixai.explainers.vision.counterfactual.ce.CounterfactualExplainer": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific": [[19, 0, 0, "-", "cem"], [19, 0, 0, "-", "ig"]], "omnixai.explainers.vision.specific.cem": [[19, 1, 1, "", "CEMOptimizer"], [19, 1, 1, "", "ContrastiveExplainer"]], "omnixai.explainers.vision.specific.cem.CEMOptimizer": [[19, 3, 1, "", "pn_optimize"], [19, 3, 1, "", "pp_optimize"]], "omnixai.explainers.vision.specific.cem.ContrastiveExplainer": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam": [[19, 0, 0, "-", "gradcam"]], "omnixai.explainers.vision.specific.gradcam.gradcam": [[19, 1, 1, "", "GradCAM"], [19, 1, 1, "", "GradCAMPlus"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAM": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAMPlus": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.ig": [[19, 1, 1, "", "IntegratedGradientImage"]], "omnixai.explainers.vision.specific.ig.IntegratedGradientImage": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explanations": [[20, 0, 0, "-", "base"], [21, 0, 0, "-", "image"], [22, 0, 0, "-", "tabular"], [23, 0, 0, "-", "text"], [24, 0, 0, "-", "timeseries"]], "omnixai.explanations.base": [[20, 1, 1, "", "DashFigure"], [20, 1, 1, "", "ExplanationBase"], [20, 1, 1, "", "PredictedResults"]], "omnixai.explanations.base.DashFigure": [[20, 3, 1, "", "show"], [20, 3, 1, "", "to_html"], [20, 3, 1, "", "to_html_div"]], "omnixai.explanations.base.ExplanationBase": [[20, 3, 1, "", "get_explanations"], [20, 3, 1, "", "ipython_plot"], [20, 3, 1, "", "plot"], [20, 3, 1, "", "plotly_plot"]], "omnixai.explanations.base.PredictedResults": [[20, 3, 1, "", "get_explanations"], [20, 3, 1, "", "ipython_plot"], [20, 3, 1, "", "plot"], [20, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image": [[21, 0, 0, "-", "contrast"], [21, 0, 0, "-", "counterfactual"], [21, 0, 0, "-", "mask"], [21, 0, 0, "-", "pixel_importance"]], "omnixai.explanations.image.contrast": [[21, 1, 1, "", "ContrastiveExplanation"]], "omnixai.explanations.image.contrast.ContrastiveExplanation": [[21, 3, 1, "", "add"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.counterfactual": [[21, 1, 1, "", "CFExplanation"]], "omnixai.explanations.image.counterfactual.CFExplanation": [[21, 3, 1, "", "add"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.mask": [[21, 1, 1, "", "MaskExplanation"]], "omnixai.explanations.image.mask.MaskExplanation": [[21, 3, 1, "", "add"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.pixel_importance": [[21, 1, 1, "", "PixelImportance"]], "omnixai.explanations.image.pixel_importance.PixelImportance": [[21, 3, 1, "", "add"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular": [[22, 0, 0, "-", "correlation"], [22, 0, 0, "-", "counterfactual"], [22, 0, 0, "-", "feature_importance"], [22, 0, 0, "-", "imbalance"], [22, 0, 0, "-", "linear"], [22, 0, 0, "-", "pdp"], [22, 0, 0, "-", "sensitivity"], [22, 0, 0, "-", "tree"]], "omnixai.explanations.tabular.correlation": [[22, 1, 1, "", "CorrelationExplanation"]], "omnixai.explanations.tabular.correlation.CorrelationExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.counterfactual": [[22, 1, 1, "", "CFExplanation"]], "omnixai.explanations.tabular.counterfactual.CFExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance": [[22, 1, 1, "", "FeatureImportance"], [22, 1, 1, "", "GlobalFeatureImportance"]], "omnixai.explanations.tabular.feature_importance.FeatureImportance": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance.GlobalFeatureImportance": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.imbalance": [[22, 1, 1, "", "ImbalanceExplanation"]], "omnixai.explanations.tabular.imbalance.ImbalanceExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.linear": [[22, 1, 1, "", "LinearExplanation"]], "omnixai.explanations.tabular.linear.LinearExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.pdp": [[22, 1, 1, "", "PDPExplanation"]], "omnixai.explanations.tabular.pdp.PDPExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.sensitivity": [[22, 1, 1, "", "SensitivityExplanation"]], "omnixai.explanations.tabular.sensitivity.SensitivityExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.tree": [[22, 1, 1, "", "TreeExplanation"]], "omnixai.explanations.tabular.tree.TreeExplanation": [[22, 3, 1, "", "add_global"], [22, 3, 1, "", "add_local"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.text": [[23, 0, 0, "-", "word_importance"]], "omnixai.explanations.text.word_importance": [[23, 1, 1, "", "WordImportance"]], "omnixai.explanations.text.word_importance.WordImportance": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries": [[24, 0, 0, "-", "counterfactual"], [24, 0, 0, "-", "feature_importance"]], "omnixai.explanations.timeseries.counterfactual": [[24, 1, 1, "", "CFExplanation"]], "omnixai.explanations.timeseries.counterfactual.CFExplanation": [[24, 3, 1, "", "add"], [24, 3, 1, "", "get_explanations"], [24, 3, 1, "", "ipython_plot"], [24, 3, 1, "", "plot"], [24, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries.feature_importance": [[24, 1, 1, "", "FeatureImportance"]], "omnixai.explanations.timeseries.feature_importance.FeatureImportance": [[24, 3, 1, "", "add"], [24, 3, 1, "", "get_explanations"], [24, 3, 1, "", "ipython_plot"], [24, 3, 1, "", "plot"], [24, 3, 1, "", "plotly_plot"]], "omnixai.preprocessing": [[25, 0, 0, "-", "base"], [25, 0, 0, "-", "encode"], [25, 0, 0, "-", "fill"], [25, 0, 0, "-", "image"], [25, 0, 0, "-", "normalize"], [25, 0, 0, "-", "pipeline"], [25, 0, 0, "-", "tabular"], [25, 0, 0, "-", "text"]], "omnixai.preprocessing.base": [[25, 1, 1, "", "Identity"], [25, 1, 1, "", "TransformBase"]], "omnixai.preprocessing.base.Identity": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.base.TransformBase": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.encode": [[25, 1, 1, "", "KBins"], [25, 1, 1, "", "LabelEncoder"], [25, 1, 1, "", "OneHot"], [25, 1, 1, "", "Ordinal"]], "omnixai.preprocessing.encode.KBins": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.LabelEncoder": [[25, 2, 1, "", "categories"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.OneHot": [[25, 2, 1, "", "categories"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "get_feature_names"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.Ordinal": [[25, 2, 1, "", "categories"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.fill": [[25, 1, 1, "", "FillNaN"], [25, 1, 1, "", "FillNaNTabular"]], "omnixai.preprocessing.fill.FillNaN": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.fill.FillNaNTabular": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.image": [[25, 1, 1, "", "Normalize"], [25, 1, 1, "", "Resize"], [25, 1, 1, "", "Round2Int"], [25, 1, 1, "", "Scale"]], "omnixai.preprocessing.image.Normalize": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Resize": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Round2Int": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Scale": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize": [[25, 1, 1, "", "MinMax"], [25, 1, 1, "", "Scale"], [25, 1, 1, "", "Standard"]], "omnixai.preprocessing.normalize.MinMax": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Scale": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Standard": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.pipeline": [[25, 1, 1, "", "Pipeline"]], "omnixai.preprocessing.pipeline.Pipeline": [[25, 3, 1, "", "dump"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "load"], [25, 4, 1, "", "name"], [25, 3, 1, "", "step"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.tabular": [[25, 1, 1, "", "TabularTransform"]], "omnixai.preprocessing.tabular.TabularTransform": [[25, 2, 1, "", "categories"], [25, 2, 1, "", "class_names"], [25, 3, 1, "", "decompose"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "get_feature_names"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.text": [[25, 1, 1, "", "Tfidf"], [25, 1, 1, "", "Word2Id"]], "omnixai.preprocessing.text.Tfidf": [[25, 3, 1, "", "fit"], [25, 3, 1, "", "get_feature_names"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"]], "omnixai.preprocessing.text.Word2Id": [[25, 4, 1, "", "PAD"], [25, 4, 1, "", "START"], [25, 4, 1, "", "UNK"], [25, 3, 1, "", "fit"], [25, 3, 1, "", "invert"], [25, 3, 1, "", "transform"], [25, 2, 1, "", "vocab_size"]], "omnixai.sampler": [[25, 0, 0, "-", "tabular"]], "omnixai.sampler.tabular": [[25, 1, 1, "", "Sampler"]], "omnixai.sampler.tabular.Sampler": [[25, 3, 1, "", "oversample"], [25, 3, 1, "", "subsample"], [25, 3, 1, "", "undersample"]], "omnixai.visualization": [[26, 0, 0, "-", "dashboard"]], "omnixai.visualization.dashboard": [[26, 1, 1, "", "Dashboard"]], "omnixai.visualization.dashboard.Dashboard": [[26, 3, 1, "", "show"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"welcom": 0, "omnixai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 40], "": 0, "document": 0, "introduct": [0, 1], "capabl": 0, "featur": [0, 28, 63, 64, 65, 66], "comparison": 0, "competitor": 0, "instal": [0, 1], "get": [0, 1], "start": [0, 1], "how": [0, 1], "contribut": [0, 1], "content": 0, "indic": 0, "tabl": 0, "an": 1, "explan": [1, 20, 21, 22, 23, 24, 32, 33, 42, 46, 48, 55, 58, 59, 60, 61, 62], "toolbox": 1, "librari": 1, "design": 1, "more": 1, "exampl": [1, 27, 29, 30], "modul": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "differ": [1, 3], "data": [1, 2, 4, 29, 30], "type": 1, "preprocess": [1, 25, 30], "function": 1, "support": 1, "method": 1, "result": [1, 20], "dashboard": [1, 26], "visual": [1, 26, 63, 64, 65, 66, 69, 72], "packag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "base": [2, 3, 9, 20, 25], "tabular": [2, 9, 10, 11, 12, 22, 25, 27, 29, 30], "imag": [2, 21, 25, 29, 30, 57, 67, 68, 70, 71, 74], "text": [2, 23, 25, 29, 30, 32, 36, 37], "timeseri": [2, 13, 14, 15, 24, 27], "explain": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 27, 36, 43, 73], "task": [3, 69, 72], "auto": [4, 5, 9, 13, 16], "correl": [4, 22], "imbal": [4, 22], "mutual_info": 4, "chi_squar": 4, "nlp": [5, 6, 7, 8, 27], "subpackag": [5, 9, 13, 16], "agnost": [6, 10, 14, 17], "lime": [6, 10, 17, 37, 44, 74], "shap": [6, 10, 14, 17, 38, 50, 56, 75], "l2x": [6, 10, 17, 36, 43, 73], "counterfactu": [7, 11, 15, 18, 21, 22, 24, 32, 33, 42, 46, 55, 58, 59, 60], "polyjuic": 7, "specif": [8, 12, 19], "ig": [8, 12, 19], "pdp": [10, 17, 22], "sensit": [10, 22, 49], "mace": [11, 15, 46], "ce": [11, 15, 18], "linear": [12, 22], "decision_tre": 12, "shap_tre": 12, "vision": [16, 17, 18, 19, 27], "gradcam": 19, "cem": 19, "three": 20, "categori": 20, "pixel_import": 21, "mask": 21, "contrast": [21, 61, 62], "feature_import": [22, 24], "tree": [22, 51], "word_import": 23, "encod": 25, "normal": 25, "fill": 25, "pipelin": 25, "sampler": 25, "tutori": 27, "code": 27, "basic": 27, "applic": 27, "dataanalyz": 28, "analysi": [28, 31, 38, 49], "object": 29, "time": [29, 54, 55, 56], "seri": [29, 54, 55, 56], "nlpexplain": [31, 39], "sentiment": [31, 38], "classif": [32, 36, 37, 52, 57, 67, 68, 70, 71, 74], "question": 33, "answer": 33, "integr": [34, 35, 70, 71, 72], "gradient": [34, 35, 70, 71, 72], "imdb": [34, 35, 39], "dataset": [34, 35, 39, 42], "tensorflow": [34, 59, 61, 63, 65, 67, 70], "pytorch": [35, 60, 62, 64, 66, 68, 71], "learn": [36, 43, 48, 73], "ml": 40, "workflow": 40, "accumul": 41, "local": 41, "effect": 41, "al": 41, "diabet": 42, "incom": [43, 44, 45, 46, 50, 51, 52], "predict": [43, 44, 45, 46, 50, 51, 52, 53], "logist": 45, "regress": [45, 53], "pariti": 47, "depend": 47, "plot": 47, "rank": 48, "expan": 48, "demo": 48, "kei": 48, "takeawai": 48, "per": 48, "queri": 48, "valid": 48, "morri": 49, "decis": 51, "tabularexplain": [52, 53], "hous": 53, "price": 53, "timeseriesexplain": 54, "anomali": [54, 55, 56], "detect": [54, 55, 56], "visionexplain": 57, "imagenet": 58, "mnist": [59, 60, 61, 62, 73, 75], "map": [63, 64], "grad": [67, 68, 69], "cam": [67, 68, 69], "languag": [69, 72]}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 3, "sphinx": 56}})