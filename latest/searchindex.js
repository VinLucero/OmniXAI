Search.setIndex({"docnames": ["index", "omnixai", "omnixai.data", "omnixai.explainers", "omnixai.explainers.data", "omnixai.explainers.nlp", "omnixai.explainers.nlp.agnostic", "omnixai.explainers.nlp.counterfactual", "omnixai.explainers.nlp.specific", "omnixai.explainers.prediction", "omnixai.explainers.tabular", "omnixai.explainers.tabular.agnostic", "omnixai.explainers.tabular.counterfactual", "omnixai.explainers.tabular.specific", "omnixai.explainers.timeseries", "omnixai.explainers.timeseries.agnostic", "omnixai.explainers.timeseries.counterfactual", "omnixai.explainers.vision", "omnixai.explainers.vision.agnostic", "omnixai.explainers.vision.counterfactual", "omnixai.explainers.vision.specific", "omnixai.explanations", "omnixai.explanations.image", "omnixai.explanations.tabular", "omnixai.explanations.text", "omnixai.explanations.timeseries", "omnixai.preprocessing", "omnixai.visualization", "tutorials", "tutorials/data_analysis", "tutorials/misc/data_objects", "tutorials/misc/preprocessing", "tutorials/nlp", "tutorials/nlp/ce_classification", "tutorials/nlp/ce_qa", "tutorials/nlp/ig_tf", "tutorials/nlp/ig_torch", "tutorials/nlp/l2x", "tutorials/nlp/lime", "tutorials/nlp/shap", "tutorials/nlp_imdb", "tutorials/omnixai_in_ml_workflow", "tutorials/tabular/ce", "tutorials/tabular/l2x", "tutorials/tabular/lime", "tutorials/tabular/linear", "tutorials/tabular/mace", "tutorials/tabular/pdp", "tutorials/tabular/sensitivity", "tutorials/tabular/shap", "tutorials/tabular/tree", "tutorials/tabular_classification", "tutorials/tabular_regression", "tutorials/timeseries", "tutorials/timeseries/mace", "tutorials/timeseries/shap", "tutorials/vision", "tutorials/vision/ce_imagenet", "tutorials/vision/ce_tf", "tutorials/vision/ce_torch", "tutorials/vision/cem_tf", "tutorials/vision/cem_torch", "tutorials/vision/gradcam_tf", "tutorials/vision/gradcam_torch", "tutorials/vision/ig_tf", "tutorials/vision/ig_torch", "tutorials/vision/l2x", "tutorials/vision/lime", "tutorials/vision/shap"], "filenames": ["index.rst", "omnixai.rst", "omnixai.data.rst", "omnixai.explainers.rst", "omnixai.explainers.data.rst", "omnixai.explainers.nlp.rst", "omnixai.explainers.nlp.agnostic.rst", "omnixai.explainers.nlp.counterfactual.rst", "omnixai.explainers.nlp.specific.rst", "omnixai.explainers.prediction.rst", "omnixai.explainers.tabular.rst", "omnixai.explainers.tabular.agnostic.rst", "omnixai.explainers.tabular.counterfactual.rst", "omnixai.explainers.tabular.specific.rst", "omnixai.explainers.timeseries.rst", "omnixai.explainers.timeseries.agnostic.rst", "omnixai.explainers.timeseries.counterfactual.rst", "omnixai.explainers.vision.rst", "omnixai.explainers.vision.agnostic.rst", "omnixai.explainers.vision.counterfactual.rst", "omnixai.explainers.vision.specific.rst", "omnixai.explanations.rst", "omnixai.explanations.image.rst", "omnixai.explanations.tabular.rst", "omnixai.explanations.text.rst", "omnixai.explanations.timeseries.rst", "omnixai.preprocessing.rst", "omnixai.visualization.rst", "tutorials.rst", "tutorials/data_analysis.ipynb", "tutorials/misc/data_objects.ipynb", "tutorials/misc/preprocessing.ipynb", "tutorials/nlp.ipynb", "tutorials/nlp/ce_classification.ipynb", "tutorials/nlp/ce_qa.ipynb", "tutorials/nlp/ig_tf.ipynb", "tutorials/nlp/ig_torch.ipynb", "tutorials/nlp/l2x.ipynb", "tutorials/nlp/lime.ipynb", "tutorials/nlp/shap.ipynb", "tutorials/nlp_imdb.ipynb", "tutorials/omnixai_in_ml_workflow.ipynb", "tutorials/tabular/ce.ipynb", "tutorials/tabular/l2x.ipynb", "tutorials/tabular/lime.ipynb", "tutorials/tabular/linear.ipynb", "tutorials/tabular/mace.ipynb", "tutorials/tabular/pdp.ipynb", "tutorials/tabular/sensitivity.ipynb", "tutorials/tabular/shap.ipynb", "tutorials/tabular/tree.ipynb", "tutorials/tabular_classification.ipynb", "tutorials/tabular_regression.ipynb", "tutorials/timeseries.ipynb", "tutorials/timeseries/mace.ipynb", "tutorials/timeseries/shap.ipynb", "tutorials/vision.ipynb", "tutorials/vision/ce_imagenet.ipynb", "tutorials/vision/ce_tf.ipynb", "tutorials/vision/ce_torch.ipynb", "tutorials/vision/cem_tf.ipynb", "tutorials/vision/cem_torch.ipynb", "tutorials/vision/gradcam_tf.ipynb", "tutorials/vision/gradcam_torch.ipynb", "tutorials/vision/ig_tf.ipynb", "tutorials/vision/ig_torch.ipynb", "tutorials/vision/l2x.ipynb", "tutorials/vision/lime.ipynb", "tutorials/vision/shap.ipynb"], "titles": ["Welcome to OmniXAI\u2019s documentation!", "OmniXAI: An Explanation Toolbox", "omnixai.data package", "omnixai.explainers package", "omnixai.explainers.data package", "omnixai.explainers.nlp package", "omnixai.explainers.nlp.agnostic package", "omnixai.explainers.nlp.counterfactual package", "omnixai.explainers.nlp.specific package", "omnixai.explainers.prediction package", "omnixai.explainers.tabular package", "omnixai.explainers.tabular.agnostic package", "omnixai.explainers.tabular.counterfactual package", "omnixai.explainers.tabular.specific package", "omnixai.explainers.timeseries package", "omnixai.explainers.timeseries.agnostic package", "omnixai.explainers.timeseries.counterfactual package", "omnixai.explainers.vision package", "omnixai.explainers.vision.agnostic package", "omnixai.explainers.vision.counterfactual package", "omnixai.explainers.vision.specific package", "omnixai.explanations package", "omnixai.explanations.image package", "omnixai.explanations.tabular package", "omnixai.explanations.text package", "omnixai.explanations.timeseries package", "omnixai.preprocessing package", "omnixai.visualization package", "Tutorials &amp; Example Code", "DataAnalyzer for feature analysis", "Examples of data objects", "Examples of data preprocessing", "NLPExplainer for sentiment analysis", "Counterfactual explanation for text classification", "Counterfactual explanation for question answering", "Integrated-gradient on IMDB dataset (Tensorflow)", "Integrated-gradient on IMDB dataset (PyTorch)", "L2X (learning to explain) for text classification", "LIME for text classification", "SHAP for sentiment analysis", "NLPExplainer on IMDB dataset", "OmniXAI in a ML workflow", "Counterfactual explanation on Diabetes dataset", "L2X (learning to explain) for income prediction", "LIME for income prediction", "Logistic regression for income prediction", "MACE counterfactual explanation for income prediction", "Paritial dependence plots", "Morris sensitivity analysis", "SHAP for income prediction", "Decision tree for income prediction", "TabularExplainer for income prediction (classification)", "TabularExplainer for house-price prediction (regression)", "TimeseriesExplainer for time series anomaly detection", "Counterfactual explanation on time series anomaly detection", "SHAP for time series anomaly detection", "VisionExplainer for image classification", "Counterfactual explanation on ImageNet", "Counterfactual explanation on MNIST (Tensorflow)", "Counterfactual explanation on MNIST (PyTorch)", "Contrastive explanation on MNIST (Tensorflow)", "Contrastive explanation on MNIST (PyTorch)", "Grad-CAM for image classification (Tensorflow)", "Grad-CAM for image classification (PyTorch)", "Integrated-gradient for image classification (Tensorflow)", "Integrated-gradient for image classification (PyTorch)", "L2X (learning to explain) on MNIST", "LIME for image classification", "SHAP on MNIST"], "terms": {"short": [0, 1], "omni": [0, 1], "explain": [0, 1, 2, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68], "ai": [0, 1, 2], "python": [0, 1, 68], "librari": [0, 2, 6, 29, 30, 31, 33, 34, 39, 43, 44, 45, 46, 47, 49, 50, 51, 52], "xai": [0, 1], "offer": [0, 1, 37], "wai": [0, 1, 3, 26, 37], "interpret": [0, 1, 6, 11, 18, 37, 43, 66], "machin": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 37, 38, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 66, 67], "learn": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 28, 32, 38, 40, 41, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 67], "address": [0, 1], "mani": [0, 1, 37], "pain": [0, 1], "point": [0, 1, 37, 53, 54, 55], "decis": [0, 1, 12, 13, 19, 23, 28, 42, 57, 58, 59], "made": [0, 1, 37], "model": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "practic": [0, 1, 3, 51, 52, 53, 56], "aim": [0, 1], "one": [0, 1, 2, 3, 6, 15, 16, 21, 22, 23, 24, 25, 26, 30, 31, 32, 37, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "stop": [0, 1], "comprehens": [0, 1], "make": [0, 1, 26, 37, 41, 53], "easi": [0, 1, 32, 40, 51, 52, 53, 56], "data": [0, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "scientist": [0, 1], "ml": [0, 1, 3, 4, 9, 13, 28, 29, 32, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "research": [0, 1], "practition": [0, 1], "who": [0, 1, 37], "need": [0, 1, 2, 3, 30, 32, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "explan": [0, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 62, 63, 64, 65, 66, 67, 68], "variou": [0, 1], "type": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 32, 35, 36, 37, 40, 42, 43, 44, 47, 49, 51, 52, 53, 55, 56, 62, 63, 64, 65, 66], "method": [0, 4, 7, 18, 20, 22, 23, 26, 30, 33, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 57, 58, 59, 60, 61, 64, 65, 66, 68], "differ": [0, 4, 5, 10, 12, 14, 17, 29, 37, 41, 43, 44, 46, 47, 49, 51, 52, 66], "stage": [0, 1, 41], "process": [0, 1, 3, 8, 9, 13, 19, 20, 26, 32, 35, 36, 40, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "includ": [0, 1, 2, 19, 20, 26, 56], "rich": [0, 1], "famili": [0, 1, 41, 44, 46, 49, 51], "integr": [0, 1, 8, 13, 20, 22, 28, 32, 40, 56], "unifi": [0, 1, 3, 32, 40, 51, 52, 53, 56], "interfac": [0, 1, 3, 32, 37, 40, 43, 51, 52, 53, 56, 66], "which": [0, 1, 2, 3, 5, 8, 9, 10, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 68], "support": [0, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 17, 18, 20, 30, 31, 32, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 68], "multipl": [0, 1, 2, 3, 4, 5, 10, 14, 17, 26, 29, 37, 41, 43, 51, 52, 66], "tabular": [0, 1, 3, 4, 9, 21, 29, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "imag": [0, 1, 3, 12, 13, 17, 18, 19, 20, 21, 28, 37, 57, 58, 59, 60, 61, 66, 68], "text": [0, 1, 3, 5, 6, 7, 8, 21, 23, 28, 32, 34, 35, 36, 39, 40], "time": [0, 1, 2, 3, 4, 5, 10, 14, 15, 16, 17, 25, 28, 29, 37, 41], "seri": [0, 1, 2, 3, 14, 15, 16, 25, 28], "tradit": [0, 1], "scikit": [0, 1, 3, 5, 9, 10, 11, 13, 14, 17, 32, 40, 47, 51, 52, 56], "deep": [0, 1, 20, 62, 63], "pytorch": [0, 1, 3, 6, 11, 18, 28, 32, 37, 40, 43, 51, 52, 56, 66, 68], "tensorflow": [0, 1, 3, 5, 9, 10, 14, 17, 28, 32, 40, 42, 51, 52, 56, 68], "rang": [0, 1, 19, 20, 26, 35, 36, 40, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "divers": [0, 1, 46], "specif": [0, 1, 3, 5, 9, 10, 14, 17, 21, 22, 23, 24, 25, 32, 35, 36, 40, 41, 50, 51, 52, 53, 56, 62, 63], "agnost": [0, 1, 3, 5, 10, 12, 14, 16, 17, 36, 37, 40, 43, 44, 46, 49, 66, 68], "attribut": [0, 1], "counterfactu": [0, 1, 5, 10, 14, 17, 21, 28, 32, 40, 41, 53, 56], "gradient": [0, 1, 8, 12, 13, 16, 19, 20, 22, 28, 32, 37, 40, 56, 62, 63, 66], "base": [0, 1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 32, 33, 34, 37, 39, 48, 50, 52, 54, 57, 58, 59, 60, 61, 62, 63, 66], "etc": [0, 1], "For": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 18, 20, 21, 23, 24, 26, 29, 30, 31, 35, 36, 37, 38, 41, 43, 45, 47, 50, 51, 52, 56, 66, 67], "provid": [0, 1, 2, 3, 21, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 40, 45, 50, 51, 52, 53, 56], "an": [0, 2, 3, 4, 6, 11, 12, 15, 16, 18, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "us": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "gener": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 66, 68], "applic": [0, 1, 62, 64], "onli": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 18, 19, 20, 26, 29, 30, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "write": [0, 1, 37, 38], "few": [0, 1], "line": [0, 1, 37, 38, 53], "code": [0, 1, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "also": [0, 1, 2, 30, 37, 56], "gui": [0, 1], "dashboard": [0, 3, 29, 32, 40, 41, 51, 52, 53, 56], "visual": [0, 3, 20, 21, 29, 32, 40, 41, 42, 51, 52, 53, 56, 62, 63], "obtain": [0, 1, 37], "more": [0, 3, 11, 12, 15, 16, 26, 29, 37, 38, 41, 43, 47, 53, 54, 55, 57, 58, 59, 60, 61, 66], "insight": [0, 1], "about": [0, 1, 3, 37], "compar": [0, 13, 18, 20], "other": [0, 1, 29, 31, 37, 41, 42, 43, 44, 46, 47, 49, 51, 52, 66], "exist": [0, 1, 26, 37, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "ibm": 0, "aix360": 0, "microsoft": 0, "interpretml": 0, "alibi": 0, "explainx": 0, "our": [0, 37, 46, 54], "ha": [0, 1, 2, 3, 7, 22, 23, 24, 25, 30, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 68], "list": [0, 1, 2, 3, 4, 5, 10, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 30, 48, 52, 53, 54, 55], "uniqu": 0, "follow": [0, 1, 2, 3, 22, 23, 24, 25, 26, 30, 32, 35, 36, 37, 38, 40, 43, 44, 46, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "analysi": [0, 1, 3, 4, 9, 11, 23, 27, 28, 33, 41, 51, 52, 56], "explor": [0, 1, 29], "analyz": [0, 1, 4, 9, 29, 37, 41, 48, 51, 52], "correl": [0, 1, 3, 21, 29, 41], "check": [0, 4, 41, 62, 64, 67], "imbal": [0, 1, 3, 21, 26, 29, 41], "issu": [0, 37, 41], "most": [0, 1, 12, 41, 53], "popular": 0, "aspect": 0, "inform": [0, 1, 3, 4, 6, 11, 12, 18, 23, 25, 29, 37, 41, 42, 43, 47, 66], "chang": [0, 18, 46, 66], "current": [0, 26, 32, 40, 56], "predict": [0, 1, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 47, 48, 54, 55, 56, 59, 61, 62, 64, 66, 67], "grad": [0, 1, 3, 17, 20, 22, 28, 35, 41, 44, 46, 49, 51, 56], "cam": [0, 1, 3, 17, 20, 22, 28, 56], "its": [0, 1, 3, 10, 11, 12, 13, 18, 30, 32, 35, 36, 40, 43, 44, 46, 47, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "variant": 0, "timeseri": [0, 1, 3, 21, 30, 53, 54, 55], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 37, 38, 39, 40, 41, 43, 53, 54, 55, 56, 57, 63, 66], "much": [0, 34, 37], "simpler": [0, 37], "user": [0, 1, 3, 4, 5, 9, 10, 14, 17, 32, 34, 40, 51, 52, 53, 56], "examin": [0, 41], "extend": [0, 37], "ad": 0, "new": [0, 1, 2, 18, 26, 37], "algorithm": 0, "easili": [0, 30, 34], "implement": [0, 1, 7, 12, 20, 27, 33, 34, 37, 43, 66], "singl": [0, 2, 3, 26, 30, 31], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "deriv": [0, 3, 4, 5, 10, 14, 17, 26, 29], "from": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 21, 22, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "show": [0, 1, 3, 21, 22, 23, 24, 27, 29, 30, 32, 33, 35, 36, 39, 40, 41, 47, 48, 51, 52, 53, 56], "we": [0, 1, 2, 3, 29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "continu": [0, 1, 2, 4, 10, 11, 12, 13, 26, 30, 31, 42, 43, 44, 46, 47, 48, 49, 51, 52], "improv": [0, 20], "thi": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "futur": 0, "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "vision": [0, 1, 3, 22, 30, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "nlp": [0, 1, 3, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40], "task": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "eda": 0, "na": [0, 37], "global": [0, 1, 3, 4, 11, 13, 23, 27, 29, 32, 40, 41, 45, 47, 48, 50, 51, 52, 56], "select": [0, 1, 2, 6, 11, 18, 29, 41, 56], "metric": [0, 1, 2, 9, 30, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 58, 60, 68], "black": [0, 1, 3, 5, 9, 10, 12, 14, 17, 19, 32, 41, 42, 44, 46, 49, 51, 52, 53, 56, 57, 58, 59], "box": [0, 1, 3, 5, 9, 10, 12, 14, 17, 19, 32, 42, 46, 51, 52, 53, 56, 57, 58, 59], "partial": [0, 1, 11, 18, 23, 42, 47, 51, 52], "depend": [0, 1, 11, 18, 23, 28, 37, 43, 51, 52, 66], "sensit": [0, 1, 10, 21, 28, 52], "lime": [0, 1, 3, 5, 10, 17, 22, 28, 32, 40, 41, 43, 51, 52, 56], "local": [0, 1, 3, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 23, 27, 32, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 62, 63], "shap": [0, 1, 3, 5, 10, 13, 14, 17, 22, 28, 32, 41, 43, 51, 52, 53], "torch": [0, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 35, 36, 40, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "tf": [0, 1, 8, 12, 13, 18, 19, 20, 26, 31, 35, 36, 37, 38, 42, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "contrast": [0, 1, 20, 21, 28], "linear": [0, 1, 6, 10, 11, 21, 36, 40, 45, 50, 59, 61, 66], "tree": [0, 1, 13, 21, 28], "accept": 0, "transform": [0, 1, 3, 5, 6, 9, 10, 14, 17, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "between": [0, 4, 34, 37, 41], "toolkit": 0, "literatur": 0, "eli5": 0, "captum": 0, "l2x": [0, 5, 10, 17, 28, 36, 40], "you": [0, 1, 30, 33, 35, 36, 37, 39], "can": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 26, 29, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "pypi": [0, 1], "call": [0, 1, 2, 29, 31, 32, 35, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 66, 68], "pip": [0, 1], "mai": [0, 1, 2, 26, 30, 37, 41, 43, 44, 45, 46, 47, 49, 51, 66], "sourc": [0, 1], "clone": [0, 1], "repo": [0, 1], "navig": [0, 1], "root": [0, 1, 30, 59, 61, 66], "directori": [0, 1, 26], "edit": [0, 1], "mode": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 29, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 47, 49, 51, 52, 53, 54, 55, 56, 62, 63, 64, 65, 66], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 51, 52, 53], "plot": [0, 1, 11, 18, 21, 22, 23, 24, 25, 27, 28, 41, 43, 44, 46, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 66, 68], "To": [0, 1, 3, 29, 30, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "recommend": [0, 1, 3, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "link": [0, 1], "tutori": [0, 1, 3, 41], "exampl": [0, 2, 3, 4, 7, 12, 16, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "In": [0, 1, 3, 29, 30, 32, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "tabularexplain": [0, 1, 3, 4, 10, 11, 12, 13, 28, 32, 40, 41, 56], "visionexplain": [0, 1, 3, 17, 28], "nlpexplain": [0, 1, 3, 5, 28], "timeseriesexplain": [0, 1, 3, 14, 28], "respect": [0, 1, 2, 3, 4, 30, 53], "dataanalyz": [0, 1, 3, 4, 27, 28, 41], "predictionanalyz": [0, 1, 3, 9, 27, 41, 51, 52], "result": [0, 3, 4, 9, 19, 20, 22, 23, 24, 25, 27, 32, 34, 40, 41, 51, 52, 53, 56], "specifi": [0, 1, 2, 3, 9, 26, 29, 30, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 66], "function": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "pre": [0, 1, 3, 8, 13, 20, 26, 35, 36], "i": [0, 1, 2, 3, 6, 7, 10, 11, 16, 18, 23, 26, 29, 30, 31, 33, 35, 36, 37, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 59, 61, 62, 64, 66], "convert": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 26, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68], "raw": [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 17, 18, 19, 20, 22, 23, 29, 30, 32, 35, 36, 40, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 30, 32, 34, 35, 36, 40, 42, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "post": [0, 1, 3, 37, 38], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 22, 23, 24, 25, 34, 51, 52, 53, 56], "output": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 26, 31, 32, 33, 34, 35, 36, 37, 38, 40, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "probabl": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 17, 18, 21, 32, 33, 37, 38, 40, 43, 44, 46, 47, 49, 51, 52, 56, 66, 67], "appli": [0, 1, 2, 3, 10, 11, 12, 13, 26, 29, 31, 32, 35, 36, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 56, 62, 64, 67], "mace": [0, 1, 3, 10, 14, 28, 41, 43, 51, 52, 53], "let": [0, 1, 31, 34, 37, 41, 62, 64, 67], "take": [0, 1, 30, 32, 37, 40, 43, 44, 46, 47, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "incom": [0, 1, 28, 29, 41, 47], "dataset": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 18, 26, 27, 28, 29, 30, 31, 37, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 66, 68], "http": [0, 1, 6, 7, 8, 11, 12, 13, 15, 18, 19, 20, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "archiv": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "ic": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "uci": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "edu": [0, 1, 29, 38, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "adult": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "repres": [0, 1, 2, 15, 16, 30, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "creat": [0, 1, 2, 3, 29, 30, 34, 37, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56], "instanc": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "given": [0, 1, 2, 3, 4, 10, 13, 26, 29, 30, 31, 32, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56], "panda": [0, 1, 2, 23, 25, 26, 29, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "datafram": [0, 1, 2, 11, 12, 13, 23, 25, 26, 29, 30, 31, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "categor": [0, 1, 2, 4, 10, 11, 12, 13, 26, 29, 30, 31, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "name": [0, 1, 2, 3, 4, 5, 10, 14, 17, 21, 22, 23, 24, 26, 27, 29, 32, 35, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "target": [0, 1, 2, 4, 9, 10, 12, 13, 20, 26, 29, 30, 31, 36, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 59, 61, 62, 63, 66], "label": [0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 18, 20, 22, 23, 24, 26, 27, 29, 30, 31, 33, 35, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "column": [0, 1, 2, 3, 9, 23, 26, 29, 30, 31, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "import": [0, 1, 2, 4, 6, 8, 11, 13, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "load": [0, 1, 3, 21, 26, 29, 32, 34, 35, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "feature_nam": [0, 1, 3, 23, 29, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "ag": [0, 1, 3, 4, 27, 29, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51], "workclass": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "fnlwgt": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "educ": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "num": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "marit": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "statu": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "occup": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "relationship": [0, 1, 3, 10, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "race": [0, 1, 3, 10, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "sex": [0, 1, 3, 10, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "capit": [0, 1, 3, 10, 27, 29, 37, 41, 43, 44, 45, 46, 47, 49, 50, 51], "gain": [0, 1, 3, 4, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "loss": [0, 1, 3, 6, 10, 11, 12, 16, 18, 19, 20, 27, 29, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 58, 59, 60, 61, 66, 68], "hour": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "per": [0, 1, 3, 12, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "week": [0, 1, 3, 27, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "countri": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "df": [0, 1, 2, 30, 31, 41, 48, 51, 52, 53, 54, 55], "pd": [0, 1, 2, 11, 12, 13, 26, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "np": [0, 1, 2, 3, 10, 11, 12, 13, 16, 20, 26, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 62, 64, 68], "genfromtxt": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "delimit": [0, 1, 3, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51], "dtype": [0, 1, 3, 29, 35, 36, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51], "str": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 26, 29, 41, 43, 44, 45, 46, 47, 49, 50, 51, 56, 57, 62, 63, 64, 65, 67], "tabular_data": [0, 1, 3, 26, 29, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "categorical_column": [0, 1, 2, 3, 26, 29, 30, 31, 41, 43, 44, 45, 46, 47, 49, 50, 51], "1": [0, 1, 2, 3, 12, 16, 17, 19, 20, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "3": [0, 1, 2, 3, 10, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "5": [0, 1, 3, 6, 7, 11, 12, 16, 18, 19, 20, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "6": [0, 1, 3, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68], "7": [0, 1, 3, 29, 30, 31, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 66, 67, 68], "8": [0, 1, 3, 10, 11, 13, 29, 30, 31, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 66, 68], "9": [0, 1, 3, 23, 29, 30, 31, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 58, 59, 60, 61, 66, 67, 68], "13": [0, 1, 3, 29, 30, 31, 41, 43, 44, 45, 46, 47, 49, 50, 51], "target_column": [0, 1, 2, 3, 29, 30, 31, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "packag": [0, 1, 31, 32, 35, 36, 37, 38, 40, 48, 51, 52, 53, 56, 68], "preprocess": [0, 3, 5, 9, 10, 13, 14, 17, 18, 19, 20, 28, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "sever": [0, 1, 30, 31, 37, 41, 45, 50, 51, 52], "tabulartransform": [0, 1, 3, 26, 31, 41, 43, 44, 46, 47, 48, 49, 51, 52], "special": [0, 1, 16, 43, 44, 45, 46, 47, 49, 50, 51, 52], "design": [0, 16, 18, 32, 40, 43, 44, 46, 47, 49, 51, 52, 53, 56], "By": [0, 1, 43, 44, 46, 47, 49, 51, 52, 56], "default": [0, 1, 2, 6, 11, 12, 18, 29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "hot": [0, 1, 26, 31, 43, 44, 46, 47, 49, 51, 52], "encod": [0, 1, 10, 13, 20, 31, 43, 44, 46, 47, 49, 51, 52], "keep": [0, 1, 26, 43, 44, 46, 47, 49, 51, 52], "valu": [0, 1, 2, 3, 4, 6, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 26, 30, 31, 32, 33, 35, 36, 37, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 60, 66, 68], "numpi": [0, 1, 2, 9, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "arrai": [0, 1, 2, 9, 26, 29, 30, 31, 32, 33, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "If": [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 26, 29, 30, 31, 35, 36, 37, 38, 39, 42, 43, 44, 46, 47, 48, 49, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "last": [0, 1, 2, 3, 26, 29, 30, 31, 43, 44, 46, 47, 49, 51, 52, 56], "after": [0, 1, 37, 41, 43, 44, 46, 47, 49, 51, 52, 66, 68], "train": [0, 1, 3, 4, 5, 6, 10, 11, 12, 13, 14, 17, 18, 23, 26, 30, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 66, 68], "xgboost": [0, 1, 3, 13, 41, 43, 44, 46, 47, 49, 51], "classifi": [0, 1, 12, 13, 37, 38, 41, 43, 44, 46, 47, 49, 51], "fit": [0, 1, 3, 10, 13, 26, 31, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 58, 60, 68], "class_nam": [0, 1, 10, 21, 22, 23, 24, 26, 27, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 49, 51, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "x": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 66, 68], "split": [0, 1, 2, 10, 13, 34, 53, 54, 55], "test": [0, 1, 9, 10, 13, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "train_label": [0, 1, 41, 51, 58, 60, 66, 68], "test_label": [0, 1, 9, 41, 51, 58, 60, 66, 68], "sklearn": [0, 1, 13, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "model_select": [0, 1, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52], "train_test_split": [0, 1, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52], "train_siz": [0, 1, 10, 13, 41, 43, 44, 46, 47, 48, 49, 51, 52], "0": [0, 1, 2, 3, 6, 10, 11, 12, 13, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "80": [0, 1, 41, 43, 44, 46, 47, 48, 49, 51, 52], "xgbclassifi": [0, 1, 3, 41, 43, 44, 46, 47, 49, 51], "n_estim": [0, 1, 3, 37, 38, 41, 43, 44, 46, 47, 48, 49, 51, 52], "300": [0, 1, 3, 41, 43, 44, 46, 47, 49, 51], "max_depth": [0, 1, 3, 41, 43, 44, 46, 47, 49, 50, 51], "back": [0, 1, 41, 44, 49, 51, 52], "train_data": [0, 1, 35, 36, 40, 41, 51, 52, 59, 61, 66], "invert": [0, 1, 26, 31, 41, 44, 49, 51, 52], "test_data": [0, 1, 9, 30, 41, 51, 52, 59, 61, 66], "initi": [0, 1, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 24, 25, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "set": [0, 1, 2, 11, 12, 16, 24, 27, 29, 30, 32, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "paramet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "pdp": [0, 1, 3, 4, 10, 17, 21, 27, 41, 47, 51, 52], "too": [0, 1, 37, 44, 46, 47, 48, 49, 51, 52], "larg": [0, 1, 10, 11, 12, 13, 41, 42, 44, 46, 47, 48, 49, 51, 52], "subset": [0, 1, 2, 10, 11, 12, 13, 26, 30, 37, 38, 42, 44, 46, 47, 48, 49, 51, 52], "sampler": [0, 1, 10, 11, 12, 13, 42, 44, 46, 47, 48, 49, 51, 52], "subsampl": [0, 1, 10, 11, 12, 13, 26, 42, 44, 46, 47, 48, 49, 51, 52], "postprocess": [0, 1, 3, 5, 9, 10, 14, 17, 18, 32, 40, 51, 52, 53, 56], "form": [0, 1, 3, 5, 9, 10, 14, 17, 32, 40, 51, 52, 53, 56], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 40, 41, 51, 52, 53, 54, 55, 56, 62, 64], "should": [0, 1, 2, 6, 9, 11, 12, 13, 15, 16, 18, 29, 35, 36, 37, 43, 51, 52, 54, 55, 66], "classif": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 32, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 52, 57, 58, 59, 60, 61, 66, 68], "regress": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18, 20, 21, 22, 23, 24, 26, 28, 32, 35, 36, 37, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 56, 62, 63, 64, 65, 66], "consum": [0, 1, 32, 40, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "simpli": [0, 1, 32, 40, 43, 44, 46, 47, 49, 51, 52, 56, 57, 58, 59, 60, 61, 68], "some": [0, 1, 3, 26, 30, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 49, 51, 52], "custom": [0, 1], "format": [0, 1, 2, 3, 7, 22, 23, 24, 25, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 56, 59, 61, 66], "lambda": [0, 1, 3, 32, 37, 38, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 56, 57, 58, 59, 60, 61, 63, 65, 66, 68], "z": [0, 1, 3, 26, 31, 41, 43, 44, 46, 47, 48, 49, 51, 52], "some_transform": [0, 1, 51, 52], "to_pd": [0, 1, 2, 30, 43, 44, 46, 47, 49, 51, 52], "param": [0, 1, 3, 4, 5, 10, 14, 17, 27, 29, 40, 41, 51, 52, 53, 56], "ignored_featur": [0, 1, 3, 10, 12, 41, 46, 51], "while": [0, 1, 41, 51, 52], "return": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 33, 34, 35, 36, 40, 42, 50, 51, 52, 53, 54, 55, 59, 61, 62, 64, 66, 67], "three": [0, 1, 6, 11, 26, 30, 41, 51, 56], "explain_glob": [0, 1, 3, 10, 29, 41, 51, 52], "hide": [0, 1, 51, 52], "all": [0, 1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 32, 37, 40, 41, 42, 51, 52, 53, 56], "detail": [0, 1, 3, 37, 43, 51, 52, 57, 58, 59, 60, 61, 66], "behind": [0, 1, 51, 52], "so": [0, 1, 37, 41, 42, 51, 52], "two": [0, 1, 2, 3, 29, 30, 31, 35, 36, 37, 40, 41, 42, 51, 52, 58, 59, 60, 61, 66, 68], "test_inst": [0, 1, 41, 44, 46, 49, 51, 52, 53], "local_explan": [0, 1, 3, 5, 10, 14, 17, 27, 32, 40, 41, 51, 52, 53, 56], "global_explan": [0, 1, 3, 10, 27, 29, 41, 51, 52], "similarli": [0, 1, 51, 52], "comput": [0, 1, 4, 9, 13, 16, 20, 31, 37, 41, 51, 52], "perform": [0, 1, 30, 33, 35, 36, 39, 40, 41, 51, 52, 59, 61, 66], "test_target": [0, 1, 9, 41, 51, 52], "integ": [0, 1, 2, 9, 26, 29, 51], "labelencod": [0, 1, 9, 10, 13, 26, 31, 51], "match": [0, 1, 9, 26, 51], "prediction_explan": [0, 1, 9, 27, 41, 51, 52], "launch": [0, 1, 29, 32, 40, 41, 51, 52, 53, 56], "dash": [0, 1, 21, 22, 23, 24, 25, 27, 29, 32, 40, 41, 51, 52, 53, 56], "app": [0, 1, 29, 32, 40, 41, 51, 52, 53, 56], "open": [0, 1, 2, 12, 19, 26, 30, 31, 37, 42, 56, 57, 58, 59, 62, 63, 64, 65, 67], "browser": [0, 1], "see": [0, 1, 37, 41, 66], "thank": [0, 1, 37], "your": [0, 1, 37, 68], "interest": [0, 1, 37], "befor": [0, 1, 37], "run": [0, 1, 29, 32, 37, 40, 41, 51, 52, 53, 56], "commit": [0, 1], "ensur": [0, 1], "file": [0, 1, 21, 26], "ar": [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 18, 21, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 66, 67, 68], "correctli": [0, 1], "contain": [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 17, 21, 23, 27, 30, 31, 37, 45, 51, 52, 53, 54, 55, 58, 59, 60, 61, 66, 68], "appropri": [0, 1], "licens": [0, 1], "header": [0, 1], "whenev": [0, 1], "add": [0, 1, 22, 23, 24, 25, 26, 37, 42, 58, 60, 68], "step": [0, 1, 8, 13, 16, 20, 26, 35, 41, 42, 56, 57, 58, 59, 60, 61, 66, 68], "below": [0, 1, 37], "choos": [0, 1, 3, 4, 5, 10, 14, 17, 29, 41], "script": [0, 1], "folder": [0, 1], "put": [0, 1], "under": [0, 1, 26], "inherit": [0, 1, 3, 26], "explainerbas": [0, 1, 3, 4, 6, 7, 8, 9, 10, 12, 15, 16, 18, 19, 20], "constructor": [0, 1, 3], "__init__": [0, 1, 3, 35, 36, 40, 59, 61, 66], "self": [0, 1, 2, 3, 26, 35, 36, 40, 41, 44, 46, 49, 51, 59, 61, 66], "predict_funct": [0, 1, 3, 6, 7, 9, 10, 11, 12, 15, 16, 18, 33, 34, 37, 38, 42, 43, 44, 46, 47, 48, 49, 54, 55, 66, 67], "kwarg": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 35, 36, 40], "preprocess_funct": [0, 1, 3, 5, 8, 9, 10, 13, 14, 17, 18, 19, 20, 35, 36, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "postprocess_funct": [0, 1, 3, 5, 17], "requir": [0, 1, 3, 5, 17, 53], "whether": [0, 1, 2, 3, 16, 23, 37, 41, 53, 54, 55], "differenti": [0, 1, 3], "resiz": [0, 1, 3, 26, 31, 56, 57, 62, 63, 64, 65, 67], "224": [0, 1, 3, 30, 31, 56, 57, 62, 63, 64, 65, 67], "normal": [0, 1, 3, 10, 13, 31, 37, 43, 44, 46, 47, 49, 51, 52, 56, 57, 58, 60, 63, 65, 67, 68], "pixel": [0, 1, 3, 18, 20, 22, 26, 31, 58, 60, 68], "logit": [0, 1, 3, 13, 35, 40, 43, 46, 56, 66, 67], "explanation_typ": [0, 1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20], "string": [0, 1, 2, 3, 21, 30, 32], "both": [0, 1, 2, 3, 13, 23, 25, 30, 45, 50], "alia": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "where": [0, 1, 21, 23, 24, 25, 37, 46], "py": [0, 1, 68], "regist": [0, 1, 3], "automat": [0, 1, 2, 3, 11, 12, 13], "via": [0, 1, 2, 4, 6, 11, 18, 20, 56, 57, 59, 61, 62, 63, 64, 65], "defin": [0, 1, 4, 30, 31, 42, 56, 57, 59, 61, 63, 65, 66], "toolbox": 0, "modul": [0, 30, 35, 36, 40, 47, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "fill": [0, 1, 31], "pipelin": [0, 1, 6, 32, 33, 34, 39], "categori": [0, 1, 26, 37, 38], "basic": [0, 12, 16, 42], "object": [0, 2, 3, 10, 12, 13, 16, 20, 21, 26, 27, 28, 31, 32, 35, 36, 37, 38, 40, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68], "hous": [0, 28], "price": [0, 28], "sentiment": [0, 1, 28, 33, 35, 36, 40], "imdb": [0, 1, 28], "anomali": [0, 1, 15, 16, 28], "detect": [0, 1, 15, 16, 28], "workflow": [0, 28], "diabet": [0, 28], "logist": [0, 13, 28], "pariti": [0, 28], "morri": [0, 11, 23, 28], "imagenet": [0, 1, 28, 56, 62, 63, 64, 65, 67], "mnist": [0, 18, 28, 30], "question": [0, 7, 28, 37], "answer": [0, 7, 28, 37], "index": [0, 2, 13, 21, 22, 23, 24, 25, 27, 30, 34, 38, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68], "search": [0, 18], "page": 0, "capabl": 1, "featur": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "five": [1, 6], "kei": [1, 23], "subpackag": [1, 3], "simpl": [1, 11, 35, 36, 40, 53, 54, 55, 56, 58, 59, 60, 61, 66, 68], "pillow": [1, 2, 30, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "One": [1, 26, 31, 32, 37, 40, 43, 45, 56, 66], "ordin": [1, 10, 13, 26, 31], "kbin": [1, 26], "standard": [1, 10, 13, 23, 26, 31, 41, 43, 44, 46, 47, 49, 51, 52], "min": [1, 12, 26, 31, 35, 36, 40], "max": [1, 12, 26, 31, 35, 36, 40, 59, 61, 66], "rescal": [1, 19, 20, 26], "nan": [1, 26, 31], "recal": 1, "idf": [1, 26, 31, 37, 38], "token": [1, 2, 6, 8, 24, 30, 31, 34, 35, 36, 40], "id": [1, 6, 8, 21, 26, 31, 35, 36, 40], "combin": 1, "togeth": [1, 26, 37], "conveni": [1, 26], "particular": [1, 18, 37, 56], "main": [1, 26], "group": [1, 37], "It": [1, 2, 3, 4, 5, 6, 11, 12, 13, 17, 19, 20, 22, 23, 24, 25, 26, 42, 56, 68], "further": [1, 41], "handl": [1, 13], "without": [1, 2, 12, 19, 37, 42, 57, 58, 59], "know": [1, 37], "either": [1, 2, 12, 13, 32, 40, 46], "feature_import": [1, 21], "store": [1, 2, 3, 22, 23, 24, 25, 26, 30, 56], "matplotlib": [1, 21, 22, 23, 24, 25, 58, 59, 60, 61, 68], "plotly_plot": [1, 21, 22, 23, 24, 25], "ipython_plot": [1, 21, 22, 23, 24, 25, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "ipython": [1, 21, 22, 23, 24, 25, 29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "word": [1, 6, 8, 24, 26, 32, 35, 36, 37, 40], "plotli": [1, 21, 22, 23, 24, 25, 27, 29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "figur": [1, 21, 22, 23, 24, 25, 27], "demonstr": 1, "architectur": 1, "four": [1, 29], "autoexplainerbas": [1, 3, 4, 5, 10, 14, 17, 29], "act": [1, 3, 32, 40, 51, 52, 53, 56], "factori": [1, 3, 32, 40, 51, 52, 53, 56], "s": [1, 2, 6, 11, 18, 31, 32, 37, 41, 43, 53, 54, 55, 62, 64, 66, 67], "next": [1, 37, 41], "resnet": [1, 3, 56, 57, 63, 65], "arxiv": [1, 6, 11, 12, 18, 19, 20, 37, 42, 43, 57, 58, 59, 60, 61, 62, 63, 66], "org": [1, 6, 11, 12, 18, 19, 20, 37, 42, 43, 47, 52, 57, 58, 59, 60, 61, 62, 63, 66], "ab": [1, 6, 11, 12, 18, 19, 20, 37, 42, 43, 57, 58, 59, 60, 61, 62, 63, 66], "1512": 1, "03385": 1, "pretrain": [1, 3, 34, 56, 57, 63, 65, 67], "www": 1, "net": [1, 37], "here": [1, 7, 11, 30, 32, 37, 42, 51, 52, 53, 54, 55, 56, 57, 63, 65, 67], "sampl": [1, 6, 10, 11, 13, 16, 18, 20, 26, 35, 36, 40], "ig": [1, 3, 5, 10, 17, 35, 36, 40, 56], "gradcam": [1, 3, 17, 56, 62, 63], "2": [1, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "resnet50": [1, 3, 56, 57, 63], "layer": [1, 6, 8, 11, 20, 35, 36, 40, 42, 56, 58, 59, 60, 61, 62, 63, 66, 68], "target_lay": [1, 3, 17, 20, 56, 62, 63], "layer4": [1, 3, 17, 56, 63], "test_img": [1, 58, 60, 66, 68], "y": [1, 6, 8, 11, 12, 13, 18, 20, 26, 31, 34, 36, 40, 42, 59, 61, 62, 64, 66], "281": [1, 62, 64], "correspond": [1, 2, 6, 7, 9, 10, 11, 12, 15, 16, 18, 20, 22, 23, 24, 25, 27, 37, 38, 42, 43, 44, 46, 47, 48, 49, 54, 55, 56, 57, 66, 67], "tiger_cat": [1, 62, 64], "top": [1, 6, 8, 11, 13, 18, 20, 62, 63, 64, 65, 67], "bull_mastiff": [1, 62, 64], "These": [1, 30, 45, 50], "highlight": 1, "region": 1, "note": [1, 19, 20, 26, 35, 36, 37, 40, 41], "besid": [1, 30], "same": [1, 3, 4, 5, 10, 14, 17, 29, 35, 37, 41, 43, 66], "gradcam0": 1, "gradcam3": 1, "first": [1, 2, 8, 22, 23, 24, 25, 29, 30, 35, 36, 37, 40, 41, 43, 44, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 66, 68], "second": [1, 2, 30, 46], "consid": [1, 4, 32, 41, 42, 56, 57, 63, 65], "goal": 1, "review": [1, 35, 36, 40], "posit": [1, 20, 22, 26, 32, 33, 35, 36, 37, 39, 40, 41, 42, 60, 61], "neg": [1, 4, 13, 20, 22, 32, 33, 35, 36, 39, 40, 41, 42, 60, 61], "cnn": [1, 35, 36, 37, 40, 59, 61, 66], "suppos": [1, 30, 31, 37], "want": [1, 29, 30, 37, 43, 44, 46, 47, 49, 51, 52], "do": [1, 29, 31, 32, 34, 37, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 56], "polyjuic": [1, 5, 32, 33, 34, 40], "embed": [1, 8, 11, 35, 36, 40], "embedding_lay": [1, 8, 35, 36, 40], "id2token": [1, 8, 35, 36, 40], "id_to_token": 1, "wa": [1, 30, 32, 33, 35, 36, 37, 39, 40], "fantast": [1, 30, 33, 35, 36, 39, 40], "clearli": [1, 41], "largest": 1, "score": [1, 8, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 32, 33, 41, 45, 53, 54, 55, 58, 60, 68], "impli": [1, 15, 16, 41, 54, 55], "sentenc": [1, 2, 26, 30, 31, 35, 36, 37, 38, 40], "becaus": [1, 2, 9, 26, 29, 32, 37, 40, 41], "horribl": [1, 30, 33, 35, 36, 39, 40], "help": 1, "understand": [1, 37], "behavior": [1, 41, 66], "univari": [1, 2, 53, 54, 55], "statist": 1, "detector": [1, 53, 54, 55], "window": [1, 53, 54, 55], "accord": [1, 31, 37], "threshold": [1, 16, 53, 54, 55], "estim": [1, 3, 4, 6, 10, 11, 12, 13, 18, 20, 26, 37, 43, 44, 46, 47, 49, 66], "have": [1, 2, 19, 20, 26, 30, 31, 33, 35, 36, 37, 39, 41, 50], "train_df": [1, 53, 54, 55], "test_df": [1, 53, 54, 55], "anomaly_detect": [1, 14, 15, 16, 25, 53, 54, 55], "from_pd": [1, 2, 30, 53, 54, 55], "none": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 37, 42, 43, 53, 66], "001": [1, 6, 11, 16, 18, 53, 54], "timestamp": [1, 2, 30, 53, 54, 55], "20": [1, 6, 18, 23, 30, 37, 41, 44, 46, 49, 51, 53, 54, 55, 59, 61, 66], "00": [1, 32, 39, 53, 54, 55], "around": [1, 37, 53], "reason": 1, "why": [1, 37], "indic": [1, 2, 3, 23, 29, 30, 43, 44, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 68], "explanationbas": [1, 21, 22, 23, 24, 25], "avail": 1, "cannot": [1, 21, 22, 23, 25], "fulfil": 1, "auto": [1, 3, 20], "mutual_info": [1, 3], "chi_squar": [1, 3], "pixel_import": [1, 21], "mask": [1, 6, 21, 35, 36, 40], "word_import": [1, 21], "feature_column": [2, 3, 29, 30, 42, 43, 44, 45, 46, 47, 49, 50], "batch": [2, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 23, 30, 31, 32, 35, 36, 37, 38, 40, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "shape": [2, 30, 31, 36, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 68], "batch_siz": [2, 6, 11, 16, 18, 30, 35, 36, 40, 42, 56, 58, 59, 60, 61, 66, 68], "height": [2, 30, 56], "width": [2, 30, 56], "channel": [2, 26, 30, 56], "true": [2, 3, 4, 12, 16, 20, 22, 23, 24, 26, 30, 32, 33, 35, 36, 37, 39, 40, 42, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "channel_last": 2, "dimens": [2, 16], "fals": [2, 4, 22, 23, 24, 30, 35, 36, 40, 59, 61, 66, 68], "instead": [2, 29, 32, 37, 40, 41, 51, 52, 53, 54, 55, 56, 68], "number": [2, 4, 6, 7, 11, 12, 13, 16, 18, 19, 20, 21, 23, 24, 25, 26, 30, 41], "4": [2, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "pil": [2, 26, 30, 31, 56, 57, 62, 63, 64, 65, 67], "pilimag": [2, 26, 30, 31, 56, 57, 62, 63, 64, 65, 67], "im": [2, 3, 30, 56, 57, 59, 61, 62, 63, 64, 65, 66], "an_imag": 2, "jpg": [2, 26, 30, 31, 56, 57, 63], "hello": [2, 26, 31, 37], "m": [2, 26, 31], "And": [2, 26, 31], "anoth": [2, 23, 26, 31, 37, 62, 64], "veri": [2, 26, 31, 37], "allow": [2, 3, 4, 5, 10, 14, 17, 37, 51, 52, 56], "nltk": 2, "word_token": 2, "variabl": [2, 25, 30, 53, 54, 55], "num_vari": [2, 30], "construct": [2, 3, 13, 18, 29, 30, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "2017": [2, 30], "12": [2, 30, 31, 32, 37, 41, 44, 46, 49, 51], "27": [2, 30, 37, 41, 44, 46, 49, 51], "1263": [2, 30], "94091": [2, 30], "394": [2, 30], "507": [2, 30], "16": [2, 30, 42, 52, 53, 54, 55], "530": [2, 30], "28": [2, 30, 41, 44, 46, 49, 51, 58, 60, 68], "1299": [2, 30], "86398": [2, 30], "506": [2, 30], "424": [2, 30], "14": [2, 30, 31], "162": [2, 30], "date": [2, 30], "consumpt": [2, 30], "wind": [2, 30], "solar": [2, 30], "set_index": [2, 30, 53, 54, 55], "to_datetim": [2, 30, 53, 54, 55], "ts": [2, 53, 54, 55], "abstract": [2, 3, 21, 26], "differet": 2, "properti": [2, 3, 26], "data_typ": 2, "union": [2, 12, 23, 24, 25, 26], "ndarrai": [2, 10, 11, 12, 13, 16, 20, 26], "num_sampl": [2, 67], "num_featur": [2, 11, 23], "when": [2, 6, 7, 8, 10, 11, 12, 13, 18, 20, 21, 22, 23, 24, 25, 30, 37, 41, 52, 66], "int": [2, 4, 6, 7, 11, 12, 18, 26, 35, 36, 40, 53, 54, 55], "iloc": [2, 53, 54, 55], "row": [2, 30, 41, 44, 46, 49, 51, 52, 53, 54, 55], "slice": 2, "tupl": [2, 26, 40, 62, 64, 67], "get": [2, 3, 21, 22, 23, 24, 25, 26, 30, 35, 36, 40], "continuous_column": [2, 30], "except": 2, "sequenc": [2, 4, 26], "copi": 2, "otherwis": 2, "to_numpi": [2, 30, 42, 56, 58, 60, 68], "remove_target_column": [2, 46], "remov": [2, 31, 41, 48, 68], "get_target_column": 2, "get_continuous_median": 2, "absolut": [2, 37], "median": [2, 12, 26, 31, 42], "dict": [2, 3, 4, 5, 8, 9, 10, 14, 17, 21, 22, 23, 24, 25, 27, 34, 51, 52], "get_continuous_bound": 2, "upper": [2, 12, 16], "lower": [2, 12, 16], "bound": [2, 12, 16], "grayscal": 2, "rgb": [2, 30, 31, 56, 57, 62, 63, 64, 65, 67], "h": [2, 26], "w": [2, 26], "ignor": [2, 3, 8, 9, 11, 12, 13, 18, 20, 22, 23, 24, 41, 46], "bool": [2, 6, 11, 18], "size": [2, 6, 11, 18, 23, 26, 30, 31], "color": [2, 30], "argument": [2, 37, 68], "image_shap": [2, 30], "hwc": [2, 30], "keepdim": [2, 30], "kept": [2, 37], "squeez": [2, 36, 40], "to_pil": [2, 3, 30, 31, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67], "callabl": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 42], "to_token": [2, 30], "to_str": 2, "sep": [2, 7, 34, 35, 36, 40], "maxsplit": 2, "variable_nam": 2, "multivari": [2, 53, 54, 55], "whose": [2, 8, 12, 13, 18, 20, 23, 31, 35, 36], "ts_len": [2, 16, 30], "length": [2, 16, 30, 32, 33, 34, 40], "datetimeindex": 2, "classmethod": 2, "rtype": 2, "kernel_width": [3, 10, 11, 41, 51, 52], "nsampl": [3, 10, 11, 18, 41, 49, 51, 52], "100": [3, 10, 11, 35, 36, 37, 40, 41, 43, 49, 51, 52, 56, 57, 59, 61, 66], "similar": [3, 26, 32, 40, 42, 50, 56], "img": [3, 17, 26, 30, 31, 56, 57, 62, 63, 64, 65, 67], "mainli": 3, "gbtree": [3, 41, 43, 44, 46, 47, 49, 51], "predict_proba": [3, 10, 37, 38, 43, 44, 46, 47, 49], "shaptabular": [3, 11, 49, 68], "training_data": [3, 4, 6, 10, 11, 12, 13, 15, 16, 18, 37, 42, 43, 44, 46, 47, 48, 49, 54, 55, 66], "compos": [3, 56, 57, 59, 61, 63, 65, 66, 67], "256": [3, 6, 11, 18, 35, 36, 40, 42, 56, 57, 63, 65, 67], "centercrop": [3, 56, 57, 63, 65, 67], "totensor": [3, 56, 57, 59, 61, 63, 65, 66, 67], "mean": [3, 13, 22, 23, 24, 26, 27, 30, 31, 36, 37, 40, 43, 44, 46, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68], "485": [3, 56, 57, 63, 65, 67], "456": [3, 56, 57, 63, 65, 67], "406": [3, 56, 57, 63, 65, 67], "std": [3, 23, 26, 36, 40, 56, 57, 63, 65, 67], "229": [3, 56, 57, 63, 65, 67], "225": [3, 56, 57, 63, 65, 67], "stack": [3, 56, 57, 59, 61, 63, 65, 66, 67], "found": [3, 16], "explainerabcmeta": 3, "classnam": 3, "cls_dict": 3, "autodocabcmeta": 3, "meta": 3, "_explain": 3, "collect": [3, 4, 5, 10, 14, 17], "empti": [3, 5, 17, 20], "ani": [3, 5, 9, 10, 13, 14, 17, 37], "param_1": [3, 4, 5, 10, 14, 17], "lime_explan": 3, "shap_explan": 3, "ordereddict": [3, 4], "pdp_explan": [3, 4], "explainer_nam": 3, "static": [3, 4, 5, 10, 13, 14, 17, 26], "list_explain": [3, 4, 5, 10, 14, 17], "mutual": [4, 29, 37, 41], "n_bin": [4, 26], "10": [4, 6, 11, 12, 16, 18, 19, 20, 22, 23, 30, 31, 35, 36, 40, 41, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 64, 66, 68], "overrid": 4, "imbalanceanalyz": 4, "count": [4, 23], "appear": [4, 23], "gender": [4, 42], "male": [4, 30, 31, 41, 42, 44, 46, 49, 51], "femal": [4, 30, 31, 41, 42, 44, 46, 49, 51], "separ": [4, 37, 43, 66], "cross": [4, 23, 29], "bin": [4, 16, 26], "discret": [4, 11, 26], "imbalanceexplan": [4, 23], "correlationanalyz": 4, "matrix": [4, 23], "scipi": 4, "stat": [4, 41], "spearmanr": 4, "correlationexplan": [4, 23], "mutualinform": 4, "globalfeatureimport": [4, 23], "chisquar": 4, "chi": [4, 29, 41], "squar": [4, 29, 41], "non": 4, "chi2": [4, 29, 41], "qa": [5, 7, 32, 34], "those": [5, 17, 31, 46], "don": [5, 17, 41, 46], "t": [5, 16, 17, 35, 36, 37, 40, 41, 46], "limetext": [6, 38], "pleas": [6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "cite": [6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "origin": [6, 8, 11, 13, 15, 18, 19, 20, 23, 25, 26, 35, 36, 37, 38, 39, 43, 44, 49, 55, 60, 61, 64, 65, 66, 67, 68], "work": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 55, 60, 61, 64, 65, 66, 67, 68], "github": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 38, 39, 44, 48, 49, 55, 64, 65, 67, 68], "com": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 38, 39, 44, 48, 49, 55, 64, 65, 67, 68], "marcotcr": [6, 11, 18, 38, 44, 67], "lime_text": 6, "limetextexplain": 6, "refer": [6, 11, 12, 18, 37, 43, 47, 57, 58, 59, 60, 61, 66], "doc": [6, 11, 18, 29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "explain_inst": [6, 11, 18], "wordimport": [6, 8, 24], "shaptext": [6, 39], "slundberg": [6, 11, 13, 15, 18, 39, 49, 55, 68], "textclassificationpipelin": [6, 39], "text_classif": 6, "defaultselectionmodel": [6, 11, 18, 37, 43, 66], "_defaultmodelbas": [6, 11, 18], "consist": [6, 41], "1d": 6, "convolut": [6, 20, 56, 58, 59, 60, 61, 62, 63, 66, 68], "l2xtext": [6, 37], "hidden_s": [6, 11, 35, 36, 40], "hidden": [6, 11, 42, 58, 59, 60, 61, 66, 68], "kernel_s": [6, 35, 36, 40, 58, 59, 60, 61, 66, 68], "kernel": 6, "forward": [6, 11, 18, 36, 40, 59, 61, 66], "defaultpredictionmodel": [6, 11, 18, 37, 43, 66], "weight": [6, 11, 12, 16, 18, 19, 20, 36, 37, 40, 42, 62, 64], "gumbel": [6, 11, 18], "softmax": [6, 11, 18, 40, 56, 67], "tau": [6, 11, 18], "k": [6, 11, 18, 35, 36, 40, 56, 57, 62, 63, 64, 65, 67], "selection_model": [6, 11, 18, 37, 43, 66], "prediction_model": [6, 11, 18, 37, 43, 66], "loss_funct": [6, 11, 18], "optim": [6, 11, 12, 16, 18, 19, 20, 35, 36, 40, 42, 54, 57, 58, 59, 60, 61, 66, 68], "learning_r": [6, 11, 12, 16, 18, 19, 20, 35, 36, 40, 42, 59, 61, 66], "num_epoch": [6, 11, 18, 35, 36, 40, 59, 61, 66], "theoret": [6, 11, 18, 37, 43, 66], "perspect": [6, 11, 18, 37, 43, 66], "jianbo": [6, 11, 18, 37, 43, 66], "chen": [6, 11, 18, 37, 43, 66], "le": [6, 11, 18, 37, 43, 66], "song": [6, 11, 18, 37, 43, 66], "martin": [6, 11, 18, 37, 43, 66], "j": [6, 11, 18, 37, 43, 66], "wainwright": [6, 11, 18, 37, 43, 66], "michael": [6, 11, 18, 37, 43, 66], "jordan": [6, 11, 18, 37, 43, 66], "1802": [6, 11, 18, 20, 37, 43, 60, 61, 66], "07814": [6, 11, 18, 37, 43, 66], "float": [6, 10, 11, 13, 16, 18, 26, 35, 59, 61, 66], "maximum": [6, 7, 11, 12, 16, 18, 19, 20, 21, 23, 24, 25, 32, 33, 34, 40], "p": [6, 11, 18, 37, 43, 66, 67], "q": [6, 11, 18, 37, 43, 66], "x_": [6, 11, 18, 37, 43, 66], "nn": [6, 8, 11, 12, 13, 18, 19, 20, 35, 36, 40, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "crossentropyloss": [6, 11, 18, 36, 40, 59, 61, 66], "adamw": [6, 36, 40], "rate": [6, 11, 12, 16, 18, 19, 20], "pick": [6, 11, 18], "32": [6, 11, 18, 36, 40, 52, 58, 60, 66, 68], "64": [6, 11, 18, 42, 58, 60, 68], "128": [6, 11, 18, 35, 36, 40, 42, 58, 59, 60, 61, 68], "epoch": [6, 11, 18, 35, 42, 58, 59, 60, 61, 66, 68], "develop": [7, 12, 16, 29, 32, 33, 34, 40, 41, 46, 51, 52, 53, 56], "wu": [7, 33, 34], "et": [7, 12, 16, 20, 33, 34, 46, 62, 63], "al": [7, 12, 16, 20, 33, 34, 46, 62, 63], "tongshuangwu": [7, 33, 34], "pr": 7, "model_path": 7, "cuda": [7, 36, 40, 56, 59, 61, 65, 66, 67], "max_number_exampl": [7, 12], "context": [7, 34], "concaten": [7, 26, 36, 40, 48, 52, 56, 62, 64], "seper": [7, 34], "ce_typ": 7, "perturb": 7, "blank": 7, "cfexplan": [7, 12, 16, 19, 22, 23, 25], "integratedgradienttext": [8, 35, 36], "ankurtali": [8, 13, 20, 35, 36, 64, 65], "kera": [8, 12, 13, 18, 19, 20, 35, 36, 42, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68], "must": [8, 35, 36, 40, 41], "map": [8, 11, 35, 36], "integrated_gradi": [8, 13, 20], "integratedgradi": [8, 13, 17, 20], "compute_integrated_gradi": [8, 13, 20], "curv": 9, "sklearnbas": [10, 13], "cate_encod": [10, 13], "onehot": [10, 13, 26, 31], "cont_encod": [10, 13], "target_encod": [10, 13], "baseestim": 10, "transformbas": [10, 13, 26], "ident": [10, 13, 26, 48, 52], "minmax": [10, 13, 26, 31, 43, 44, 46, 47, 49, 51, 52], "scale": [10, 13, 26, 31], "proport": [10, 13], "ce": [10, 14, 17, 56], "decision_tre": [10, 50], "shap_tre": 10, "limetabular": [11, 44], "lime_tabular": 11, "limetabularexplain": 11, "featureimport": [11, 13, 15, 23, 25], "kernelexplain": [11, 15], "shap_valu": [11, 15], "partialdependencetabular": [11, 47], "stabl": [11, 47, 52], "partial_depend": [11, 18, 47], "html": [11, 47, 52], "grid_resolut": [11, 18], "candid": 11, "dure": [11, 12, 16, 19, 20], "pdpexplan": [11, 23], "sensitivityanalysistabular": [11, 48], "salib": [11, 48], "sa": 11, "sensitivityexplan": [11, 23], "feedforward": [11, 42], "neural": [11, 58, 59, 60, 61, 66, 68], "network": [11, 20, 37, 42, 43, 58, 59, 60, 61, 62, 63, 66, 68], "l2xtabular": [11, 43], "adam": [11, 18, 35, 58, 59, 60, 61, 66, 68], "Not": [11, 13, 19, 41, 44, 46, 49, 51], "maceexplain": [12, 16, 46, 54], "yang": [12, 16, 46], "paper": [12, 16, 19, 20, 42, 46, 57, 58, 59], "effici": [12, 16, 46], "framework": [12, 16, 34, 46], "cfretriev": 12, "gld": 12, "retriev": 12, "desir": [12, 26, 66], "counterfactualoptim": [12, 16], "x0": [12, 16, 20], "c": [12, 16, 19, 20, 26, 29, 30, 31, 32, 37, 40, 41, 51, 52, 53, 56, 67], "kappa": [12, 16, 19, 20], "binary_search_step": [12, 16, 19, 20, 56, 57, 58, 59, 60, 61], "01": [12, 16, 19, 20, 36, 40, 53, 54, 55], "num_iter": [12, 16, 19, 20, 56, 57, 58, 59, 60, 61], "1000": [12, 16, 19, 20, 48, 62, 64, 67], "grad_clip": [12, 16, 19, 20], "gamma": [12, 16, 20], "autom": [12, 19, 42, 57, 58, 59], "gdpr": [12, 19, 42, 57, 58, 59], "sandra": [12, 19, 42, 57, 58, 59], "wachter": [12, 19, 42, 57, 58, 59], "brent": [12, 19, 42, 57, 58, 59], "mittelstadt": [12, 19, 42, 57, 58, 59], "chri": [12, 19, 42, 57, 58, 59], "russel": [12, 19, 42, 57, 58, 59], "1711": [12, 19, 42, 57, 58, 59], "00399": [12, 19, 42, 57, 58, 59], "hing": [12, 16, 19, 20], "term": [12, 16, 19, 20], "iter": [12, 16, 19, 20], "adjust": [12, 16, 19, 20], "clip": [12, 16, 19, 20], "denomin": [12, 16], "regular": [12, 16, 20], "verbos": [12, 16, 20, 36, 40, 42, 58, 60, 68], "counterfactualexplain": [12, 16, 19, 42, 57, 58, 59, 61], "extract": [12, 22, 23, 26, 42], "inp": 13, "baselin": [13, 20], "output_index": 13, "50": [13, 35, 36, 40, 41, 44, 46, 49, 51, 59, 61, 66], "integratedgradienttabular": 13, "num_random_tri": [13, 20], "trial": [13, 20], "_sample_baselin": 13, "linearbas": 13, "coeffici": [13, 23, 45], "linearexplan": [13, 23], "linearregress": [13, 45], "lasso": 13, "linear_regress": 13, "logisticregress": [13, 45], "logistic_regress": 13, "treebas": 13, "random": [13, 26, 37, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "forest": [13, 37, 38, 48, 52], "structur": [13, 23, 32, 37, 43, 50, 58, 60, 66], "path": [13, 23, 29, 37, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55], "treeexplan": [13, 23], "treeregressor": [13, 50], "regressor": [13, 52], "decisiontreeregressor": 13, "tree_regressor": 13, "treeclassifi": [13, 50], "decisiontreeclassifi": 13, "tree_classifi": 13, "shaptreetabular": 13, "forecast": [14, 15, 16, 25, 53, 55], "shaptimeseri": [15, 55], "higher": [15, 16, 41, 53, 54, 55], "anomal": [15, 16, 53, 54, 55], "smooth_weight": 16, "grid_siz": 16, "reshap": [16, 48, 52, 58, 60, 68], "determin": [16, 37, 53, 54, 55], "smooth": 16, "numer": 16, "revis": 16, "version": [16, 32, 37, 40], "rl": 16, "cem": 17, "limeimag": [18, 67], "top_label": 18, "limeimageexplain": 18, "maskexplan": [18, 22], "shapimag": [18, 68], "background_data": [18, 20], "background": [18, 20], "pixelimport": [18, 20, 22], "partialdependenceimag": 18, "segment": 18, "quickshift": 18, "measur": 18, "averag": [18, 23, 35, 36, 37, 38, 40], "replac": [18, 42], "grid": [18, 23], "resolut": 18, "n_segment": 18, "l2ximag": [18, 66], "upsampl": [18, 66], "been": [19, 20, 37], "255": [19, 20, 31, 58, 60, 68], "integratedgradientimag": [20, 64, 65], "randomli": 20, "selvaraju": [20, 62, 63], "1610": [20, 62, 63], "02391": [20, 62, 63], "gradcamplu": 20, "chattopadhyai": 20, "pdf": 20, "1710": 20, "11063": 20, "cemoptim": 20, "beta": 20, "ae_model": 20, "07623": [20, 60, 61], "l1": 20, "ae": 20, "pn_optim": 20, "pertin": [20, 22, 60, 61], "pp_optim": 20, "contrastiveexplain": [20, 60, 61], "contrastiveexplan": [20, 22], "get_explan": [21, 22, 23, 24, 25], "compon": [21, 37], "dump": [21, 26, 29], "pickl": 21, "unpickl": 21, "byte": 21, "byte_str": 21, "dashfigur": 21, "to_html_div": 21, "to_html": 21, "predictedresult": 21, "classfic": 21, "max_num_subplot": [21, 23, 24], "subplot": [21, 23, 24], "use_heatmap": 22, "item": [22, 23, 24, 25, 41, 51, 52, 59, 61, 66], "entri": [22, 23, 24], "target_label": [22, 23, 24], "heatmap": 22, "importance_scor": [22, 23, 24, 25], "dog": [22, 23, 24, 27, 56], "cat": [22, 23, 24, 27, 36, 37, 40], "boundari": 22, "pn": 22, "pn_label": 22, "pp": 22, "pp_label": 22, "cf": [22, 23, 25], "cf_label": 22, "counterfactualexplan": 22, "feature_valu": 23, "sort": [23, 24, 31], "queri": [23, 25], "font_siz": 23, "font": 23, "tabl": 23, "deviat": [23, 26], "pdp_mean": 23, "pdp_std": 23, "plot_std": 23, "mu": 23, "mu_star": 23, "sigma": 23, "mu_star_conf": 23, "plot_coeffici": 23, "tick": 23, "binari": [23, 35, 36, 37, 38, 40, 42, 56, 57, 58, 59, 60, 61], "add_glob": 23, "whole": [23, 37], "add_loc": 23, "decision_path": 23, "node_ind": 23, "node": 23, "figsiz": 23, "15": [23, 30, 37, 41, 44, 46, 49, 51, 53, 54, 55], "fontsiz": 23, "num_tokens_per_class": 24, "shown": 24, "max_length": [24, 32, 33, 34, 35, 36, 40], "512": 24, "figure_typ": 25, "max_num_variables_to_plot": 25, "25": [25, 52], "bar": 25, "invers": [26, 31, 44, 49], "b": [26, 30, 31], "d": [26, 30, 31, 33], "cate_transform": [26, 31], "cont_transform": [26, 31, 43, 44, 46, 47, 49, 51, 52], "fillnan": 26, "fillnantabular": [26, 31], "pseudo": 26, "recov": 26, "some_imag": 26, "360": 26, "240": [26, 31, 67], "tfidf": [26, 31, 35, 36, 37, 38, 40], "vector": [26, 31, 37, 38], "drop": [26, 41, 42, 48, 53, 54, 55], "get_feature_nam": [26, 31], "input_featur": 26, "zero": [26, 35, 36, 40], "unit": [26, 41, 42, 44, 46, 49, 51, 53, 54, 55], "varianc": 26, "ratio": 26, "miss": 26, "chosen": 26, "itself": 26, "save": 26, "target_transform": [26, 31, 48, 52], "decompos": 26, "hold": [26, 37], "expect": 26, "ith": 26, "00392156862745098": 26, "round2int": 26, "round": 26, "resampl": 26, "bilinear": [26, 66], "smaller": 26, "edg": 26, "strategi": 26, "word2id": [26, 31, 35, 36, 40], "remove_punctu": 26, "pad": [26, 35, 36, 40], "start": [26, 37], "unk": [26, 31], "vocab_s": [26, 35, 36, 40], "re": [26, 37, 38], "sub": 26, "over": 26, "fraction": 26, "random_st": [26, 42], "guarante": 26, "seed": [26, 41, 43, 44, 45, 46, 47, 49, 50, 51], "undersampl": 26, "balanc": 26, "minor": 26, "decreas": [26, 41], "major": 26, "oversampl": 26, "increas": [26, 37, 41], "data_explan": [27, 41], "predic": 27, "host": [27, 38], "127": [27, 29, 32, 40, 41, 51, 52, 53, 56], "port": 27, "8050": [27, 29, 32, 40, 41, 51, 52, 53, 56], "omnixai": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "render": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "sphinx": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "delet": [29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "cell": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "io": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "pio": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "png": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "os": [29, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55], "join": [29, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55], "now": [29, 35, 36, 37, 40, 41, 51, 52, 56, 59, 61, 66], "than": [29, 34, 37], "onc": [29, 37], "n": [29, 30, 35, 36, 40], "append": [29, 33, 36, 40, 53, 54, 55, 62, 64], "print": [29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68], "serv": [29, 32, 40, 41, 51, 52, 53, 56], "flask": [29, 32, 40, 41, 51, 52, 53, 56], "34": [29, 30, 31, 32, 40, 41, 51, 52, 53, 56], "lazi": [29, 32, 40, 41, 51, 52, 53, 56], "environ": [29, 32, 34, 40, 41, 51, 52, 53, 56], "product": [29, 32, 40, 41, 51, 52, 53, 56], "warn": [29, 32, 37, 40, 41, 51, 52, 53, 56, 68], "server": [29, 32, 40, 41, 51, 52, 53, 56], "deploy": [29, 32, 40, 41, 51, 52, 53, 56], "wsgi": [29, 32, 40, 41, 51, 52, 53, 56], "debug": [29, 32, 40, 41, 51, 52, 53, 56], "off": [29, 32, 37, 40, 41, 51, 52, 53, 56], "press": [29, 32, 40, 41, 51, 52, 53, 56], "ctrl": [29, 32, 40, 41, 51, 52, 53, 56], "quit": [29, 32, 40, 41, 51, 52, 53, 56], "notebook": 30, "how": [30, 37, 41], "f": [30, 31, 35, 41, 51, 52], "39": [30, 31, 41, 44, 46, 49, 51, 52, 62, 64, 67], "ye": [30, 31, 37, 42], "swap": 30, "digit": [30, 58, 59, 60, 61, 66, 68], "torchvis": [30, 56, 57, 59, 61, 63, 65, 66, 67], "download": [30, 59, 61, 66], "10000": [30, 53, 54, 55], "11": [30, 31, 37, 41, 48, 68], "displai": [30, 31], "loop": 30, "camera": [30, 31, 56, 57, 63], "what": [30, 32, 33, 34, 35, 36, 37, 39], "great": [30, 32, 33, 35, 36, 37, 39, 40], "movi": [30, 32, 33, 35, 36, 39, 40], "tast": [30, 33, 35, 36, 39], "best": [30, 33, 35, 36, 39, 40], "film": [30, 33, 35, 36, 39, 40], "ever": [30, 33, 35, 36, 39, 40], "ve": [30, 33, 35, 36, 39, 40], "never": [30, 33, 35, 36, 39, 40, 41, 44, 46, 49, 51], "watch": [30, 33, 35, 36, 39, 40], "someth": [30, 33, 35, 36, 37, 39, 40], "bad": [30, 33, 35, 36, 37, 39, 40], "len": [30, 35, 36, 40, 56, 57, 62, 63, 64, 65, 67], "17": [30, 39, 52, 53, 54, 55], "18": [30, 37, 52], "29": 30, "1319": 30, "76541": 30, "610": 30, "314": 30, "173": 30, "19": [30, 37], "ts_a": 30, "ts_b": 30, "try": [31, 43, 44, 46, 47, 49, 51, 52], "22474487": 31, "120": 31, "6227660078332259": 31, "4736296010332684": 31, "5178561161676974": 31, "680918560398684": 31, "7265094189091538": 31, "3632547094545769": 31, "2762645695949752": 31, "unknown": 31, "xxx": 31, "lt": [31, 41, 44, 46, 49, 51], "gt": [31, 41, 44, 46, 49, 51], "limit": [32, 40], "interview": 32, "neither": 32, "funni": 32, "nor": 32, "witti": 32, "even": [32, 37], "like": [32, 37], "overal": [32, 37], "distilbert": [32, 33, 39], "uncas": [32, 33, 39], "finetun": [32, 33, 39], "sst": [32, 33, 39], "english": [32, 33, 39], "return_all_scor": [32, 33, 39], "ss": 32, "There": [32, 40, 56], "partit": [32, 37, 39], "3it": 32, "70": 32, "info": [32, 33, 34, 40], "polyjuice_wrapp": [32, 33, 34, 40], "setup": [32, 33, 34, 40], "spaci": [32, 33, 34, 40], "processor": [32, 33, 34, 40], "perplex": [32, 33, 34, 40], "scorer": [32, 33, 34, 40], "ask": [32, 33, 34, 37, 40], "truncat": [32, 33, 34, 40], "predefin": [32, 33, 34, 40], "werkzeug": [32, 40], "idx2label": [33, 56, 57, 62, 63, 64, 65, 67], "build": [33, 34, 41, 59, 61], "def": [33, 34, 35, 36, 40, 42, 53, 54, 55, 59, 61, 62, 64, 66, 67], "_predict": [33, 34], "pred": 33, "els": [33, 35, 36, 37, 40, 56, 58, 59, 60, 61, 65, 66, 67, 68], "unittest": [34, 35, 45, 67], "model_nam": 34, "deepset": 34, "roberta": 34, "squad2": 34, "isinst": 34, "farm": 34, "give": [34, 37], "freedom": 34, "peopl": [34, 37], "switch": 34, "covers": 34, "electr": 34, "vehicl": 34, "emit": 34, "less": [34, 37], "harm": 34, "pollut": 34, "convent": 34, "ultim": 34, "cleaner": [34, 41, 44, 46, 49, 51], "human": [34, 37], "beings": 34, "eletr": 34, "fetch_20newsgroup": [35, 36, 37, 38, 40], "textmodel": [35, 36, 40], "num_embed": [35, 36, 40], "num_class": [35, 36, 40, 58, 60, 68], "super": [35, 36, 40, 59, 61, 66], "embedding_s": [35, 36, 40], "embeddings_initi": 35, "randomuniform": 35, "minval": 35, "maxval": 35, "conv_lay": [35, 36, 40, 59, 61, 66], "conv1d": [35, 36, 40], "activ": [35, 36, 37, 40, 42, 58, 60, 68], "relu": [35, 36, 40, 58, 59, 60, 61, 66, 68], "dropout": [35, 36, 40, 58, 59, 60, 61, 66, 68], "output_lay": [35, 36, 40], "dens": [35, 42, 58, 59, 60, 61, 66, 68], "expand_dim": [35, 58, 60, 62, 64, 68], "axi": [35, 36, 40, 42, 48, 52, 58, 60, 62, 64, 68], "reduce_max": 35, "concat": 35, "relat": [35, 36, 37, 38, 40], "read_csv": [35, 36, 40, 42, 53, 54, 55], "home": [35, 36, 40, 68], "ywz": [35, 36, 40, 68], "labeledtraindata": [35, 36, 40], "tsv": [35, 36, 40], "x_train": [35, 36, 37, 38, 40, 42, 48, 52, 58, 59, 60, 61, 68], "y_train": [35, 36, 37, 38, 40, 42, 48, 52, 58, 59, 60, 61, 68], "astyp": [35, 36, 40, 42, 53, 54, 55, 58, 60, 68], "x_test": [35, 36, 37, 38, 40, 42, 48, 52, 58, 59, 60, 61, 68], "y_test": [35, 36, 37, 38, 40, 42, 48, 52, 58, 59, 60, 61, 68], "max_len": [35, 36, 40], "float32": [35, 36, 40, 42, 58, 60, 68], "evalu": [35, 36, 40, 42, 58, 59, 60, 61, 66, 68], "1e": [35, 36, 40, 59, 61, 66], "loss_fn": 35, "sparsecategoricalcrossentropi": 35, "from_logit": [35, 42, 58, 60, 68], "train_dataset": 35, "from_tensor_slic": 35, "shuffl": [35, 36, 40, 59, 61, 66], "buffer_s": 35, "1024": 35, "enumer": [35, 59, 61, 66], "gradienttap": 35, "tape": 35, "trainable_weight": 35, "apply_gradi": 35, "zip": [35, 59, 61, 66, 67], "200": [35, 42, 52], "6866752505302429": 35, "4109169542789459": 35, "21237820386886597": 35, "1540527492761612": 35, "08126655220985413": 35, "02999718114733696": 35, "008433952927589417": 35, "009998280555009842": 35, "0030068857595324516": 35, "001554026734083891": 35, "argmax": [35, 36, 40], "accuraci": [35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 58, 59, 60, 61, 66, 68], "f1_score": [35, 36, 37, 38, 40], "8560798903465829": 35, "id_to_word": [35, 36, 40], "util": [36, 40, 42, 58, 59, 60, 61, 66, 68], "trainer": [36, 40], "inputdata": [36, 40, 59, 61, 66], "dataload": [36, 40, 59, 61, 66], "normal_": [36, 40], "modulelist": [36, 40], "unsqueez": [36, 40, 67], "dim": [36, 40, 56, 67], "permut": [36, 40], "devic": [36, 40, 56, 59, 61, 65, 66, 67], "is_avail": [36, 40, 56, 59, 61, 65, 66, 67], "cpu": [36, 40, 56, 59, 61, 65, 66, 67], "optimizer_class": [36, 40], "loss_func": [36, 40, 59, 61, 66], "train_x": [36, 40], "train_i": [36, 40], "complet": [36, 37, 40, 43, 66], "0008": 36, "eval": [36, 40, 59, 61, 66, 67], "data_load": [36, 40], "collate_fn": [36, 40], "collate_func": [36, 40], "detach": [36, 40, 66, 67], "8458027386386188": 36, "advantag": [37, 43, 66], "fast": [37, 43, 66], "disadvantag": [37, 43, 66], "qualiti": [37, 43, 66], "highli": [37, 41, 43, 66], "affect": [37, 43, 66], "factor": [37, 43, 66], "hyperparamet": [37, 43], "ensembl": [37, 38, 45, 48, 51, 52], "alt": [37, 38], "atheism": [37, 38], "soc": [37, 38], "religion": [37, 38], "christian": [37, 38], "newsgroups_train": [37, 38], "newsgroups_test": [37, 38], "tfdif": [37, 38], "train_vector": [37, 38], "test_vector": [37, 38], "randomforestclassifi": [37, 38], "500": [37, 38], "925233644859813": 37, "idx": [37, 38], "83": [37, 38], "0039": 37, "8674698795180723": 37, "subject": [37, 38], "request": 37, "darwin": 37, "fish": 37, "organ": [37, 38], "univers": 37, "mexico": 37, "albuquerqu": 37, "recent": 37, "seen": 37, "anyon": [37, 38], "contact": 37, "email": 37, "me": 37, "john": 37, "dan": 37, "rose": 37, "aros": 37, "nation": [37, 38], "repent": 37, "my": 37, "own": [37, 41, 44, 46, 49, 51], "view": 37, "63": 37, "mcovingt": 37, "covington": 37, "heard": 37, "radio": 37, "todai": 37, "student": 37, "confer": 37, "were": 37, "america": 37, "sin": [37, 38], "sexual": 37, "promiscu": 37, "repli": 37, "ca": 37, "claim": 37, "someon": 37, "am": 37, "fact": 37, "him": 37, "jesu": 37, "equip": 37, "judg": 37, "lewi": 37, "essai": 37, "world": 37, "war": 37, "ii": 37, "leader": 37, "britain": 37, "urg": 37, "horror": 37, "strongli": 37, "disagre": 37, "turn": 37, "behav": 37, "incred": 37, "toward": 37, "god": 37, "encourag": 37, "forc": 37, "folk": 37, "particip": 37, "directli": [37, 45], "oppos": 37, "written": 37, "far": 37, "abov": [37, 41, 42, 59, 61, 66], "luxuri": 37, "live": 37, "land": 37, "slaughter": 37, "children": 37, "million": 37, "stricken": 37, "out": 37, "honor": 37, "due": 37, "everi": 37, "ow": 37, "apolog": 37, "bit": [37, 41], "public": 37, "said": [37, 38], "decai": 37, "bibl": 37, "quiz": 37, "distribut": 37, "articl": 37, "healta": 37, "tammi": 37, "r": [37, 56, 57, 62, 63, 64, 65, 67], "heali": 37, "coven": 37, "he": 37, "idol": 37, "worship": 37, "high": 37, "priest": 37, "could": 37, "enter": 37, "holi": 37, "year": 37, "dai": 37, "aton": 37, "familiar": 37, "knowledg": 37, "languag": 37, "believ": 37, "translat": 37, "would": 37, "had": 37, "think": 37, "wrong": 37, "again": 37, "just": 37, "suggest": 37, "correct": 37, "dean": 37, "danb": 37, "babcock": 37, "thought": 37, "commun": 37, "compani": 37, "voic": 37, "bil": 37, "bill": 37, "conner": 37, "jame": 37, "felder": 37, "spbach": 37, "wrote": 37, "logic": 37, "alert": 37, "incredul": 37, "hard": 37, "doe": 37, "liar": 37, "pursuas": 37, "look": 37, "koresh": 37, "yourself": 37, "basi": 37, "reject": 37, "account": 37, "thing": 37, "madalyn": 37, "face": 37, "silli": 37, "okai": 37, "disbeliev": 37, "admit": 37, "fallaci": 37, "awar": 37, "reader": 37, "assert": 37, "mam": 37, "mike": 37, "mcangu": 37, "american": 37, "evolut": 37, "mat": 37, "tin": 37, "pl9": 37, "53": [37, 41, 44, 46, 49, 51], "tue": 37, "apr": 37, "1993": 37, "gmt": 37, "robert": 37, "singleton": 37, "bob": 37, "sure": 37, "exclus": 37, "lend": 37, "notion": 37, "posterior": 37, "atheist": 37, "pitch": 37, "thu": 37, "necessarili": 37, "reduc": 37, "quantiti": 37, "theist": 37, "divin": 37, "fall": 37, "prei": 37, "ockham": 37, "razor": 37, "phenomenon": 37, "being": 37, "satisfactorili": 37, "independ": 37, "evid": 37, "occam": 37, "law": 37, "natur": 37, "often": 37, "end": 37, "seem": 37, "odd": 37, "simultan": 37, "condemn": 37, "primit": 37, "unscientif": 37, "childish": 37, "yet": 37, "complex": 37, "scientif": 37, "straightforeward": 37, "appar": 37, "cute": 37, "character": 37, "howev": 37, "inconsist": 37, "statement": 37, "still": 37, "unnecessari": 37, "level": 37, "idea": 37, "themselv": 37, "thei": [37, 41], "unnecessarili": 37, "descript": 37, "part": 37, "sfp": 37, "sheila": 37, "patterson": 37, "mari": 37, "assumpt": 37, "cornel": 37, "cit": 37, "22": [37, 41, 44, 46, 49, 51, 52], "mpaul": 37, "marxhausen": 37, "paul": 37, "feel": 37, "better": 37, "phrase": 37, "sai": 37, "parent": 37, "sanctifi": 37, "beyond": 37, "sound": 37, "inabl": 37, "grasp": 37, "grace": 37, "incarn": 37, "through": 37, "alwai": 37, "impress": 37, "chose": 37, "woman": 37, "bring": 37, "himself": 37, "prove": 37, "down": 37, "hi": 37, "perfect": 37, "touch": 37, "ah": 37, "wonder": 37, "ithaca": 37, "ny": 37, "mark": 37, "boston": [37, 48], "asid": 37, "moder": 37, "rick": 37, "granberri": 37, "wo": 37, "quot": 37, "error": 37, "opinion": 37, "writer": 37, "plain": 37, "confus": 37, "come": 37, "lexington": 37, "church": 37, "brought": 37, "team": 37, "actual": 37, "il": 37, "up": 37, "friend": 37, "tell": 37, "go": 37, "northeast": 37, "wast": 37, "talent": 37, "realli": 37, "kind": [37, 51, 52], "insid": 37, "joke": 37, "took": 37, "well": 37, "inde": 37, "misinform": 37, "sun": 37, "ok": 37, "mail": 37, "marshal": 37, "kevin": 37, "death": 37, "penalti": 37, "polit": 37, "virginia": 37, "tech": [37, 41, 44, 46, 49, 51], "scienc": 37, "dept": 37, "blacksburg": 37, "va": 37, "46": 37, "fascin": 37, "argu": 37, "abort": 37, "defend": 37, "homosexu": 37, "popul": [37, 52], "control": 37, "insist": 37, "biolog": 37, "punish": 37, "benedikt": 37, "contardictori": 37, "case": 37, "excel": 37, "growth": 37, "sorri": 37, "escap": 37, "assum": 37, "alik": 37, "vari": 37, "greatli": 37, "attack": 37, "presum": 37, "present": 37, "person": 37, "right": 37, "regardless": 37, "arrog": 37, "individu": 37, "bodi": 37, "domain": 37, "jcj": 37, "becom": [37, 41], "huh": 37, "whuzzat": 37, "muirm": 37, "maxwel": 37, "muir": 37, "candor": 37, "happi": 37, "proven": 37, "problem": 37, "broken": 37, "went": 37, "journei": 37, "lukewarm": 37, "agnostic": 37, "although": 37, "faith": 37, "jeff": 37, "johnson": 37, "9230769230769231": 38, "nntp": 38, "murder": 38, "7it": 39, "51": [39, 41, 42], "0010": 40, "8492442322991249": 40, "tensor": [40, 56, 57, 59, 61, 63, 65], "preprocess_func": [40, 58, 60, 68], "postprocess_func": 40, "state": [41, 44, 46, 49, 51], "gov": [41, 44, 46, 49, 51], "77516": [41, 44, 46, 49, 51], "bachelor": [41, 44, 46, 49, 51], "emp": [41, 44, 46, 49, 51], "inc": [41, 44, 46, 49, 51], "83311": [41, 44, 46, 49, 51], "38": [41, 44, 46, 49, 51], "privat": [41, 44, 46, 49, 51], "215646": [41, 44, 46, 49, 51], "hs": [41, 44, 46, 49, 51], "234721": [41, 44, 46, 49, 51], "11th": [41, 44, 46, 49, 51], "338409": [41, 44, 46, 49, 51], "32556": [41, 44, 46, 49, 51], "257302": [41, 44, 46, 49, 51], "assoc": [41, 44, 46, 49, 51], "acdm": [41, 44, 46, 49, 51], "32557": [41, 44, 46, 49, 51], "40": [41, 44, 46, 49, 51], "154374": [41, 44, 46, 49, 51], "32558": [41, 44, 46, 49, 51], "58": [41, 44, 46, 49, 51], "151910": [41, 44, 46, 49, 51], "32559": [41, 44, 46, 49, 51], "201490": [41, 44, 46, 49, 51], "32560": [41, 44, 46, 49, 51], "52": [41, 44, 46, 49, 51, 52], "287927": [41, 44, 46, 49, 51], "marri": [41, 44, 46, 49, 51], "adm": [41, 44, 46, 49, 51], "cleric": [41, 44, 46, 49, 51], "white": [41, 44, 46, 49, 51], "civ": [41, 44, 46, 49, 51], "spous": [41, 44, 46, 49, 51], "exec": [41, 44, 46, 49, 51], "manageri": [41, 44, 46, 49, 51], "husband": [41, 44, 46, 49, 51], "divorc": [41, 44, 46, 49, 51], "handler": [41, 44, 46, 49, 51], "prof": [41, 44, 46, 49, 51], "specialti": [41, 44, 46, 49, 51], "wife": [41, 44, 46, 49, 51], "op": [41, 44, 46, 49, 51], "inspct": [41, 44, 46, 49, 51], "widow": [41, 44, 46, 49, 51], "unmarri": [41, 44, 46, 49, 51], "child": [41, 44, 46, 49, 51], "2174": [41, 44, 46, 49, 51], "50k": [41, 44, 46, 49, 51], "cuba": [41, 44, 46, 49, 51], "15024": [41, 44, 46, 49, 51], "32561": [41, 44, 46, 49, 51], "lead": 41, "potenti": 41, "sociolog": 41, "bia": 41, "observ": [41, 52], "strong": 41, "matrit": 41, "imbalanc": 41, "among": 41, "therefor": 41, "avoid": 41, "rough": 41, "educt": 41, "least": 41, "them": [41, 56, 62, 64], "rel": 41, "low": 41, "12345": 41, "accuracy_scor": [41, 43, 44, 46, 47, 49, 51], "26048": [41, 43, 44, 46, 47, 49, 51], "6513": [41, 43, 44, 46, 47, 49, 51], "8593582066635959": 41, "describ": 41, "longer": [41, 68], "But": 41, "causal": 41, "caus": 41, "unclear": 41, "1653": [41, 43, 44, 49, 50, 51], "1658": [41, 51], "ocup": 41, "confusion_matrix": [41, 51], "roc": [41, 51], "precision_recal": [41, 51], "cumulative_gain": [41, 51], "lift_curv": [41, 51], "standardscal": 42, "diabetes_data": 42, "file_path": 42, "to_replac": 42, "No": 42, "polyuria": 42, "polydipsia": 42, "sudden": 42, "weak": 42, "polyphagia": 42, "genit": 42, "thrush": 42, "blur": 42, "itch": 42, "irrit": 42, "delai": 42, "heal": 42, "paresi": 42, "muscl": 42, "stiff": 42, "alopecia": 42, "obes": 42, "x_train_un": 42, "x_test_un": 42, "test_siz": 42, "stratifi": 42, "sc": 42, "fit_transform": 42, "train_tf_model": 42, "to_categor": [42, 58, 60, 68], "sequenti": [42, 58, 59, 60, 61, 66, 68], "softplu": 42, "schedul": 42, "exponentialdecai": 42, "initial_learning_r": 42, "decay_step": 42, "decay_r": 42, "99": [42, 56, 57, 58, 59, 61, 66], "staircas": 42, "sgd": 42, "momentum": 42, "nesterov": 42, "categoricalcrossentropi": [42, 58, 60, 68], "compil": [42, 58, 60, 68], "train_loss": 42, "train_accuraci": 42, "test_loss": 42, "test_accuraci": 42, "4f": 42, "csv": [42, 53, 54, 55], "416": 42, "104": 42, "0631": 42, "9856": [42, 58], "0568": 42, "9808": 42, "necessari": [43, 44, 46, 51, 52], "labels_train": [43, 44, 46, 47, 49], "labels_test": [43, 44, 46, 47, 49], "108": [43, 44, 46, 47, 49, 51], "8668816213726394": [43, 44, 46, 47, 49, 51], "1953": 43, "8647768803169436": 43, "test_x": [43, 44, 45, 49, 50, 54, 55], "1655": [44, 49], "pprint": 45, "valid": [45, 50], "8518347919545525": 45, "fix": 46, "pdo": 47, "load_boston": 48, "rf": [48, 52], "randomforestregressor": [48, 52], "mserror": [48, 52], "404": 48, "102": 48, "215751067843145": 48, "8446184553968985": 50, "readi": [51, 52], "fetch_california_h": 52, "medinc": 52, "houseag": 52, "averoom": 52, "avebedrm": 52, "aveoccup": 52, "latitud": 52, "3252": 52, "41": 52, "984127": 52, "023810": 52, "322": 52, "555556": 52, "37": 52, "88": 52, "3014": 52, "21": 52, "238137": 52, "971880": 52, "2401": 52, "109842": 52, "86": 52, "2574": 52, "288136": 52, "073446": 52, "496": 52, "802260": 52, "85": 52, "6431": 52, "817352": 52, "073059": 52, "558": 52, "547945": 52, "8462": 52, "281853": 52, "081081": 52, "565": 52, "181467": 52, "20635": 52, "5603": 52, "045455": 52, "133333": 52, "845": 52, "560606": 52, "48": 52, "20636": 52, "5568": 52, "114035": 52, "315789": 52, "356": 52, "122807": 52, "49": 52, "20637": 52, "7000": 52, "205543": 52, "120092": 52, "1007": 52, "325635": 52, "43": 52, "20638": 52, "8672": 52, "329513": 52, "171920": 52, "741": 52, "123209": 52, "20639": 52, "3886": 52, "254717": 52, "162264": 52, "1387": 52, "616981": 52, "longitud": 52, "122": 52, "23": 52, "526": 52, "585": 52, "24": 52, "521": 52, "413": 52, "422": 52, "121": 52, "09": 52, "781": 52, "771": 52, "923": 52, "847": 52, "894": 52, "20640": 52, "16512": 52, "4128": 52, "338793822760024": 52, "26970328040007546": 52, "residu": 52, "sythent": [53, 54, 55], "renam": [53, 54, 55], "horizont": [53, 54, 55], "1970": [53, 54, 55], "928031": [53, 54, 55], "05": [53, 54, 55], "156620": [53, 54, 55], "390650": [53, 54, 55], "400804": [53, 54, 55], "874490": [53, 54, 55], "02": [53, 54, 55], "04": [53, 54, 55], "55": [53, 54, 55], "362724": [53, 54, 55], "657373": [53, 54, 55], "472341": [53, 54, 55], "033154": [53, 54, 55], "950466": [53, 54, 55], "9150": [53, 54, 55], "9300": [53, 54, 55], "percentil": [53, 54, 55], "90": [53, 54, 55], "anomaly_scor": [53, 54, 55], "sum": [53, 54, 55], "98": [53, 54, 59, 61, 66], "json": [56, 57, 62, 63, 64, 65, 67], "img_1": 56, "dog_cat": [56, 65, 67], "img_2": 56, "img_3": 56, "visul": 56, "imagenet_class_index": [56, 57, 62, 63, 64, 65, 67], "read_fil": [56, 57, 62, 63, 64, 65, 67], "class_idx": [56, 57, 62, 63, 64, 65, 67], "sent": 56, "purpos": 57, "pyplot": [58, 59, 60, 61, 68], "plt": [58, 59, 60, 61, 68], "img_row": [58, 60, 68], "img_col": [58, 60, 68], "load_data": [58, 60, 68], "backend": [58, 60, 68], "image_data_format": [58, 60, 68], "channels_first": [58, 60, 68], "input_shap": [58, 60, 68], "train_img": [58, 60, 66, 68], "conv2d": [58, 59, 60, 61, 66, 68], "maxpooling2d": [58, 60, 68], "pool_siz": [58, 60, 68], "flatten": [58, 59, 60, 61, 66, 68], "validation_data": [58, 60, 68], "469": [58, 60, 68], "2s": [58, 60, 68], "5m": [58, 60, 68], "1696": 58, "9492": 58, "val_loss": [58, 60, 68], "0436": 58, "val_accuraci": [58, 60, 68], "9855": [58, 68], "0478": 58, "0352": 58, "9882": 58, "0324": 58, "9896": [58, 60], "0315": 58, "9892": [58, 60], "0223": 58, "9929": 58, "0320": 58, "9887": [58, 60], "0179": 58, "9940": 58, "0314": 58, "9901": 58, "0141": 58, "9952": 58, "0365": 58, "9888": 58, "0113": 58, "9960": 58, "9903": [58, 68], "0109": [58, 60, 68], "9965": 58, "0297": [58, 60], "9918": 58, "0083": 58, "9972": 58, "0337": 58, "0072": [58, 68], "9976": 58, "0382": 58, "9895": [58, 60], "03824701905250549": 58, "9894999861717224": 58, "__len__": [59, 61, 66], "__getitem__": [59, 61, 66], "mnistnet": [59, 61, 66], "maxpool2d": [59, 61, 66], "fc_layer": [59, 61, 66], "320": [59, 61, 66], "train_load": [59, 61, 66], "test_load": [59, 61, 66], "lr": [59, 61, 66], "zero_grad": [59, 61, 66], "backward": [59, 61, 66], "correct_pr": [59, 61, 66], "total_pr": [59, 61, 66], "_": [59, 61, 66], "correct_count": [59, 61, 66], "1f": [59, 61, 66], "97": [59, 61], "1712": 60, "9493": 60, "0509": 60, "9837": 60, "0467": 60, "9857": 60, "0364": 60, "9880": 60, "0331": 60, "0323": [60, 68], "9884": 60, "0226": 60, "9927": 60, "0345": 60, "9890": 60, "0171": 60, "9942": 60, "0371": 60, "0150": 60, "9949": [60, 68], "9906": [60, 68], "9966": 60, "0428": 60, "0101": 60, "9967": 60, "0356": 60, "0086": 60, "9969": 60, "0393": 60, "0065": [60, 68], "9977": 60, "0399": 60, "9898": 60, "03988948091864586": 60, "989799976348877": 60, "mobilenet_v2": [62, 64], "dog_cat_2": [62, 64], "mobilenetv2": [62, 64], "include_top": [62, 64], "img_to_arrai": [62, 64], "preprocess_input": [62, 64], "input_img": [62, 67], "top_indic": [62, 64], "argsort": [62, 64], "243": [62, 64], "242": [62, 64], "boxer": [62, 64], "282": [62, 64], "tabbi": [62, 64], "292": [62, 64], "tiger": [62, 64], "inception_v3": [65, 67], "96": 66, "align_corn": 66, "sinc": 66, "old": 66, "document": 66, "2665": 66, "8901166666666667": 66, "incept": 67, "probs_top_5": 67, "topk": 67, "93592954": 67, "239": [67, 68], "bernese_mountain_dog": 67, "038448237": 67, "241": 67, "entlebuch": 67, "023756476": 67, "appenzel": 67, "0018181928": 67, "238": 67, "greater_swiss_mountain_dog": 67, "113302e": 67, "06": 67, "214": 67, "gordon_sett": 67, "batch_predict": 67, "prob": 67, "hide_color": 67, "1724": 68, "9487": 68, "0458": 68, "0466": 68, "9852": 68, "0333": 68, "9885": 68, "0298": 68, "9891": 68, "0207": 68, "9933": 68, "0286": 68, "0158": 68, "0295": 68, "9907": 68, "0125": 68, "9962": 68, "0290": 68, "9904": 68, "9963": 68, "0283": 68, "9902": 68, "0090": 68, "9970": 68, "9978": 68, "0317": 68, "9912": 68, "9974": 68, "0359": 68, "9915": 68, "03591015189886093": 68, "9915000200271606": 68, "anaconda3": 68, "lib": 68, "python3": 68, "site": 68, "_deep": 68, "deep_tf": 68, "set_learning_phas": 68, "deprec": 68, "2020": 68, "instruct": 68, "updat": 68, "pass": 68, "__call__": 68}, "objects": {"": [[1, 0, 0, "-", "omnixai"]], "omnixai": [[2, 0, 0, "-", "data"], [3, 0, 0, "-", "explainers"], [21, 0, 0, "-", "explanations"], [26, 0, 0, "-", "preprocessing"], [27, 0, 0, "-", "visualization"]], "omnixai.data": [[2, 0, 0, "-", "base"], [2, 0, 0, "-", "image"], [2, 0, 0, "-", "tabular"], [2, 0, 0, "-", "text"], [2, 0, 0, "-", "timeseries"]], "omnixai.data.base": [[2, 1, 1, "", "Data"]], "omnixai.data.base.Data": [[2, 2, 1, "", "data_type"], [2, 3, 1, "", "values"]], "omnixai.data.image": [[2, 1, 1, "", "Image"]], "omnixai.data.image.Image": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "image_shape"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pil"], [2, 2, 1, "", "values"]], "omnixai.data.tabular": [[2, 1, 1, "", "Tabular"]], "omnixai.data.tabular.Tabular": [[2, 2, 1, "", "categorical_columns"], [2, 2, 1, "", "columns"], [2, 2, 1, "", "continuous_columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "feature_columns"], [2, 3, 1, "", "get_continuous_bounds"], [2, 3, 1, "", "get_continuous_medians"], [2, 3, 1, "", "get_target_column"], [2, 3, 1, "", "iloc"], [2, 3, 1, "", "remove_target_column"], [2, 2, 1, "", "shape"], [2, 2, 1, "", "target_column"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "values"]], "omnixai.data.text": [[2, 1, 1, "", "Text"]], "omnixai.data.text.Text": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "split"], [2, 3, 1, "", "to_str"], [2, 3, 1, "", "to_tokens"], [2, 2, 1, "", "values"]], "omnixai.data.timeseries": [[2, 1, 1, "", "Timeseries"]], "omnixai.data.timeseries.Timeseries": [[2, 2, 1, "", "batch_size"], [2, 2, 1, "", "columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "from_pd"], [2, 2, 1, "", "index"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "ts_len"], [2, 2, 1, "", "values"]], "omnixai.explainers": [[3, 0, 0, "-", "base"], [4, 0, 0, "-", "data"], [9, 0, 0, "-", "prediction"]], "omnixai.explainers.base": [[3, 1, 1, "", "AutoExplainerBase"], [3, 1, 1, "", "ExplainerABCMeta"], [3, 1, 1, "", "ExplainerBase"]], "omnixai.explainers.base.AutoExplainerBase": [[3, 3, 1, "", "explain"], [3, 3, 1, "", "explain_global"], [3, 2, 1, "", "explainer_names"], [3, 3, 1, "", "list_explainers"]], "omnixai.explainers.base.ExplainerBase": [[3, 3, 1, "", "explain"], [3, 2, 1, "", "explanation_type"]], "omnixai.explainers.data": [[4, 1, 1, "", "ChiSquare"], [4, 1, 1, "", "CorrelationAnalyzer"], [4, 1, 1, "", "DataAnalyzer"], [4, 1, 1, "", "ImbalanceAnalyzer"], [4, 1, 1, "", "MutualInformation"], [4, 0, 0, "-", "auto"], [4, 0, 0, "-", "chi_square"], [4, 0, 0, "-", "correlation"], [4, 0, 0, "-", "imbalance"], [4, 0, 0, "-", "mutual_info"]], "omnixai.explainers.data.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.DataAnalyzer": [[4, 3, 1, "", "explain"], [4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.auto": [[4, 1, 1, "", "DataAnalyzer"]], "omnixai.explainers.data.auto.DataAnalyzer": [[4, 3, 1, "", "explain"], [4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.chi_square": [[4, 1, 1, "", "ChiSquare"]], "omnixai.explainers.data.chi_square.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.correlation": [[4, 1, 1, "", "CorrelationAnalyzer"]], "omnixai.explainers.data.correlation.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.imbalance": [[4, 1, 1, "", "ImbalanceAnalyzer"]], "omnixai.explainers.data.imbalance.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.mutual_info": [[4, 1, 1, "", "MutualInformation"]], "omnixai.explainers.data.mutual_info.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp": [[6, 0, 0, "-", "agnostic"], [5, 0, 0, "-", "auto"], [7, 0, 0, "-", "counterfactual"], [8, 0, 0, "-", "specific"]], "omnixai.explainers.nlp.agnostic": [[6, 0, 0, "-", "l2x"], [6, 0, 0, "-", "lime"], [6, 0, 0, "-", "shap"]], "omnixai.explainers.nlp.agnostic.l2x": [[6, 1, 1, "", "DefaultPredictionModel"], [6, 1, 1, "", "DefaultSelectionModel"], [6, 1, 1, "", "L2XText"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultPredictionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultSelectionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.L2XText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.lime": [[6, 1, 1, "", "LimeText"]], "omnixai.explainers.nlp.agnostic.lime.LimeText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.shap": [[6, 1, 1, "", "ShapText"]], "omnixai.explainers.nlp.agnostic.shap.ShapText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.auto": [[5, 1, 1, "", "NLPExplainer"]], "omnixai.explainers.nlp.auto.NLPExplainer": [[5, 3, 1, "", "list_explainers"]], "omnixai.explainers.nlp.counterfactual": [[7, 0, 0, "-", "polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice": [[7, 1, 1, "", "Polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice.Polyjuice": [[7, 4, 1, "", "alias"], [7, 3, 1, "", "explain"], [7, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.specific": [[8, 0, 0, "-", "ig"]], "omnixai.explainers.nlp.specific.ig": [[8, 1, 1, "", "IntegratedGradientText"]], "omnixai.explainers.nlp.specific.ig.IntegratedGradientText": [[8, 4, 1, "", "alias"], [8, 3, 1, "", "explain"], [8, 4, 1, "", "explanation_type"]], "omnixai.explainers.prediction": [[9, 1, 1, "", "PredictionAnalyzer"]], "omnixai.explainers.prediction.PredictionAnalyzer": [[9, 4, 1, "", "alias"], [9, 3, 1, "", "explain"], [9, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular": [[11, 0, 0, "-", "agnostic"], [10, 0, 0, "-", "auto"], [10, 0, 0, "-", "base"], [12, 0, 0, "-", "counterfactual"], [13, 0, 0, "-", "specific"]], "omnixai.explainers.tabular.agnostic.L2X": [[11, 0, 0, "-", "l2x"]], "omnixai.explainers.tabular.agnostic.L2X.l2x": [[11, 1, 1, "", "DefaultPredictionModel"], [11, 1, 1, "", "DefaultSelectionModel"], [11, 1, 1, "", "L2XTabular"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultPredictionModel": [[11, 3, 1, "", "forward"], [11, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultSelectionModel": [[11, 3, 1, "", "forward"], [11, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.L2XTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic": [[11, 0, 0, "-", "lime"], [11, 0, 0, "-", "pdp"], [11, 0, 0, "-", "sensitivity"], [11, 0, 0, "-", "shap"]], "omnixai.explainers.tabular.agnostic.lime": [[11, 1, 1, "", "LimeTabular"]], "omnixai.explainers.tabular.agnostic.lime.LimeTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.pdp": [[11, 1, 1, "", "PartialDependenceTabular"]], "omnixai.explainers.tabular.agnostic.pdp.PartialDependenceTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.sensitivity": [[11, 1, 1, "", "SensitivityAnalysisTabular"]], "omnixai.explainers.tabular.agnostic.sensitivity.SensitivityAnalysisTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.shap": [[11, 1, 1, "", "ShapTabular"]], "omnixai.explainers.tabular.agnostic.shap.ShapTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.auto": [[10, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.auto.TabularExplainer": [[10, 3, 1, "", "list_explainers"]], "omnixai.explainers.tabular.base": [[10, 1, 1, "", "SklearnBase"], [10, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.base.SklearnBase": [[10, 3, 1, "", "class_names"], [10, 3, 1, "", "fit"], [10, 3, 1, "", "predict"], [10, 3, 1, "", "predict_proba"]], "omnixai.explainers.tabular.counterfactual": [[12, 0, 0, "-", "ce"]], "omnixai.explainers.tabular.counterfactual.ce": [[12, 1, 1, "", "CounterfactualExplainer"], [12, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualExplainer": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualOptimizer": [[12, 3, 1, "", "optimize"]], "omnixai.explainers.tabular.counterfactual.mace": [[12, 0, 0, "-", "mace"]], "omnixai.explainers.tabular.counterfactual.mace.mace": [[12, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.tabular.counterfactual.mace.mace.MACEExplainer": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific": [[13, 0, 0, "-", "decision_tree"], [13, 0, 0, "-", "ig"], [13, 0, 0, "-", "linear"], [13, 0, 0, "-", "shap_tree"]], "omnixai.explainers.tabular.specific.decision_tree": [[13, 1, 1, "", "TreeBase"], [13, 1, 1, "", "TreeClassifier"], [13, 1, 1, "", "TreeRegressor"]], "omnixai.explainers.tabular.specific.decision_tree.TreeBase": [[13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.decision_tree.TreeClassifier": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.decision_tree.TreeRegressor": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.ig": [[13, 1, 1, "", "IntegratedGradient"], [13, 1, 1, "", "IntegratedGradientTabular"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradient": [[13, 3, 1, "", "compute_integrated_gradients"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradientTabular": [[13, 4, 1, "", "alias"], [13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific.linear": [[13, 1, 1, "", "LinearBase"], [13, 1, 1, "", "LinearRegression"], [13, 1, 1, "", "LogisticRegression"]], "omnixai.explainers.tabular.specific.linear.LinearBase": [[13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.linear.LinearRegression": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.linear.LogisticRegression": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.shap_tree": [[13, 1, 1, "", "ShapTreeTabular"]], "omnixai.explainers.tabular.specific.shap_tree.ShapTreeTabular": [[13, 4, 1, "", "alias"], [13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.timeseries": [[15, 0, 0, "-", "agnostic"], [14, 0, 0, "-", "auto"], [16, 0, 0, "-", "counterfactual"]], "omnixai.explainers.timeseries.agnostic": [[15, 0, 0, "-", "shap"]], "omnixai.explainers.timeseries.agnostic.shap": [[15, 1, 1, "", "ShapTimeseries"]], "omnixai.explainers.timeseries.agnostic.shap.ShapTimeseries": [[15, 4, 1, "", "alias"], [15, 3, 1, "", "explain"], [15, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.auto": [[14, 1, 1, "", "TimeseriesExplainer"]], "omnixai.explainers.timeseries.auto.TimeseriesExplainer": [[14, 3, 1, "", "list_explainers"]], "omnixai.explainers.timeseries.counterfactual": [[16, 0, 0, "-", "ce"], [16, 0, 0, "-", "mace"]], "omnixai.explainers.timeseries.counterfactual.ce": [[16, 1, 1, "", "CounterfactualExplainer"], [16, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualExplainer": [[16, 4, 1, "", "alias"], [16, 3, 1, "", "explain"], [16, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualOptimizer": [[16, 3, 1, "", "optimize"]], "omnixai.explainers.timeseries.counterfactual.mace": [[16, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.timeseries.counterfactual.mace.MACEExplainer": [[16, 4, 1, "", "alias"], [16, 3, 1, "", "explain"], [16, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision": [[18, 0, 0, "-", "agnostic"], [17, 0, 0, "-", "auto"], [19, 0, 0, "-", "counterfactual"], [20, 0, 0, "-", "specific"]], "omnixai.explainers.vision.agnostic": [[18, 0, 0, "-", "l2x"], [18, 0, 0, "-", "lime"], [18, 0, 0, "-", "pdp"], [18, 0, 0, "-", "shap"]], "omnixai.explainers.vision.agnostic.l2x": [[18, 1, 1, "", "DefaultPredictionModel"], [18, 1, 1, "", "DefaultSelectionModel"], [18, 1, 1, "", "L2XImage"]], "omnixai.explainers.vision.agnostic.l2x.DefaultPredictionModel": [[18, 3, 1, "", "forward"], [18, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.DefaultSelectionModel": [[18, 3, 1, "", "forward"], [18, 3, 1, "", "postprocess"], [18, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.L2XImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.lime": [[18, 1, 1, "", "LimeImage"]], "omnixai.explainers.vision.agnostic.lime.LimeImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.pdp": [[18, 1, 1, "", "PartialDependenceImage"]], "omnixai.explainers.vision.agnostic.pdp.PartialDependenceImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.shap": [[18, 1, 1, "", "ShapImage"]], "omnixai.explainers.vision.agnostic.shap.ShapImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.auto": [[17, 1, 1, "", "VisionExplainer"]], "omnixai.explainers.vision.auto.VisionExplainer": [[17, 3, 1, "", "list_explainers"]], "omnixai.explainers.vision.counterfactual": [[19, 0, 0, "-", "ce"]], "omnixai.explainers.vision.counterfactual.ce": [[19, 1, 1, "", "CounterfactualExplainer"]], "omnixai.explainers.vision.counterfactual.ce.CounterfactualExplainer": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific": [[20, 0, 0, "-", "cem"], [20, 0, 0, "-", "ig"]], "omnixai.explainers.vision.specific.cem": [[20, 1, 1, "", "CEMOptimizer"], [20, 1, 1, "", "ContrastiveExplainer"]], "omnixai.explainers.vision.specific.cem.CEMOptimizer": [[20, 3, 1, "", "pn_optimize"], [20, 3, 1, "", "pp_optimize"]], "omnixai.explainers.vision.specific.cem.ContrastiveExplainer": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam": [[20, 0, 0, "-", "gradcam"]], "omnixai.explainers.vision.specific.gradcam.gradcam": [[20, 1, 1, "", "GradCAM"], [20, 1, 1, "", "GradCAMPlus"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAM": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAMPlus": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.ig": [[20, 1, 1, "", "IntegratedGradientImage"]], "omnixai.explainers.vision.specific.ig.IntegratedGradientImage": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explanations": [[21, 0, 0, "-", "base"], [22, 0, 0, "-", "image"], [23, 0, 0, "-", "tabular"], [24, 0, 0, "-", "text"], [25, 0, 0, "-", "timeseries"]], "omnixai.explanations.base": [[21, 1, 1, "", "DashFigure"], [21, 1, 1, "", "ExplanationBase"], [21, 1, 1, "", "PredictedResults"]], "omnixai.explanations.base.DashFigure": [[21, 3, 1, "", "show"], [21, 3, 1, "", "to_html"], [21, 3, 1, "", "to_html_div"]], "omnixai.explanations.base.ExplanationBase": [[21, 3, 1, "", "dump"], [21, 3, 1, "", "dumps"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "load"], [21, 3, 1, "", "loads"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.base.PredictedResults": [[21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image": [[22, 0, 0, "-", "contrast"], [22, 0, 0, "-", "counterfactual"], [22, 0, 0, "-", "mask"], [22, 0, 0, "-", "pixel_importance"]], "omnixai.explanations.image.contrast": [[22, 1, 1, "", "ContrastiveExplanation"]], "omnixai.explanations.image.contrast.ContrastiveExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.counterfactual": [[22, 1, 1, "", "CFExplanation"]], "omnixai.explanations.image.counterfactual.CFExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.mask": [[22, 1, 1, "", "MaskExplanation"]], "omnixai.explanations.image.mask.MaskExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.pixel_importance": [[22, 1, 1, "", "PixelImportance"]], "omnixai.explanations.image.pixel_importance.PixelImportance": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular": [[23, 0, 0, "-", "correlation"], [23, 0, 0, "-", "counterfactual"], [23, 0, 0, "-", "feature_importance"], [23, 0, 0, "-", "imbalance"], [23, 0, 0, "-", "linear"], [23, 0, 0, "-", "pdp"], [23, 0, 0, "-", "sensitivity"], [23, 0, 0, "-", "tree"]], "omnixai.explanations.tabular.correlation": [[23, 1, 1, "", "CorrelationExplanation"]], "omnixai.explanations.tabular.correlation.CorrelationExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.counterfactual": [[23, 1, 1, "", "CFExplanation"]], "omnixai.explanations.tabular.counterfactual.CFExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance": [[23, 1, 1, "", "FeatureImportance"], [23, 1, 1, "", "GlobalFeatureImportance"]], "omnixai.explanations.tabular.feature_importance.FeatureImportance": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance.GlobalFeatureImportance": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.imbalance": [[23, 1, 1, "", "ImbalanceExplanation"]], "omnixai.explanations.tabular.imbalance.ImbalanceExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.linear": [[23, 1, 1, "", "LinearExplanation"]], "omnixai.explanations.tabular.linear.LinearExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.pdp": [[23, 1, 1, "", "PDPExplanation"]], "omnixai.explanations.tabular.pdp.PDPExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.sensitivity": [[23, 1, 1, "", "SensitivityExplanation"]], "omnixai.explanations.tabular.sensitivity.SensitivityExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.tree": [[23, 1, 1, "", "TreeExplanation"]], "omnixai.explanations.tabular.tree.TreeExplanation": [[23, 3, 1, "", "add_global"], [23, 3, 1, "", "add_local"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.text": [[24, 0, 0, "-", "word_importance"]], "omnixai.explanations.text.word_importance": [[24, 1, 1, "", "WordImportance"]], "omnixai.explanations.text.word_importance.WordImportance": [[24, 3, 1, "", "add"], [24, 3, 1, "", "get_explanations"], [24, 3, 1, "", "ipython_plot"], [24, 3, 1, "", "plot"], [24, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries": [[25, 0, 0, "-", "counterfactual"], [25, 0, 0, "-", "feature_importance"]], "omnixai.explanations.timeseries.counterfactual": [[25, 1, 1, "", "CFExplanation"]], "omnixai.explanations.timeseries.counterfactual.CFExplanation": [[25, 3, 1, "", "add"], [25, 3, 1, "", "get_explanations"], [25, 3, 1, "", "ipython_plot"], [25, 3, 1, "", "plot"], [25, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries.feature_importance": [[25, 1, 1, "", "FeatureImportance"]], "omnixai.explanations.timeseries.feature_importance.FeatureImportance": [[25, 3, 1, "", "add"], [25, 3, 1, "", "get_explanations"], [25, 3, 1, "", "ipython_plot"], [25, 3, 1, "", "plot"], [25, 3, 1, "", "plotly_plot"]], "omnixai.preprocessing": [[26, 0, 0, "-", "base"], [26, 0, 0, "-", "encode"], [26, 0, 0, "-", "fill"], [26, 0, 0, "-", "image"], [26, 0, 0, "-", "normalize"], [26, 0, 0, "-", "pipeline"], [26, 0, 0, "-", "tabular"], [26, 0, 0, "-", "text"]], "omnixai.preprocessing.base": [[26, 1, 1, "", "Identity"], [26, 1, 1, "", "TransformBase"]], "omnixai.preprocessing.base.Identity": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.base.TransformBase": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode": [[26, 1, 1, "", "KBins"], [26, 1, 1, "", "LabelEncoder"], [26, 1, 1, "", "OneHot"], [26, 1, 1, "", "Ordinal"]], "omnixai.preprocessing.encode.KBins": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.LabelEncoder": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.OneHot": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.Ordinal": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.fill": [[26, 1, 1, "", "FillNaN"], [26, 1, 1, "", "FillNaNTabular"]], "omnixai.preprocessing.fill.FillNaN": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.fill.FillNaNTabular": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image": [[26, 1, 1, "", "Normalize"], [26, 1, 1, "", "Resize"], [26, 1, 1, "", "Round2Int"], [26, 1, 1, "", "Scale"]], "omnixai.preprocessing.image.Normalize": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Resize": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Round2Int": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Scale": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize": [[26, 1, 1, "", "MinMax"], [26, 1, 1, "", "Scale"], [26, 1, 1, "", "Standard"]], "omnixai.preprocessing.normalize.MinMax": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Scale": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Standard": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.pipeline": [[26, 1, 1, "", "Pipeline"]], "omnixai.preprocessing.pipeline.Pipeline": [[26, 3, 1, "", "dump"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "load"], [26, 4, 1, "", "name"], [26, 3, 1, "", "step"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.tabular": [[26, 1, 1, "", "TabularTransform"]], "omnixai.preprocessing.tabular.TabularTransform": [[26, 2, 1, "", "categories"], [26, 2, 1, "", "class_names"], [26, 3, 1, "", "decompose"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.text": [[26, 1, 1, "", "Tfidf"], [26, 1, 1, "", "Word2Id"]], "omnixai.preprocessing.text.Tfidf": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.text.Word2Id": [[26, 4, 1, "", "PAD"], [26, 4, 1, "", "START"], [26, 4, 1, "", "UNK"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"], [26, 2, 1, "", "vocab_size"]], "omnixai.sampler": [[26, 0, 0, "-", "tabular"]], "omnixai.sampler.tabular": [[26, 1, 1, "", "Sampler"]], "omnixai.sampler.tabular.Sampler": [[26, 3, 1, "", "oversample"], [26, 3, 1, "", "subsample"], [26, 3, 1, "", "undersample"]], "omnixai.visualization": [[27, 0, 0, "-", "dashboard"]], "omnixai.visualization.dashboard": [[27, 1, 1, "", "Dashboard"]], "omnixai.visualization.dashboard.Dashboard": [[27, 3, 1, "", "show"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"welcom": 0, "omnixai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 41], "s": 0, "document": 0, "introduct": [0, 1], "capabl": 0, "featur": [0, 29], "comparison": 0, "competitor": 0, "instal": [0, 1], "get": [0, 1], "start": [0, 1], "how": [0, 1], "contribut": [0, 1], "content": 0, "indic": 0, "tabl": 0, "an": 1, "explan": [1, 21, 22, 23, 24, 25, 33, 34, 42, 46, 54, 57, 58, 59, 60, 61], "toolbox": 1, "librari": 1, "design": 1, "more": 1, "exampl": [1, 28, 30, 31], "modul": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "differ": [1, 3], "data": [1, 2, 4, 30, 31], "type": 1, "preprocess": [1, 26, 31], "function": 1, "support": 1, "method": 1, "result": [1, 21], "dashboard": [1, 27], "visual": [1, 27], "packag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "base": [2, 3, 10, 21, 26], "tabular": [2, 10, 11, 12, 13, 23, 26, 28, 30, 31], "imag": [2, 22, 26, 30, 31, 56, 62, 63, 64, 65, 67], "text": [2, 24, 26, 30, 31, 33, 37, 38], "timeseri": [2, 14, 15, 16, 25, 28], "explain": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 28, 37, 43, 66], "task": 3, "auto": [4, 5, 10, 14, 17], "correl": [4, 23], "imbal": [4, 23], "mutual_info": 4, "chi_squar": 4, "nlp": [5, 6, 7, 8, 28], "subpackag": [5, 10, 14, 17], "agnost": [6, 11, 15, 18], "lime": [6, 11, 18, 38, 44, 67], "shap": [6, 11, 15, 18, 39, 49, 55, 68], "l2x": [6, 11, 18, 37, 43, 66], "counterfactu": [7, 12, 16, 19, 22, 23, 25, 33, 34, 42, 46, 54, 57, 58, 59], "polyjuic": 7, "specif": [8, 13, 20], "ig": [8, 13, 20], "predict": [9, 43, 44, 45, 46, 49, 50, 51, 52], "pdp": [11, 18, 23], "sensit": [11, 23, 48], "mace": [12, 16, 46], "ce": [12, 16, 19], "linear": [13, 23], "decision_tre": 13, "shap_tre": 13, "vision": [17, 18, 19, 20, 28], "gradcam": 20, "cem": 20, "three": 21, "categori": 21, "pixel_import": 22, "mask": 22, "contrast": [22, 60, 61], "feature_import": [23, 25], "tree": [23, 50], "word_import": 24, "encod": 26, "normal": 26, "fill": 26, "pipelin": 26, "sampler": 26, "tutori": 28, "code": 28, "basic": 28, "applic": 28, "dataanalyz": 29, "analysi": [29, 32, 39, 48], "object": 30, "time": [30, 53, 54, 55], "seri": [30, 53, 54, 55], "nlpexplain": [32, 40], "sentiment": [32, 39], "classif": [33, 37, 38, 51, 56, 62, 63, 64, 65, 67], "question": 34, "answer": 34, "integr": [35, 36, 64, 65], "gradient": [35, 36, 64, 65], "imdb": [35, 36, 40], "dataset": [35, 36, 40, 42], "tensorflow": [35, 58, 60, 62, 64], "pytorch": [36, 59, 61, 63, 65], "learn": [37, 43, 66], "ml": 41, "workflow": 41, "diabet": 42, "incom": [43, 44, 45, 46, 49, 50, 51], "logist": 45, "regress": [45, 52], "pariti": 47, "depend": 47, "plot": 47, "morri": 48, "decis": 50, "tabularexplain": [51, 52], "hous": 52, "price": 52, "timeseriesexplain": 53, "anomali": [53, 54, 55], "detect": [53, 54, 55], "visionexplain": 56, "imagenet": 57, "mnist": [58, 59, 60, 61, 66, 68], "grad": [62, 63], "cam": [62, 63]}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 3, "sphinx": 56}})