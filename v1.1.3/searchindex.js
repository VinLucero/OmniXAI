Search.setIndex({"docnames": ["index", "omnixai", "omnixai.data", "omnixai.explainers", "omnixai.explainers.data", "omnixai.explainers.nlp", "omnixai.explainers.nlp.agnostic", "omnixai.explainers.nlp.counterfactual", "omnixai.explainers.nlp.specific", "omnixai.explainers.prediction", "omnixai.explainers.tabular", "omnixai.explainers.tabular.agnostic", "omnixai.explainers.tabular.counterfactual", "omnixai.explainers.tabular.specific", "omnixai.explainers.timeseries", "omnixai.explainers.timeseries.agnostic", "omnixai.explainers.timeseries.counterfactual", "omnixai.explainers.vision", "omnixai.explainers.vision.agnostic", "omnixai.explainers.vision.counterfactual", "omnixai.explainers.vision.specific", "omnixai.explanations", "omnixai.explanations.image", "omnixai.explanations.tabular", "omnixai.explanations.text", "omnixai.explanations.timeseries", "omnixai.preprocessing", "omnixai.visualization", "tutorials", "tutorials/data_analysis", "tutorials/misc/data_objects", "tutorials/misc/preprocessing", "tutorials/nlp", "tutorials/nlp/ce_classification", "tutorials/nlp/ce_qa", "tutorials/nlp/ig_tf", "tutorials/nlp/ig_torch", "tutorials/nlp/l2x", "tutorials/nlp/lime", "tutorials/nlp/shap", "tutorials/nlp_imdb", "tutorials/omnixai_in_ml_workflow", "tutorials/tabular/ale", "tutorials/tabular/ce", "tutorials/tabular/l2x", "tutorials/tabular/lime", "tutorials/tabular/linear", "tutorials/tabular/mace", "tutorials/tabular/pdp", "tutorials/tabular/ranking", "tutorials/tabular/sensitivity", "tutorials/tabular/shap", "tutorials/tabular/tree", "tutorials/tabular_classification", "tutorials/tabular_regression", "tutorials/timeseries", "tutorials/timeseries/mace", "tutorials/timeseries/shap", "tutorials/vision", "tutorials/vision/ce_imagenet", "tutorials/vision/ce_tf", "tutorials/vision/ce_torch", "tutorials/vision/cem_tf", "tutorials/vision/cem_torch", "tutorials/vision/gradcam_tf", "tutorials/vision/gradcam_torch", "tutorials/vision/gradcam_vlm", "tutorials/vision/ig_tf", "tutorials/vision/ig_torch", "tutorials/vision/ig_vlm", "tutorials/vision/l2x", "tutorials/vision/lime", "tutorials/vision/shap"], "filenames": ["index.rst", "omnixai.rst", "omnixai.data.rst", "omnixai.explainers.rst", "omnixai.explainers.data.rst", "omnixai.explainers.nlp.rst", "omnixai.explainers.nlp.agnostic.rst", "omnixai.explainers.nlp.counterfactual.rst", "omnixai.explainers.nlp.specific.rst", "omnixai.explainers.prediction.rst", "omnixai.explainers.tabular.rst", "omnixai.explainers.tabular.agnostic.rst", "omnixai.explainers.tabular.counterfactual.rst", "omnixai.explainers.tabular.specific.rst", "omnixai.explainers.timeseries.rst", "omnixai.explainers.timeseries.agnostic.rst", "omnixai.explainers.timeseries.counterfactual.rst", "omnixai.explainers.vision.rst", "omnixai.explainers.vision.agnostic.rst", "omnixai.explainers.vision.counterfactual.rst", "omnixai.explainers.vision.specific.rst", "omnixai.explanations.rst", "omnixai.explanations.image.rst", "omnixai.explanations.tabular.rst", "omnixai.explanations.text.rst", "omnixai.explanations.timeseries.rst", "omnixai.preprocessing.rst", "omnixai.visualization.rst", "tutorials.rst", "tutorials/data_analysis.ipynb", "tutorials/misc/data_objects.ipynb", "tutorials/misc/preprocessing.ipynb", "tutorials/nlp.ipynb", "tutorials/nlp/ce_classification.ipynb", "tutorials/nlp/ce_qa.ipynb", "tutorials/nlp/ig_tf.ipynb", "tutorials/nlp/ig_torch.ipynb", "tutorials/nlp/l2x.ipynb", "tutorials/nlp/lime.ipynb", "tutorials/nlp/shap.ipynb", "tutorials/nlp_imdb.ipynb", "tutorials/omnixai_in_ml_workflow.ipynb", "tutorials/tabular/ale.ipynb", "tutorials/tabular/ce.ipynb", "tutorials/tabular/l2x.ipynb", "tutorials/tabular/lime.ipynb", "tutorials/tabular/linear.ipynb", "tutorials/tabular/mace.ipynb", "tutorials/tabular/pdp.ipynb", "tutorials/tabular/ranking.ipynb", "tutorials/tabular/sensitivity.ipynb", "tutorials/tabular/shap.ipynb", "tutorials/tabular/tree.ipynb", "tutorials/tabular_classification.ipynb", "tutorials/tabular_regression.ipynb", "tutorials/timeseries.ipynb", "tutorials/timeseries/mace.ipynb", "tutorials/timeseries/shap.ipynb", "tutorials/vision.ipynb", "tutorials/vision/ce_imagenet.ipynb", "tutorials/vision/ce_tf.ipynb", "tutorials/vision/ce_torch.ipynb", "tutorials/vision/cem_tf.ipynb", "tutorials/vision/cem_torch.ipynb", "tutorials/vision/gradcam_tf.ipynb", "tutorials/vision/gradcam_torch.ipynb", "tutorials/vision/gradcam_vlm.ipynb", "tutorials/vision/ig_tf.ipynb", "tutorials/vision/ig_torch.ipynb", "tutorials/vision/ig_vlm.ipynb", "tutorials/vision/l2x.ipynb", "tutorials/vision/lime.ipynb", "tutorials/vision/shap.ipynb"], "titles": ["Welcome to OmniXAI\u2019s documentation!", "OmniXAI: An Explanation Toolbox", "omnixai.data package", "omnixai.explainers package", "omnixai.explainers.data package", "omnixai.explainers.nlp package", "omnixai.explainers.nlp.agnostic package", "omnixai.explainers.nlp.counterfactual package", "omnixai.explainers.nlp.specific package", "omnixai.explainers.prediction package", "omnixai.explainers.tabular package", "omnixai.explainers.tabular.agnostic package", "omnixai.explainers.tabular.counterfactual package", "omnixai.explainers.tabular.specific package", "omnixai.explainers.timeseries package", "omnixai.explainers.timeseries.agnostic package", "omnixai.explainers.timeseries.counterfactual package", "omnixai.explainers.vision package", "omnixai.explainers.vision.agnostic package", "omnixai.explainers.vision.counterfactual package", "omnixai.explainers.vision.specific package", "omnixai.explanations package", "omnixai.explanations.image package", "omnixai.explanations.tabular package", "omnixai.explanations.text package", "omnixai.explanations.timeseries package", "omnixai.preprocessing package", "omnixai.visualization package", "Tutorials &amp; Example Code", "DataAnalyzer for feature analysis", "Examples of data objects", "Examples of data preprocessing", "NLPExplainer for sentiment analysis", "Counterfactual explanation for text classification", "Counterfactual explanation for question answering", "Integrated-gradient on IMDB dataset (Tensorflow)", "Integrated-gradient on IMDB dataset (PyTorch)", "L2X (learning to explain) for text classification", "LIME for text classification", "SHAP for sentiment analysis", "NLPExplainer on IMDB dataset", "OmniXAI in a ML workflow", "Accumulated local effects (ALE)", "Counterfactual explanation on Diabetes dataset", "L2X (learning to explain) for income prediction", "LIME for income prediction", "Logistic regression for income prediction", "MACE counterfactual explanation for income prediction", "Paritial dependence plots (PDP)", "Learning to Rank Expanations Demo", "Morris sensitivity analysis", "SHAP for income prediction", "Decision tree for income prediction", "TabularExplainer for income prediction (classification)", "TabularExplainer for house-price prediction (regression)", "TimeseriesExplainer for time series anomaly detection", "Counterfactual explanation on time series anomaly detection", "SHAP for time series anomaly detection", "VisionExplainer for image classification", "Counterfactual explanation on ImageNet", "Counterfactual explanation on MNIST (Tensorflow)", "Counterfactual explanation on MNIST (PyTorch)", "Contrastive explanation on MNIST (Tensorflow)", "Contrastive explanation on MNIST (PyTorch)", "Grad-CAM for image classification (Tensorflow)", "Grad-CAM for image classification (PyTorch)", "Grad-CAM for visual language tasks", "Integrated-gradient for image classification (Tensorflow)", "Integrated-gradient for image classification (PyTorch)", "Integrated-gradient for visual language tasks", "L2X (learning to explain) on MNIST", "LIME for image classification", "SHAP on MNIST"], "terms": {"short": [0, 1], "omni": [0, 1], "explain": [0, 1, 2, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72], "ai": [0, 1, 2], "i": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "python": [0, 1, 49, 66, 69, 72], "librari": [0, 2, 6, 29, 30, 31, 33, 34, 39, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 66, 69], "xai": [0, 1], "offer": [0, 1, 37], "wai": [0, 1, 3, 26, 37, 49], "interpret": [0, 1, 6, 11, 18, 37, 44, 70], "machin": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 37, 38, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 57, 70, 71], "learn": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 28, 32, 38, 40, 41, 42, 43, 45, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 71], "address": [0, 1], "mani": [0, 1, 37], "pain": [0, 1], "point": [0, 1, 37, 55, 56, 57], "decis": [0, 1, 12, 13, 19, 23, 28, 43, 59, 60, 61], "made": [0, 1, 37], "model": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "practic": [0, 1, 3, 53, 54, 55, 58], "aim": [0, 1], "one": [0, 1, 2, 3, 6, 15, 16, 21, 22, 23, 24, 25, 26, 30, 31, 32, 37, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "stop": [0, 1], "comprehens": [0, 1], "make": [0, 1, 26, 37, 41, 55], "easi": [0, 1, 32, 40, 53, 54, 55, 58], "data": [0, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "scientist": [0, 1], "ml": [0, 1, 3, 4, 9, 11, 13, 28, 29, 32, 40, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72], "research": [0, 1, 66, 69], "practition": [0, 1], "who": [0, 1, 37], "need": [0, 1, 2, 3, 30, 32, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "explan": [0, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 64, 65, 66, 67, 68, 69, 70, 71, 72], "variou": [0, 1], "type": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 32, 35, 36, 37, 40, 42, 43, 44, 45, 48, 49, 51, 53, 54, 55, 57, 58, 64, 65, 67, 68, 70], "method": [0, 4, 7, 18, 20, 22, 23, 26, 30, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 59, 60, 61, 62, 63, 67, 68, 70, 72], "differ": [0, 4, 5, 10, 12, 14, 17, 29, 37, 41, 42, 44, 45, 47, 48, 51, 53, 54, 70], "stage": [0, 1, 41], "process": [0, 1, 3, 8, 9, 13, 19, 20, 26, 32, 35, 36, 40, 49, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72], "includ": [0, 1, 2, 19, 20, 26, 58], "rich": [0, 1], "famili": [0, 1, 41, 45, 47, 51, 53], "integr": [0, 1, 8, 13, 20, 22, 28, 32, 40, 58], "unifi": [0, 1, 3, 32, 40, 53, 54, 55, 58], "interfac": [0, 1, 3, 32, 37, 40, 44, 53, 54, 55, 58, 70], "which": [0, 1, 2, 3, 5, 8, 9, 10, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 35, 36, 37, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 72], "support": [0, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 17, 18, 20, 30, 31, 32, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 71, 72], "multipl": [0, 1, 2, 3, 4, 5, 10, 14, 17, 26, 29, 37, 41, 44, 53, 54, 70], "tabular": [0, 1, 3, 4, 9, 21, 29, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], "imag": [0, 1, 3, 12, 13, 17, 18, 19, 20, 21, 28, 37, 59, 60, 61, 62, 63, 66, 69, 70, 72], "text": [0, 1, 3, 5, 6, 7, 8, 21, 23, 28, 32, 34, 35, 36, 39, 40, 49, 66, 69], "time": [0, 1, 2, 3, 4, 5, 10, 11, 14, 15, 16, 17, 25, 28, 29, 37, 41], "seri": [0, 1, 2, 3, 14, 15, 16, 25, 28], "tradit": [0, 1], "scikit": [0, 1, 3, 5, 9, 10, 11, 13, 14, 17, 32, 40, 48, 53, 54, 58], "deep": [0, 1, 20, 64, 65], "pytorch": [0, 1, 3, 6, 11, 18, 28, 32, 37, 40, 44, 53, 54, 58, 66, 69, 70, 72], "tensorflow": [0, 1, 3, 5, 9, 10, 14, 17, 28, 32, 40, 43, 49, 53, 54, 58, 72], "rang": [0, 1, 19, 20, 26, 35, 36, 40, 58, 59, 61, 63, 64, 65, 67, 68, 70, 71], "divers": [0, 1, 47], "specif": [0, 1, 3, 5, 9, 10, 14, 17, 21, 22, 23, 24, 25, 32, 35, 36, 40, 41, 52, 53, 54, 55, 58, 64, 65, 66, 69], "agnost": [0, 1, 3, 5, 10, 12, 14, 16, 17, 36, 37, 40, 44, 45, 47, 49, 51, 70, 72], "attribut": [0, 1, 66, 69], "counterfactu": [0, 1, 5, 10, 14, 17, 21, 28, 32, 40, 41, 55, 58], "gradient": [0, 1, 8, 12, 13, 16, 19, 20, 22, 28, 32, 37, 40, 58, 64, 65, 66, 70], "base": [0, 1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 32, 33, 34, 37, 39, 49, 50, 52, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70], "etc": [0, 1], "For": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 18, 20, 21, 23, 24, 26, 29, 30, 31, 35, 36, 37, 38, 41, 44, 46, 48, 52, 53, 54, 58, 66, 69, 70, 71], "provid": [0, 1, 2, 3, 21, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 40, 46, 52, 53, 54, 55, 58], "an": [0, 2, 3, 4, 6, 11, 12, 15, 16, 18, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "us": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "gener": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 37, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 70, 72], "applic": [0, 1, 49, 64, 67], "onli": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 18, 19, 20, 26, 29, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "write": [0, 1, 37, 38], "few": [0, 1], "line": [0, 1, 37, 38, 55], "code": [0, 1, 58, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "also": [0, 1, 2, 30, 37, 49, 58], "gui": [0, 1], "dashboard": [0, 3, 29, 32, 40, 41, 53, 54, 55, 58], "visual": [0, 3, 20, 21, 28, 29, 32, 40, 41, 43, 49, 53, 54, 55, 58, 64, 65], "obtain": [0, 1, 37], "more": [0, 3, 11, 12, 15, 16, 26, 29, 37, 38, 41, 44, 48, 55, 56, 57, 59, 60, 61, 62, 63, 70], "insight": [0, 1], "about": [0, 1, 3, 37], "compar": [0, 13, 18, 20], "other": [0, 1, 29, 31, 37, 41, 42, 43, 44, 45, 47, 48, 51, 53, 54, 70], "exist": [0, 1, 26, 37, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "ibm": 0, "aix360": 0, "microsoft": 0, "interpretml": 0, "alibi": 0, "explainx": 0, "our": [0, 37, 47, 49, 56], "ha": [0, 1, 2, 3, 7, 22, 23, 24, 25, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 69, 72], "list": [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 16, 17, 21, 22, 23, 24, 25, 26, 27, 30, 49, 50, 54], "uniqu": 0, "follow": [0, 1, 2, 3, 22, 23, 24, 25, 26, 30, 32, 35, 36, 37, 38, 40, 42, 44, 45, 47, 48, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "analysi": [0, 1, 3, 4, 9, 11, 23, 27, 28, 33, 41, 53, 54, 58], "explor": [0, 1, 29, 49], "analyz": [0, 1, 4, 9, 29, 37, 41, 49, 50, 53, 54], "correl": [0, 1, 3, 21, 29, 41, 49], "check": [0, 4, 41, 49, 64, 67, 71], "imbal": [0, 1, 3, 21, 26, 29, 41], "issu": [0, 37, 41], "most": [0, 1, 12, 41, 55], "popular": 0, "aspect": 0, "inform": [0, 1, 2, 3, 4, 6, 11, 12, 18, 23, 25, 29, 37, 41, 43, 44, 48, 70], "chang": [0, 18, 47, 70], "current": [0, 26, 32, 40, 58], "predict": [0, 1, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 48, 49, 50, 56, 57, 58, 61, 63, 64, 67, 70, 71], "grad": [0, 1, 3, 17, 20, 22, 28, 35, 41, 45, 47, 51, 53, 58], "cam": [0, 1, 3, 17, 20, 22, 28, 58], "its": [0, 1, 3, 10, 11, 12, 13, 18, 30, 32, 35, 36, 40, 42, 44, 45, 47, 48, 49, 51, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 72], "variant": 0, "timeseri": [0, 1, 3, 21, 30, 55, 56, 57], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 37, 38, 39, 40, 41, 44, 49, 55, 56, 57, 58, 59, 65, 66, 69, 70], "much": [0, 34, 37], "simpler": [0, 37], "user": [0, 1, 3, 4, 5, 9, 10, 14, 17, 32, 34, 40, 49, 53, 54, 55, 58], "examin": [0, 41], "extend": [0, 37], "ad": 0, "new": [0, 1, 2, 18, 26, 37, 66, 69], "algorithm": [0, 49], "easili": [0, 30, 34], "implement": [0, 1, 7, 12, 20, 27, 33, 34, 37, 44, 70], "singl": [0, 2, 3, 26, 30, 31], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71], "deriv": [0, 3, 4, 5, 10, 14, 17, 26, 29], "from": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 14, 17, 18, 20, 21, 22, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "show": [0, 1, 3, 21, 22, 23, 24, 27, 29, 30, 32, 33, 35, 36, 39, 40, 41, 48, 50, 53, 54, 55, 58], "we": [0, 1, 2, 3, 29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "continu": [0, 1, 2, 4, 10, 11, 12, 13, 26, 30, 31, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54], "improv": [0, 20], "thi": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "futur": 0, "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "vision": [0, 1, 3, 22, 30, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "nlp": [0, 1, 3, 24, 32, 33, 34, 35, 36, 37, 38, 39, 40], "task": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "eda": 0, "na": [0, 37], "global": [0, 1, 3, 4, 11, 13, 23, 27, 29, 32, 40, 41, 46, 48, 50, 52, 53, 54, 58], "select": [0, 1, 2, 6, 11, 18, 29, 30, 41, 58], "metric": [0, 1, 2, 9, 30, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 51, 53, 54, 55, 60, 62, 72], "black": [0, 1, 3, 5, 9, 10, 12, 14, 17, 19, 32, 41, 43, 45, 47, 51, 53, 54, 55, 58, 59, 60, 61], "box": [0, 1, 3, 5, 9, 10, 12, 14, 17, 19, 32, 43, 47, 53, 54, 55, 58, 59, 60, 61], "pdp": [0, 1, 3, 4, 10, 17, 21, 27, 28, 41, 53, 54], "al": [0, 1, 7, 10, 12, 16, 20, 28, 33, 34, 41, 47, 53, 54, 64, 65], "sensit": [0, 1, 10, 21, 28, 54], "lime": [0, 1, 3, 5, 10, 17, 22, 28, 32, 40, 41, 44, 53, 54, 58], "local": [0, 1, 3, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 23, 27, 28, 32, 40, 41, 44, 45, 46, 47, 51, 52, 53, 54, 55, 57, 58, 64, 65], "shap": [0, 1, 3, 5, 10, 13, 14, 17, 22, 28, 32, 41, 44, 53, 54, 55], "torch": [0, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 35, 36, 40, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "tf": [0, 1, 8, 12, 13, 18, 19, 20, 26, 31, 35, 36, 37, 38, 43, 49, 59, 60, 61, 62, 63, 64, 65, 67, 68, 72], "contrast": [0, 1, 20, 21, 28], "linear": [0, 1, 6, 10, 11, 21, 36, 40, 46, 52, 61, 63, 70], "tree": [0, 1, 13, 21, 28], "accept": 0, "transform": [0, 1, 3, 5, 6, 9, 10, 14, 17, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71], "between": [0, 4, 34, 37, 41], "toolkit": 0, "literatur": 0, "eli5": 0, "captum": 0, "l2x": [0, 5, 10, 17, 28, 36, 40], "you": [0, 1, 30, 33, 35, 36, 37, 39, 49], "can": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 26, 29, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "pypi": [0, 1], "call": [0, 1, 2, 29, 31, 32, 35, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 70, 72], "pip": [0, 1, 49], "mai": [0, 1, 2, 26, 30, 37, 41, 42, 44, 45, 46, 47, 48, 51, 53, 70], "sourc": [0, 1], "clone": [0, 1], "repo": [0, 1], "navig": [0, 1], "root": [0, 1, 30, 61, 63, 70], "directori": [0, 1, 26], "edit": [0, 1], "mode": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 29, 32, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 48, 51, 53, 54, 55, 56, 57, 58, 64, 65, 67, 68, 70], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 29, 53, 54, 55], "depend": [0, 1, 11, 18, 23, 28, 37, 44, 53, 54, 70], "plot": [0, 1, 11, 18, 21, 22, 23, 24, 25, 27, 28, 41, 44, 45, 47, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 70, 72], "To": [0, 1, 3, 29, 30, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "recommend": [0, 1, 3, 42, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "link": [0, 1], "tutori": [0, 1, 3, 41], "exampl": [0, 2, 3, 4, 7, 12, 16, 22, 23, 25, 26, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "In": [0, 1, 3, 29, 30, 32, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 72], "tabularexplain": [0, 1, 3, 4, 10, 11, 12, 13, 28, 32, 40, 41, 58], "visionexplain": [0, 1, 3, 17, 28], "nlpexplain": [0, 1, 3, 5, 28], "timeseriesexplain": [0, 1, 3, 14, 28], "respect": [0, 1, 2, 3, 4, 30, 55], "dataanalyz": [0, 1, 3, 4, 27, 28, 41], "predictionanalyz": [0, 1, 3, 9, 27, 41, 53, 54], "result": [0, 3, 4, 9, 19, 20, 22, 23, 24, 25, 27, 32, 34, 40, 41, 49, 53, 54, 55, 58], "specifi": [0, 1, 2, 3, 9, 26, 29, 30, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 70], "function": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "pre": [0, 1, 3, 8, 13, 20, 26, 35, 36], "convert": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 26, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72], "raw": [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 17, 18, 19, 20, 22, 23, 29, 30, 32, 35, 36, 40, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 30, 32, 34, 35, 36, 40, 42, 43, 44, 45, 47, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "post": [0, 1, 3, 37, 38], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 22, 23, 24, 25, 34, 53, 54, 55, 58], "output": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 26, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "probabl": [0, 1, 3, 5, 6, 7, 9, 10, 11, 12, 13, 17, 18, 21, 32, 33, 37, 38, 40, 42, 44, 45, 47, 48, 51, 53, 54, 58, 70, 71], "appli": [0, 1, 2, 3, 10, 11, 12, 13, 26, 29, 31, 32, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 64, 67, 71], "mace": [0, 1, 3, 10, 14, 28, 41, 44, 53, 54, 55], "let": [0, 1, 31, 34, 37, 41, 49, 64, 67, 71], "take": [0, 1, 30, 32, 37, 40, 42, 44, 45, 47, 48, 51, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 72], "incom": [0, 1, 28, 29, 41, 42, 48], "dataset": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 18, 26, 27, 28, 29, 30, 31, 37, 38, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 70, 72], "http": [0, 1, 6, 7, 8, 11, 12, 13, 15, 18, 19, 20, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "archiv": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53], "ic": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53], "uci": [0, 1, 29, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53], "edu": [0, 1, 29, 38, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53], "adult": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "repres": [0, 1, 2, 15, 16, 30, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "creat": [0, 1, 2, 3, 29, 30, 34, 37, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58], "instanc": [0, 1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "given": [0, 1, 2, 3, 4, 10, 13, 26, 29, 30, 31, 32, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58], "panda": [0, 1, 2, 23, 25, 26, 29, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "datafram": [0, 1, 2, 11, 12, 13, 23, 25, 26, 29, 30, 31, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "categor": [0, 1, 2, 4, 10, 11, 12, 13, 26, 29, 30, 31, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "name": [0, 1, 2, 3, 4, 5, 10, 11, 14, 17, 21, 22, 23, 24, 26, 27, 29, 32, 35, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 61, 63, 64, 65, 67, 68, 70, 71], "target": [0, 1, 2, 4, 9, 10, 12, 13, 20, 26, 29, 30, 31, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 61, 63, 64, 65, 66, 69, 70], "label": [0, 1, 2, 3, 6, 8, 9, 10, 11, 12, 13, 18, 20, 22, 23, 24, 26, 27, 29, 30, 31, 33, 35, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 67, 68, 70, 71], "column": [0, 1, 2, 3, 9, 23, 26, 29, 30, 31, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "import": [0, 1, 2, 4, 6, 8, 11, 13, 15, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "load": [0, 1, 3, 21, 26, 29, 32, 34, 35, 36, 37, 38, 40, 41, 43, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "feature_nam": [0, 1, 3, 23, 29, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "ag": [0, 1, 3, 4, 27, 29, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53], "workclass": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "fnlwgt": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "educ": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "num": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "marit": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "statu": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "occup": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "relationship": [0, 1, 3, 10, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "race": [0, 1, 3, 10, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "sex": [0, 1, 3, 10, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "capit": [0, 1, 3, 10, 27, 29, 37, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "gain": [0, 1, 3, 4, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "loss": [0, 1, 3, 6, 10, 11, 12, 16, 18, 19, 20, 27, 29, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 60, 61, 62, 63, 66, 69, 70, 72], "hour": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "per": [0, 1, 3, 12, 27, 28, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "week": [0, 1, 3, 27, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "countri": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "df": [0, 1, 2, 30, 31, 41, 50, 53, 54, 55, 56, 57], "pd": [0, 1, 2, 11, 12, 13, 26, 30, 31, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "np": [0, 1, 2, 3, 10, 11, 12, 13, 16, 20, 26, 29, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 69, 72], "genfromtxt": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "delimit": [0, 1, 3, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "dtype": [0, 1, 3, 29, 35, 36, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53], "str": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 26, 29, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 58, 59, 64, 65, 67, 68, 71], "tabular_data": [0, 1, 3, 26, 29, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "categorical_column": [0, 1, 2, 3, 26, 29, 30, 31, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "1": [0, 1, 2, 3, 11, 12, 16, 17, 19, 20, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "3": [0, 1, 2, 3, 10, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "5": [0, 1, 3, 6, 7, 11, 12, 16, 18, 19, 20, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "6": [0, 1, 3, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70, 72], "7": [0, 1, 3, 29, 30, 31, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72], "8": [0, 1, 3, 10, 11, 13, 29, 30, 31, 35, 36, 37, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 70, 72], "9": [0, 1, 3, 23, 29, 30, 31, 35, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 60, 61, 62, 63, 66, 69, 70, 71, 72], "13": [0, 1, 3, 29, 30, 31, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "target_column": [0, 1, 2, 3, 29, 30, 31, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "packag": [0, 1, 31, 32, 35, 36, 37, 38, 40, 49, 50, 53, 54, 55, 58, 66, 69, 72], "preprocess": [0, 3, 5, 9, 10, 13, 14, 17, 18, 19, 20, 28, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "sever": [0, 1, 30, 31, 37, 41, 46, 52, 53, 54], "tabulartransform": [0, 1, 3, 26, 31, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54], "special": [0, 1, 16, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54], "design": [0, 16, 18, 32, 40, 42, 44, 45, 47, 48, 51, 53, 54, 55, 58], "By": [0, 1, 42, 44, 45, 47, 48, 51, 53, 54, 58], "default": [0, 1, 2, 6, 11, 12, 18, 29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "hot": [0, 1, 26, 31, 42, 44, 45, 47, 48, 51, 53, 54], "encod": [0, 1, 10, 13, 20, 31, 42, 44, 45, 47, 48, 49, 51, 53, 54, 66], "keep": [0, 1, 26, 42, 44, 45, 47, 48, 51, 53, 54], "valu": [0, 1, 2, 3, 4, 6, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 26, 30, 31, 32, 33, 35, 36, 37, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 60, 62, 66, 69, 70, 72], "numpi": [0, 1, 2, 9, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "arrai": [0, 1, 2, 9, 26, 29, 30, 31, 32, 33, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "If": [0, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 22, 23, 24, 26, 29, 30, 31, 35, 36, 37, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "last": [0, 1, 2, 3, 26, 29, 30, 31, 42, 44, 45, 47, 48, 51, 53, 54, 58], "after": [0, 1, 37, 41, 42, 44, 45, 47, 48, 49, 51, 53, 54, 70, 72], "train": [0, 1, 3, 4, 5, 6, 10, 11, 12, 13, 14, 17, 18, 23, 26, 30, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 70, 72], "xgboost": [0, 1, 3, 13, 41, 42, 44, 45, 47, 48, 51, 53], "classifi": [0, 1, 12, 13, 37, 38, 41, 42, 44, 45, 47, 48, 51, 53], "fit": [0, 1, 3, 10, 13, 26, 31, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 60, 62, 72], "class_nam": [0, 1, 10, 21, 22, 23, 24, 26, 27, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 51, 53, 58, 59, 61, 63, 64, 65, 67, 68, 70, 71], "x": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 60, 61, 62, 63, 66, 69, 70, 72], "split": [0, 1, 2, 10, 13, 34, 55, 56, 57], "test": [0, 1, 9, 10, 13, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "train_label": [0, 1, 41, 42, 48, 53, 60, 62, 70, 72], "test_label": [0, 1, 9, 41, 42, 48, 53, 60, 62, 70, 72], "sklearn": [0, 1, 13, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "model_select": [0, 1, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54], "train_test_split": [0, 1, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54], "train_siz": [0, 1, 10, 13, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54], "0": [0, 1, 2, 3, 6, 10, 11, 12, 13, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72], "80": [0, 1, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54], "xgbclassifi": [0, 1, 3, 41, 42, 44, 45, 47, 48, 51, 53], "n_estim": [0, 1, 3, 37, 38, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54], "300": [0, 1, 3, 41, 42, 44, 45, 47, 48, 51, 53], "max_depth": [0, 1, 3, 41, 42, 44, 45, 47, 48, 51, 52, 53], "back": [0, 1, 2, 41, 45, 49, 51, 53, 54], "train_data": [0, 1, 35, 36, 40, 41, 53, 54, 61, 63, 70], "invert": [0, 1, 26, 31, 41, 45, 51, 53, 54], "test_data": [0, 1, 9, 30, 41, 53, 54, 61, 63, 70], "initi": [0, 1, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 23, 24, 25, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "set": [0, 1, 2, 11, 12, 16, 24, 27, 29, 30, 32, 35, 36, 37, 38, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "paramet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "too": [0, 1, 37, 42, 45, 47, 48, 50, 51, 53, 54, 66, 69], "larg": [0, 1, 10, 11, 12, 13, 41, 42, 43, 45, 47, 48, 50, 51, 53, 54], "subset": [0, 1, 2, 10, 11, 12, 13, 26, 30, 37, 38, 42, 43, 45, 47, 48, 50, 51, 53, 54], "sampler": [0, 1, 10, 11, 12, 13, 42, 43, 45, 47, 48, 50, 51, 53, 54], "subsampl": [0, 1, 10, 11, 12, 13, 26, 42, 43, 45, 47, 48, 50, 51, 53, 54], "postprocess": [0, 1, 3, 5, 9, 10, 14, 17, 18, 32, 40, 53, 54, 55, 58], "form": [0, 1, 3, 5, 9, 10, 14, 17, 32, 40, 53, 54, 55, 58], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 32, 40, 41, 53, 54, 55, 58, 64, 67], "should": [0, 1, 2, 6, 9, 11, 12, 13, 16, 18, 29, 35, 36, 37, 44, 53, 54, 56, 57, 70], "classif": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 32, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 59, 60, 61, 62, 63, 70, 72], "regress": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 17, 18, 20, 21, 22, 23, 24, 26, 28, 32, 35, 36, 37, 40, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 58, 64, 65, 67, 68, 70], "consum": [0, 1, 32, 40, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 72], "simpli": [0, 1, 32, 40, 42, 44, 45, 47, 48, 51, 53, 54, 58, 59, 60, 61, 62, 63, 72], "some": [0, 1, 3, 26, 30, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 51, 53, 54], "custom": [0, 1], "format": [0, 1, 2, 3, 7, 22, 23, 24, 25, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 58, 61, 63, 70], "lambda": [0, 1, 3, 32, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 53, 54, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 72], "z": [0, 1, 3, 26, 31, 41, 42, 44, 45, 47, 48, 50, 51, 53, 54, 66, 69], "some_transform": [0, 1, 53, 54], "to_pd": [0, 1, 2, 30, 42, 44, 45, 47, 48, 49, 51, 53, 54], "param": [0, 1, 3, 4, 5, 10, 14, 17, 27, 29, 40, 41, 53, 54, 55, 58], "ignored_featur": [0, 1, 3, 10, 11, 12, 41, 47, 49, 53], "while": [0, 1, 41, 53, 54], "partial": [0, 1, 11, 18, 23, 43, 48, 53, 54], "return": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 33, 34, 35, 36, 40, 43, 49, 52, 53, 54, 55, 56, 57, 61, 63, 64, 66, 67, 69, 70, 71], "three": [0, 1, 6, 11, 26, 30, 41, 53, 58], "explain_glob": [0, 1, 3, 10, 29, 41, 53, 54], "hide": [0, 1, 53, 54], "all": [0, 1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 32, 37, 40, 41, 43, 49, 53, 54, 55, 58], "detail": [0, 1, 3, 37, 44, 53, 54, 59, 60, 61, 62, 63, 70], "behind": [0, 1, 53, 54], "so": [0, 1, 37, 41, 43, 53, 54], "two": [0, 1, 2, 3, 29, 30, 31, 35, 36, 37, 40, 41, 43, 53, 54, 60, 61, 62, 63, 70, 72], "test_inst": [0, 1, 41, 45, 47, 51, 53, 54, 55], "local_explan": [0, 1, 3, 5, 10, 14, 17, 27, 32, 40, 41, 53, 54, 55, 58], "global_explan": [0, 1, 3, 10, 27, 29, 41, 53, 54], "similarli": [0, 1, 49, 53, 54], "comput": [0, 1, 4, 9, 11, 13, 16, 20, 23, 31, 37, 41, 53, 54, 66, 69], "perform": [0, 1, 30, 33, 35, 36, 39, 40, 41, 53, 54, 61, 63, 70], "test_target": [0, 1, 9, 41, 53, 54], "integ": [0, 1, 2, 9, 26, 29, 53], "labelencod": [0, 1, 9, 10, 13, 26, 31, 53], "match": [0, 1, 9, 26, 53], "prediction_explan": [0, 1, 9, 27, 41, 53, 54], "launch": [0, 1, 29, 32, 40, 41, 53, 54, 55, 58], "dash": [0, 1, 21, 22, 23, 24, 25, 27, 29, 32, 40, 41, 53, 54, 55, 58], "app": [0, 1, 29, 32, 40, 41, 53, 54, 55, 58], "open": [0, 1, 2, 12, 19, 26, 30, 31, 37, 43, 49, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71], "browser": [0, 1], "see": [0, 1, 37, 41, 49, 70], "thank": [0, 1, 37], "your": [0, 1, 37, 66, 69, 72], "interest": [0, 1, 37], "befor": [0, 1, 37], "run": [0, 1, 29, 32, 37, 40, 41, 53, 54, 55, 58], "commit": [0, 1], "ensur": [0, 1], "file": [0, 1, 21, 26, 49], "ar": [0, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 16, 18, 21, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 62, 70, 71, 72], "correctli": [0, 1], "contain": [0, 1, 2, 3, 4, 5, 9, 10, 12, 14, 17, 21, 23, 27, 30, 31, 37, 46, 53, 54, 55, 56, 57, 60, 61, 62, 63, 70, 72], "appropri": [0, 1], "licens": [0, 1], "header": [0, 1], "whenev": [0, 1], "add": [0, 1, 22, 23, 24, 25, 26, 37, 43, 60, 62, 72], "step": [0, 1, 8, 11, 13, 16, 20, 26, 35, 41, 43, 58, 59, 60, 61, 62, 63, 70, 72], "below": [0, 1, 37], "choos": [0, 1, 3, 4, 5, 10, 14, 17, 29, 41], "script": [0, 1, 49], "folder": [0, 1], "put": [0, 1], "under": [0, 1, 26], "inherit": [0, 1, 3, 26], "explainerbas": [0, 1, 3, 4, 6, 7, 8, 9, 10, 12, 15, 16, 18, 19, 20], "constructor": [0, 1, 3], "__init__": [0, 1, 3, 35, 36, 40, 61, 63, 66, 69, 70], "self": [0, 1, 2, 3, 26, 35, 36, 40, 41, 45, 47, 51, 53, 61, 63, 66, 70], "predict_funct": [0, 1, 3, 6, 7, 9, 10, 11, 12, 15, 16, 18, 33, 34, 37, 38, 42, 43, 44, 45, 47, 48, 49, 50, 51, 56, 57, 70, 71], "kwarg": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 35, 36, 40], "preprocess_funct": [0, 1, 3, 5, 8, 9, 10, 13, 14, 17, 18, 19, 20, 35, 36, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72], "postprocess_funct": [0, 1, 3, 5, 17], "requir": [0, 1, 3, 5, 17, 55], "whether": [0, 1, 2, 3, 11, 16, 23, 37, 41, 55, 56, 57], "differenti": [0, 1, 3], "resiz": [0, 1, 3, 26, 31, 58, 59, 64, 65, 66, 67, 68, 69, 71], "224": [0, 1, 3, 30, 31, 58, 59, 64, 65, 67, 68, 71], "normal": [0, 1, 3, 10, 13, 31, 37, 42, 44, 45, 47, 48, 51, 53, 54, 58, 59, 60, 62, 65, 68, 71, 72], "pixel": [0, 1, 3, 18, 20, 22, 26, 31, 60, 62, 72], "logit": [0, 1, 3, 13, 35, 40, 44, 47, 58, 70, 71], "explanation_typ": [0, 1, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20], "string": [0, 1, 2, 3, 21, 30, 32], "both": [0, 1, 2, 3, 13, 23, 25, 30, 46, 52], "alia": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "where": [0, 1, 21, 23, 24, 25, 30, 37, 47], "py": [0, 1, 49, 66, 69, 72], "regist": [0, 1, 3], "automat": [0, 1, 2, 3, 11, 12, 13], "via": [0, 1, 2, 4, 6, 11, 18, 20, 58, 59, 61, 63, 64, 65, 67, 68], "defin": [0, 1, 4, 30, 31, 43, 49, 58, 59, 61, 63, 65, 66, 68, 69, 70], "toolbox": 0, "modul": [0, 30, 35, 36, 40, 48, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72], "fill": [0, 1, 31], "pipelin": [0, 1, 6, 32, 33, 34, 39, 49], "categori": [0, 1, 26, 37, 38], "basic": [0, 12, 16, 43], "object": [0, 2, 3, 10, 12, 13, 16, 20, 21, 26, 27, 28, 31, 32, 35, 36, 37, 38, 40, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 72], "hous": [0, 28], "price": [0, 28], "sentiment": [0, 1, 28, 33, 35, 36, 40], "imdb": [0, 1, 28], "anomali": [0, 1, 15, 16, 28], "detect": [0, 1, 15, 16, 28], "workflow": [0, 28], "accumul": [0, 11, 28], "effect": [0, 11, 28], "diabet": [0, 28], "logist": [0, 13, 28], "pariti": [0, 28, 49], "rank": [0, 28], "expan": [0, 28], "demo": [0, 28], "kei": [0, 1, 23, 28], "takeawai": [0, 28], "queri": [0, 23, 25, 28], "valid": [0, 28, 46, 52], "morri": [0, 11, 23, 28], "imagenet": [0, 1, 28, 58, 64, 65, 67, 68, 71], "mnist": [0, 18, 28, 30], "languag": [0, 28, 37], "question": [0, 7, 28, 37], "answer": [0, 7, 28, 37], "index": [0, 2, 13, 21, 22, 23, 24, 25, 27, 30, 34, 38, 41, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72], "search": [0, 18], "page": 0, "capabl": 1, "featur": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 72], "five": [1, 6], "subpackag": [1, 3], "simpl": [1, 11, 35, 36, 40, 49, 55, 56, 57, 58, 60, 61, 62, 63, 70, 72], "pillow": [1, 2, 30, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "One": [1, 26, 31, 32, 37, 40, 44, 46, 58, 70], "ordin": [1, 10, 13, 26, 31], "kbin": [1, 26], "standard": [1, 10, 13, 26, 31, 41, 42, 44, 45, 47, 48, 49, 51, 53, 54], "min": [1, 12, 26, 31, 35, 36, 40], "max": [1, 12, 26, 31, 35, 36, 40, 61, 63, 70], "rescal": [1, 19, 20, 26], "nan": [1, 26, 31], "recal": 1, "idf": [1, 26, 31, 37, 38], "token": [1, 2, 6, 8, 24, 30, 31, 34, 35, 36, 40, 66, 69], "id": [1, 6, 8, 21, 26, 31, 35, 36, 40], "combin": 1, "togeth": [1, 26, 37], "conveni": [1, 26], "particular": [1, 18, 37, 58], "main": [1, 26], "group": [1, 37, 49], "It": [1, 2, 3, 4, 5, 6, 11, 12, 13, 17, 19, 20, 22, 23, 24, 25, 26, 43, 58, 72], "further": [1, 41], "handl": [1, 13], "without": [1, 2, 12, 19, 37, 43, 59, 60, 61], "know": [1, 37], "either": [1, 2, 12, 13, 32, 40, 47], "feature_import": [1, 21], "store": [1, 2, 3, 22, 23, 24, 25, 26, 30, 58], "matplotlib": [1, 21, 22, 23, 24, 25, 60, 61, 62, 63, 72], "plotly_plot": [1, 21, 22, 23, 24, 25], "ipython_plot": [1, 21, 22, 23, 24, 25, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "ipython": [1, 21, 22, 23, 24, 25, 29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "word": [1, 6, 8, 24, 26, 32, 35, 36, 37, 40], "plotli": [1, 21, 22, 23, 24, 25, 27, 29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "figur": [1, 21, 22, 23, 24, 25, 27], "demonstr": 1, "architectur": 1, "four": [1, 29], "autoexplainerbas": [1, 3, 4, 5, 10, 14, 17, 29], "act": [1, 3, 32, 40, 53, 54, 55, 58], "factori": [1, 3, 32, 40, 53, 54, 55, 58], "": [1, 2, 6, 11, 18, 31, 32, 37, 41, 44, 49, 55, 56, 57, 64, 67, 70, 71], "next": [1, 37, 41], "resnet": [1, 3, 58, 59, 65, 68], "arxiv": [1, 6, 11, 12, 18, 19, 20, 37, 43, 44, 49, 59, 60, 61, 62, 63, 64, 65, 70], "org": [1, 6, 11, 12, 18, 19, 20, 37, 43, 44, 48, 49, 54, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70], "ab": [1, 6, 11, 12, 18, 19, 20, 37, 43, 44, 49, 59, 60, 61, 62, 63, 64, 65, 70], "1512": 1, "03385": 1, "pretrain": [1, 3, 34, 58, 59, 65, 66, 68, 69, 71], "www": [1, 66, 69], "net": [1, 37], "here": [1, 7, 11, 30, 32, 37, 43, 53, 54, 55, 56, 57, 58, 59, 65, 68, 71], "sampl": [1, 2, 6, 10, 11, 13, 16, 18, 20, 23, 26, 35, 36, 40, 49], "ig": [1, 3, 5, 10, 17, 35, 36, 40, 58, 69], "gradcam": [1, 3, 17, 58, 64, 65, 66], "2": [1, 23, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "resnet50": [1, 3, 58, 59, 65], "layer": [1, 6, 8, 11, 20, 35, 36, 40, 43, 49, 58, 60, 61, 62, 63, 64, 65, 66, 69, 70, 72], "target_lay": [1, 3, 17, 20, 58, 64, 65, 66, 69], "layer4": [1, 3, 17, 58, 65], "test_img": [1, 60, 62, 70, 72], "y": [1, 6, 8, 11, 12, 13, 18, 20, 26, 31, 34, 36, 40, 43, 61, 63, 64, 67, 70], "281": [1, 64, 67], "correspond": [1, 6, 7, 9, 10, 11, 12, 15, 16, 18, 20, 22, 23, 24, 25, 27, 37, 38, 42, 43, 44, 45, 47, 48, 49, 50, 51, 56, 57, 58, 59, 70, 71], "tiger_cat": [1, 64, 67], "top": [1, 6, 8, 11, 13, 18, 20, 64, 65, 67, 68, 71], "bull_mastiff": [1, 64, 67], "These": [1, 30, 46, 49, 52], "highlight": 1, "region": 1, "note": [1, 19, 20, 26, 35, 36, 37, 40, 41], "besid": [1, 30], "same": [1, 3, 4, 5, 10, 14, 17, 29, 35, 37, 41, 44, 70], "gradcam0": 1, "gradcam3": 1, "first": [1, 2, 8, 22, 23, 24, 25, 29, 30, 35, 36, 37, 40, 41, 44, 45, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 70, 72], "second": [1, 2, 30, 47], "consid": [1, 4, 32, 41, 43, 49, 58, 59, 65, 68], "goal": [1, 49], "review": [1, 35, 36, 40], "posit": [1, 20, 22, 26, 32, 33, 35, 36, 37, 39, 40, 41, 43, 62, 63], "neg": [1, 4, 13, 20, 22, 32, 33, 35, 36, 39, 40, 41, 43, 62, 63], "cnn": [1, 35, 36, 37, 40, 61, 63, 70], "suppos": [1, 30, 31, 37], "want": [1, 29, 30, 37, 42, 44, 45, 47, 48, 51, 53, 54], "do": [1, 29, 31, 32, 34, 37, 40, 41, 42, 44, 45, 47, 48, 51, 53, 54, 55, 58], "polyjuic": [1, 5, 32, 33, 34, 40], "embed": [1, 8, 11, 35, 36, 40, 49, 69], "embedding_lay": [1, 8, 35, 36, 40, 69], "id2token": [1, 8, 35, 36, 40], "id_to_token": 1, "wa": [1, 30, 32, 33, 35, 36, 37, 39, 40], "fantast": [1, 30, 33, 35, 36, 39, 40], "clearli": [1, 41], "largest": 1, "score": [1, 8, 11, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 32, 33, 41, 46, 49, 55, 56, 57, 60, 62, 72], "impli": [1, 15, 16, 41, 56, 57], "sentenc": [1, 2, 26, 30, 31, 35, 36, 37, 38, 40, 66, 69], "becaus": [1, 2, 9, 26, 29, 32, 37, 40, 41], "horribl": [1, 30, 33, 35, 36, 39, 40], "help": 1, "u": [1, 37, 53, 54], "understand": [1, 37], "behavior": [1, 41, 70], "univari": [1, 2, 55, 56, 57], "statist": 1, "detector": [1, 55, 56, 57], "window": [1, 55, 56, 57], "accord": [1, 31, 37], "threshold": [1, 16, 55, 56, 57], "estim": [1, 3, 4, 6, 10, 11, 12, 13, 18, 20, 26, 37, 42, 44, 45, 47, 48, 51, 70], "have": [1, 2, 19, 20, 26, 30, 31, 33, 35, 36, 37, 39, 41, 52], "train_df": [1, 55, 56, 57], "test_df": [1, 55, 56, 57], "anomaly_detect": [1, 14, 15, 16, 25, 55, 56, 57], "from_pd": [1, 2, 30, 55, 56, 57], "none": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 37, 43, 44, 55, 70], "001": [1, 6, 11, 16, 18, 55, 56], "timestamp": [1, 2, 30, 55, 56, 57], "20": [1, 6, 18, 22, 23, 30, 37, 41, 45, 47, 49, 51, 53, 55, 56, 57, 61, 63, 70], "00": [1, 32, 39, 55, 56, 57], "around": [1, 37, 55], "reason": 1, "why": [1, 37], "indic": [1, 2, 3, 23, 29, 30, 44, 45, 47, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 70, 72], "explanationbas": [1, 21, 22, 23, 24, 25], "avail": 1, "cannot": [1, 21, 22, 23, 25], "fulfil": 1, "auto": [1, 3, 20], "mutual_info": [1, 3], "chi_squar": [1, 3], "pixel_import": [1, 21], "mask": [1, 6, 21, 35, 36, 40], "word_import": [1, 21], "feature_column": [2, 3, 29, 30, 42, 43, 44, 45, 46, 47, 48, 51, 52], "batch": [2, 6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 23, 30, 31, 32, 35, 36, 37, 38, 40, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "shape": [2, 30, 31, 36, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 70, 72], "batch_siz": [2, 6, 11, 16, 18, 30, 35, 36, 40, 43, 58, 60, 61, 62, 63, 70, 72], "height": [2, 30, 58], "width": [2, 30, 49, 58], "channel": [2, 26, 30, 58], "true": [2, 3, 4, 11, 12, 16, 20, 22, 23, 24, 26, 30, 32, 33, 35, 36, 37, 39, 40, 43, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "channel_last": 2, "dimens": [2, 16], "fals": [2, 4, 11, 22, 23, 24, 30, 35, 36, 40, 49, 61, 63, 70, 72], "instead": [2, 29, 32, 37, 40, 41, 49, 53, 54, 55, 56, 57, 58, 72], "number": [2, 4, 6, 7, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 41, 49], "4": [2, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "pil": [2, 26, 30, 31, 58, 59, 64, 65, 66, 67, 68, 69, 71], "pilimag": [2, 26, 30, 31, 58, 59, 64, 65, 66, 67, 68, 69, 71], "im": [2, 3, 30, 58, 59, 61, 63, 64, 65, 67, 68, 70], "an_imag": 2, "jpg": [2, 26, 30, 31, 58, 59, 65, 66, 69], "hello": [2, 26, 31, 37], "m": [2, 26, 31, 49], "And": [2, 26, 31, 49], "anoth": [2, 23, 26, 31, 37, 64, 67], "veri": [2, 26, 31, 37], "allow": [2, 3, 4, 5, 10, 14, 17, 37, 53, 54, 58], "nltk": 2, "word_token": 2, "variabl": [2, 25, 30, 55, 56, 57], "num_vari": [2, 30], "construct": [2, 3, 13, 18, 29, 30, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "2017": [2, 30], "12": [2, 30, 31, 32, 37, 41, 45, 47, 49, 51, 53, 66, 69], "27": [2, 30, 37, 41, 45, 47, 49, 51, 53], "1263": [2, 30], "94091": [2, 30], "394": [2, 30], "507": [2, 30], "16": [2, 30, 43, 54, 55, 56, 57], "530": [2, 30], "28": [2, 30, 41, 45, 47, 51, 53, 60, 62, 72], "1299": [2, 30], "86398": [2, 30], "506": [2, 30], "424": [2, 30], "14": [2, 30, 31], "162": [2, 30], "date": [2, 30], "consumpt": [2, 30], "wind": [2, 30], "solar": [2, 30], "set_index": [2, 30, 49, 55, 56, 57], "to_datetim": [2, 30, 55, 56, 57], "t": [2, 5, 16, 17, 30, 35, 36, 37, 40, 41, 47, 55, 56, 57, 66, 69], "abstract": [2, 3, 21, 26], "differet": 2, "properti": [2, 3, 26], "data_typ": 2, "num_sampl": [2, 71], "union": [2, 12, 23, 24, 25, 26], "ndarrai": [2, 10, 11, 12, 13, 16, 20, 26], "num_featur": [2, 11, 23], "when": [2, 6, 7, 8, 10, 11, 12, 13, 15, 18, 20, 21, 22, 23, 24, 25, 30, 37, 41, 54, 70], "int": [2, 4, 6, 7, 11, 12, 18, 26, 35, 36, 40, 55, 56, 57], "iloc": [2, 55, 56, 57], "row": [2, 30, 41, 45, 47, 49, 51, 53, 54, 55, 56, 57], "slice": [2, 49], "tupl": [2, 26, 40, 64, 67, 71], "get": [2, 3, 21, 22, 23, 24, 25, 26, 30, 35, 36, 40, 49], "continuous_column": [2, 30], "except": 2, "sequenc": [2, 4, 26, 49], "copi": [2, 49], "otherwis": 2, "to_numpi": [2, 30, 43, 58, 60, 62, 72], "remove_target_column": [2, 47], "remov": [2, 31, 41, 49, 50, 72], "get_target_column": 2, "get_continuous_median": 2, "absolut": [2, 37], "median": [2, 12, 26, 31, 43], "dict": [2, 3, 4, 5, 8, 9, 10, 14, 17, 21, 22, 23, 24, 25, 27, 34, 53, 54], "get_continuous_bound": 2, "upper": [2, 12, 16], "lower": [2, 12, 16], "bound": [2, 12, 16], "grayscal": 2, "rgb": [2, 30, 31, 58, 59, 64, 65, 66, 67, 68, 69, 71], "h": [2, 26, 41, 45, 47, 51, 53], "w": [2, 26, 66, 69], "ignor": [2, 3, 8, 9, 11, 12, 13, 18, 20, 22, 23, 24, 41, 47], "bool": [2, 6, 11, 18], "size": [2, 6, 11, 18, 23, 26, 31, 66, 69], "color": [2, 30], "argument": [2, 37, 72], "image_shap": [2, 30], "hwc": [2, 30], "keepdim": [2, 30], "kept": [2, 37], "squeez": [2, 36, 40, 49], "to_pil": [2, 3, 30, 31, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71], "callabl": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 43], "to_token": [2, 30], "to_str": 2, "sep": [2, 7, 34, 35, 36, 40, 69], "maxsplit": 2, "variable_nam": 2, "multivari": [2, 55, 56, 57], "whose": [2, 8, 12, 13, 18, 20, 23, 31, 35, 36], "ts_len": [2, 16, 30], "length": [2, 16, 30, 32, 33, 34, 40], "classmethod": 2, "rtype": 2, "static": [2, 3, 4, 5, 10, 11, 13, 14, 17, 26], "get_timestamp_info": 2, "reset_timestamp_index": 2, "timestamp_info": 2, "move": 2, "float": [2, 6, 10, 11, 13, 16, 18, 26, 35, 49, 61, 63, 70], "restore_timestamp_index": 2, "origin": [2, 6, 8, 11, 13, 15, 18, 19, 20, 23, 25, 26, 35, 36, 37, 38, 39, 44, 45, 51, 57, 62, 63, 67, 68, 70, 71, 72], "kernel_width": [3, 10, 11, 41, 53, 54], "nsampl": [3, 10, 11, 15, 18, 41, 51, 53, 54, 55], "100": [3, 10, 11, 35, 36, 37, 40, 41, 44, 51, 53, 54, 58, 59, 61, 63, 70], "similar": [3, 26, 32, 40, 43, 52, 58], "img": [3, 17, 26, 30, 31, 58, 59, 64, 65, 67, 68, 71], "mainli": 3, "gbtree": [3, 41, 42, 44, 45, 47, 48, 51, 53], "predict_proba": [3, 10, 37, 38, 42, 44, 45, 47, 48, 51], "shaptabular": [3, 11, 51, 72], "training_data": [3, 4, 6, 10, 11, 12, 13, 15, 16, 18, 37, 42, 43, 44, 45, 47, 48, 49, 50, 51, 56, 57, 70], "compos": [3, 58, 59, 61, 63, 65, 68, 70, 71], "256": [3, 6, 11, 18, 35, 36, 40, 43, 49, 58, 59, 65, 68, 71], "centercrop": [3, 58, 59, 65, 68, 71], "totensor": [3, 58, 59, 61, 63, 65, 68, 70, 71], "mean": [3, 13, 22, 23, 24, 26, 27, 30, 31, 36, 37, 40, 44, 45, 47, 50, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 68, 70, 71, 72], "485": [3, 58, 59, 65, 68, 71], "456": [3, 58, 59, 65, 68, 71], "406": [3, 58, 59, 65, 68, 71], "std": [3, 26, 36, 40, 58, 59, 65, 68, 71], "229": [3, 58, 59, 65, 68, 71], "225": [3, 58, 59, 65, 68, 71], "stack": [3, 58, 59, 61, 63, 65, 66, 68, 69, 70, 71], "found": [3, 16, 66, 69], "explainerabcmeta": 3, "classnam": 3, "cls_dict": 3, "autodocabcmeta": 3, "meta": 3, "_explain": 3, "collect": [3, 4, 5, 10, 14, 17], "empti": [3, 5, 17, 20], "ani": [3, 5, 9, 10, 13, 14, 17, 37], "param_1": [3, 4, 5, 10, 14, 17], "lime_explan": 3, "shap_explan": 3, "ordereddict": [3, 4], "pdp_explan": [3, 4], "explainer_nam": 3, "list_explain": [3, 4, 5, 10, 14, 17], "mutual": [4, 29, 37, 41], "n_bin": [4, 26], "10": [4, 6, 11, 12, 16, 18, 19, 20, 22, 23, 30, 31, 35, 36, 40, 41, 49, 50, 53, 54, 55, 56, 57, 60, 61, 62, 63, 67, 70, 72], "overrid": 4, "imbalanceanalyz": 4, "count": [4, 23], "appear": [4, 23], "gender": [4, 43], "male": [4, 30, 31, 41, 43, 45, 47, 51, 53], "femal": [4, 30, 31, 41, 43, 45, 47, 51, 53], "separ": [4, 37, 44, 70], "cross": [4, 23, 29], "bin": [4, 16, 26], "discret": [4, 11, 26], "imbalanceexplan": [4, 23], "correlationanalyz": 4, "matrix": [4, 23], "scipi": 4, "stat": [4, 41], "spearmanr": 4, "correlationexplan": [4, 23], "mutualinform": 4, "globalfeatureimport": [4, 23], "chisquar": 4, "chi": [4, 29, 41], "squar": [4, 29, 41], "non": 4, "chi2": [4, 29, 41], "qa": [5, 7, 32, 34], "those": [5, 17, 31, 47], "don": [5, 17, 41, 47], "limetext": [6, 38], "pleas": [6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "cite": [6, 7, 8, 11, 12, 13, 15, 16, 18, 19, 20, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 47, 50, 51, 57, 59, 60, 61, 62, 63, 64, 65, 67, 68, 70, 71, 72], "work": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 37, 38, 39, 41, 44, 45, 51, 57, 62, 63, 67, 68, 70, 71, 72], "github": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 38, 39, 45, 50, 51, 57, 67, 68, 71, 72], "com": [6, 7, 8, 11, 13, 15, 18, 20, 33, 34, 35, 36, 38, 39, 45, 50, 51, 57, 66, 67, 68, 69, 71, 72], "marcotcr": [6, 11, 18, 38, 45, 71], "lime_text": 6, "limetextexplain": 6, "refer": [6, 11, 12, 18, 37, 44, 48, 49, 59, 60, 61, 62, 63, 70], "doc": [6, 11, 18, 29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "explain_inst": [6, 11, 18], "wordimport": [6, 8, 24], "shaptext": [6, 39], "slundberg": [6, 11, 13, 15, 18, 39, 51, 57, 72], "textclassificationpipelin": [6, 39], "text_classif": 6, "defaultselectionmodel": [6, 11, 18, 37, 44, 70], "_defaultmodelbas": [6, 11, 18], "consist": [6, 41], "1d": 6, "convolut": [6, 20, 58, 60, 61, 62, 63, 64, 65, 70, 72], "l2xtext": [6, 37], "hidden_s": [6, 11, 35, 36, 40], "hidden": [6, 11, 43, 60, 61, 62, 63, 70, 72], "kernel_s": [6, 35, 36, 40, 60, 61, 62, 63, 70, 72], "kernel": 6, "forward": [6, 11, 18, 36, 40, 61, 63, 70], "defaultpredictionmodel": [6, 11, 18, 37, 44, 70], "weight": [6, 11, 12, 16, 18, 19, 20, 36, 37, 40, 43, 64, 67], "gumbel": [6, 11, 18], "softmax": [6, 11, 18, 40, 58, 71], "tau": [6, 11, 18, 49], "k": [6, 11, 18, 35, 36, 40, 49, 58, 59, 64, 65, 67, 68, 71], "selection_model": [6, 11, 18, 37, 44, 70], "prediction_model": [6, 11, 18, 37, 44, 70], "loss_funct": [6, 11, 18, 66, 69], "optim": [6, 11, 12, 16, 18, 19, 20, 35, 36, 40, 43, 49, 56, 59, 60, 61, 62, 63, 70, 72], "learning_r": [6, 11, 12, 16, 18, 19, 20, 35, 36, 40, 43, 61, 63, 70], "num_epoch": [6, 11, 18, 35, 36, 40, 49, 61, 63, 70], "theoret": [6, 11, 18, 37, 44, 70], "perspect": [6, 11, 18, 37, 44, 70], "jianbo": [6, 11, 18, 37, 44, 70], "chen": [6, 11, 18, 37, 44, 70], "le": [6, 11, 18, 37, 44, 70], "song": [6, 11, 18, 37, 44, 70], "martin": [6, 11, 18, 37, 44, 70], "j": [6, 11, 18, 37, 44, 49, 70], "wainwright": [6, 11, 18, 37, 44, 70], "michael": [6, 11, 18, 37, 44, 70], "jordan": [6, 11, 18, 37, 44, 70], "1802": [6, 11, 18, 20, 37, 44, 62, 63, 70], "07814": [6, 11, 18, 37, 44, 70], "maximum": [6, 7, 11, 12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 34, 40, 49], "p": [6, 11, 18, 37, 44, 70, 71], "q": [6, 11, 18, 37, 44, 49, 70], "x_": [6, 11, 18, 37, 44, 70], "nn": [6, 8, 11, 12, 13, 18, 19, 20, 35, 36, 40, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "crossentropyloss": [6, 11, 18, 36, 40, 61, 63, 70], "adamw": [6, 36, 40], "rate": [6, 11, 12, 16, 18, 19, 20, 49], "pick": [6, 11, 18], "32": [6, 11, 18, 36, 40, 54, 60, 62, 70, 72], "64": [6, 11, 18, 43, 49, 60, 62, 72], "128": [6, 11, 18, 35, 36, 40, 43, 60, 61, 62, 63, 72], "epoch": [6, 11, 18, 35, 43, 60, 61, 62, 63, 70, 72], "develop": [7, 12, 16, 29, 32, 33, 34, 40, 41, 47, 53, 54, 55, 58], "wu": [7, 33, 34], "et": [7, 12, 16, 20, 33, 34, 47, 64, 65], "tongshuangwu": [7, 33, 34], "pr": 7, "model_path": 7, "cuda": [7, 36, 40, 58, 61, 63, 66, 68, 69, 70, 71], "max_number_exampl": [7, 12], "context": [7, 34, 49], "concaten": [7, 26, 36, 40, 50, 54, 58, 64, 67], "seper": [7, 34], "ce_typ": 7, "perturb": 7, "blank": 7, "cfexplan": [7, 12, 16, 19, 22, 23, 25], "integratedgradienttext": [8, 35, 36], "ankurtali": [8, 13, 20, 35, 36, 67, 68], "kera": [8, 12, 13, 18, 19, 20, 35, 36, 43, 49, 59, 60, 61, 62, 63, 64, 65, 67, 68, 72], "must": [8, 35, 36, 40, 41], "map": [8, 11, 35, 36], "integrated_gradi": [8, 13, 20], "integratedgradi": [8, 13, 17, 20, 69], "compute_integrated_gradi": [8, 13, 20], "curv": 9, "sklearnbas": [10, 13], "cate_encod": [10, 13], "onehot": [10, 13, 26, 31], "cont_encod": [10, 13], "target_encod": [10, 13], "baseestim": 10, "transformbas": [10, 13, 26], "ident": [10, 13, 26, 50, 54], "minmax": [10, 13, 26, 31, 42, 44, 45, 47, 48, 51, 53, 54], "scale": [10, 11, 13, 26, 31], "proport": [10, 13], "ce": [10, 14, 17, 58], "decision_tre": [10, 52], "shap_tre": 10, "limetabular": [11, 45], "lime_tabular": 11, "limetabularexplain": 11, "featureimport": [11, 13, 15, 23, 25], "kernelexplain": [11, 15], "shap_valu": [11, 15], "re": [11, 15, 26, 37, 38], "evalu": [11, 15, 35, 36, 40, 43, 60, 61, 62, 63, 70, 72], "partialdependencetabular": [11, 48], "stabl": [11, 48, 49, 54], "partial_depend": [11, 18, 48], "html": [11, 48, 49, 54], "grid_resolut": [11, 18], "candid": 11, "dure": [11, 12, 16, 19, 20], "monte_carlo": 11, "monte_carlo_step": 11, "monte_carlo_frac": 11, "studi": [11, 23], "mont": [11, 23], "carlo": [11, 23], "randomli": [11, 20], "pdpexplan": [11, 23], "christophm": 11, "io": [11, 29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "book": 11, "accumulated_local_effect": 11, "cmd": 11, "mat": [11, 37], "classic": 11, "multidimension": 11, "en": 11, "wikipedia": 11, "wiki": 11, "multidimensional_sc": 11, "classical_multidimensional_sc": 11, "aleexplan": 11, "sensitivityanalysistabular": [11, 50], "salib": [11, 50], "sa": 11, "sensitivityexplan": [11, 23], "feedforward": [11, 43], "neural": [11, 60, 61, 62, 63, 70, 72], "network": [11, 20, 37, 43, 44, 60, 61, 62, 63, 64, 65, 70, 72], "l2xtabular": [11, 44], "adam": [11, 18, 35, 60, 61, 62, 63, 70, 72], "Not": [11, 13, 19, 41, 45, 47, 51, 53], "maceexplain": [12, 16, 47, 56], "yang": [12, 16, 47], "paper": [12, 16, 19, 20, 43, 47, 59, 60, 61], "effici": [12, 16, 47], "framework": [12, 16, 34, 47], "cfretriev": 12, "gld": 12, "retriev": 12, "desir": [12, 26, 70], "counterfactualoptim": [12, 16], "x0": [12, 16, 20], "c": [12, 16, 19, 20, 26, 29, 30, 31, 32, 37, 40, 41, 53, 54, 55, 58, 71], "kappa": [12, 16, 19, 20], "binary_search_step": [12, 16, 19, 20, 58, 59, 60, 61, 62, 63], "01": [12, 16, 19, 20, 36, 40, 55, 56, 57], "num_iter": [12, 16, 19, 20, 58, 59, 60, 61, 62, 63], "1000": [12, 16, 19, 20, 50, 55, 64, 67, 71], "grad_clip": [12, 16, 19, 20], "gamma": [12, 16, 20], "autom": [12, 19, 43, 59, 60, 61], "gdpr": [12, 19, 43, 59, 60, 61], "sandra": [12, 19, 43, 59, 60, 61], "wachter": [12, 19, 43, 59, 60, 61], "brent": [12, 19, 43, 59, 60, 61], "mittelstadt": [12, 19, 43, 59, 60, 61], "chri": [12, 19, 43, 59, 60, 61], "russel": [12, 19, 43, 59, 60, 61], "1711": [12, 19, 43, 59, 60, 61], "00399": [12, 19, 43, 59, 60, 61], "hing": [12, 16, 19, 20], "term": [12, 16, 19, 20], "iter": [12, 16, 19, 20], "adjust": [12, 16, 19, 20], "clip": [12, 16, 19, 20], "denomin": [12, 16], "regular": [12, 16, 20], "verbos": [12, 16, 20, 36, 40, 43, 60, 62, 72], "counterfactualexplain": [12, 16, 19, 43, 59, 60, 61, 63], "extract": [12, 22, 23, 26, 43], "inp": 13, "baselin": [13, 20], "output_index": 13, "50": [13, 35, 36, 40, 41, 45, 47, 51, 53, 61, 63, 70], "integratedgradienttabular": 13, "num_random_tri": [13, 20], "trial": [13, 20], "_sample_baselin": 13, "linearbas": 13, "coeffici": [13, 23, 46], "linearexplan": [13, 23], "linearregress": [13, 46], "lasso": 13, "linear_regress": 13, "logisticregress": [13, 46], "logistic_regress": 13, "treebas": 13, "random": [13, 26, 37, 38, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54], "forest": [13, 37, 38, 50, 54], "structur": [13, 23, 32, 37, 44, 52, 60, 62, 70], "path": [13, 23, 29, 37, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57], "treeexplan": [13, 23], "treeregressor": [13, 52], "regressor": [13, 54], "decisiontreeregressor": 13, "tree_regressor": 13, "treeclassifi": [13, 52], "decisiontreeclassifi": 13, "tree_classifi": 13, "shaptreetabular": 13, "forecast": [14, 15, 16, 25, 55, 57], "shaptimeseri": [15, 57], "higher": [15, 16, 41, 55, 56, 57], "anomal": [15, 16, 55, 56, 57], "smooth_weight": 16, "grid_siz": 16, "reshap": [16, 50, 54, 60, 62, 72], "determin": [16, 37, 49, 55, 56, 57], "smooth": 16, "numer": [16, 49], "revis": 16, "version": [16, 32, 37, 40, 66, 69], "rl": 16, "cem": 17, "limeimag": [18, 71], "top_label": 18, "limeimageexplain": 18, "maskexplan": [18, 22], "shapimag": [18, 72], "background_data": [18, 20], "background": [18, 20], "pixelimport": [18, 20, 22], "partialdependenceimag": 18, "segment": 18, "quickshift": 18, "measur": 18, "averag": [18, 23, 35, 36, 37, 38, 40], "replac": [18, 43], "grid": [18, 23], "resolut": 18, "n_segment": 18, "l2ximag": [18, 70], "upsampl": [18, 70], "been": [19, 20, 37, 66, 69], "255": [19, 20, 31, 60, 62, 72], "integratedgradientimag": [20, 67, 68], "selvaraju": [20, 64, 65], "1610": [20, 64, 65], "02391": [20, 64, 65], "gradcamplu": 20, "chattopadhyai": 20, "pdf": 20, "1710": 20, "11063": 20, "cemoptim": 20, "beta": 20, "ae_model": 20, "07623": [20, 62, 63], "l1": 20, "ae": 20, "pn_optim": 20, "pertin": [20, 22, 62, 63], "pp_optim": 20, "contrastiveexplain": [20, 62, 63], "contrastiveexplan": [20, 22], "get_explan": [21, 22, 23, 24, 25, 49], "compon": [21, 37], "dump": [21, 26, 29], "pickl": 21, "unpickl": 21, "byte": 21, "byte_str": 21, "dashfigur": 21, "to_html_div": 21, "to_html": 21, "predictedresult": 21, "classfic": 21, "max_num_subplot": [21, 23, 24], "subplot": [21, 23, 24], "use_heatmap": 22, "item": [22, 23, 24, 25, 41, 53, 54, 61, 63, 70], "entri": [22, 23, 24], "target_label": [22, 23, 24], "heatmap": 22, "importance_scor": [22, 23, 24, 25], "max_num_figur": 22, "dog": [22, 23, 24, 27, 58, 66, 69], "cat": [22, 23, 24, 27, 36, 37, 40], "boundari": 22, "pn": 22, "pn_label": 22, "pp": 22, "pp_label": 22, "cf": [22, 23, 25], "cf_label": 22, "counterfactualexplan": 22, "feature_valu": 23, "sort": [23, 24, 31], "font_siz": 23, "font": 23, "tabl": 23, "sampled_scor": 23, "mu": 23, "mu_star": 23, "sigma": 23, "mu_star_conf": 23, "plot_coeffici": 23, "tick": 23, "binari": [23, 35, 36, 37, 38, 40, 43, 58, 59, 60, 61, 62, 63], "add_glob": 23, "whole": [23, 37], "add_loc": 23, "decision_path": 23, "node_ind": 23, "node": 23, "figsiz": 23, "15": [23, 30, 37, 41, 45, 47, 51, 53, 55, 56, 57], "fontsiz": 23, "num_tokens_per_class": 24, "shown": 24, "max_length": [24, 32, 33, 34, 35, 36, 40], "512": 24, "figure_typ": 25, "max_num_variables_to_plot": 25, "25": [25, 49, 54], "bar": 25, "invers": [26, 31, 45, 51], "b": [26, 30, 31], "d": [26, 30, 31, 33], "cate_transform": [26, 31], "cont_transform": [26, 31, 42, 44, 45, 47, 48, 51, 53, 54], "fillnan": 26, "fillnantabular": [26, 31], "pseudo": 26, "recov": 26, "some_imag": 26, "360": 26, "240": [26, 31, 71], "tfidf": [26, 31, 35, 36, 37, 38, 40], "vector": [26, 31, 37, 38], "drop": [26, 41, 43, 50, 55, 56, 57], "get_feature_nam": [26, 31], "input_featur": 26, "zero": [26, 35, 36, 40], "unit": [26, 41, 43, 45, 47, 49, 51, 53, 55, 56, 57], "varianc": 26, "ratio": 26, "miss": 26, "chosen": 26, "itself": 26, "save": [26, 49], "target_transform": [26, 31, 50, 54], "decompos": 26, "hold": [26, 37], "expect": 26, "ith": 26, "00392156862745098": 26, "round2int": 26, "round": 26, "deviat": 26, "resampl": 26, "bilinear": [26, 70], "smaller": 26, "edg": 26, "strategi": 26, "word2id": [26, 31, 35, 36, 40], "remove_punctu": 26, "pad": [26, 35, 36, 40], "start": [26, 37, 49], "unk": [26, 31], "vocab_s": [26, 35, 36, 40], "sub": 26, "over": 26, "fraction": 26, "random_st": [26, 43], "guarante": 26, "seed": [26, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53], "undersampl": 26, "balanc": 26, "minor": 26, "decreas": [26, 41], "major": 26, "oversampl": 26, "increas": [26, 37, 41], "data_explan": [27, 41], "predic": 27, "host": [27, 38], "127": [27, 29, 32, 40, 41, 53, 54, 55, 58], "port": 27, "8050": [27, 29, 32, 40, 41, 53, 54, 55, 58], "omnixai": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "render": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "sphinx": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "delet": [29, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "cell": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "pio": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "png": [29, 32, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "o": [29, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 66, 69], "join": [29, 41, 42, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57], "now": [29, 35, 36, 37, 40, 41, 49, 53, 54, 58, 61, 63, 70], "than": [29, 34, 37], "onc": [29, 37], "n": [29, 30, 35, 36, 40, 49], "append": [29, 33, 36, 40, 64, 67], "print": [29, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 71, 72], "serv": [29, 32, 40, 41, 53, 54, 55, 58], "flask": [29, 32, 40, 41, 53, 54, 55, 58], "34": [29, 30, 31, 32, 40, 41, 53, 54, 55, 58], "lazi": [29, 32, 40, 41, 53, 54, 55, 58], "environ": [29, 32, 34, 40, 41, 49, 53, 54, 55, 58], "product": [29, 32, 40, 41, 53, 54, 55, 58], "warn": [29, 32, 37, 40, 41, 53, 54, 55, 58, 72], "server": [29, 32, 40, 41, 53, 54, 55, 58], "deploy": [29, 32, 40, 41, 53, 54, 55, 58], "wsgi": [29, 32, 40, 41, 53, 54, 55, 58], "debug": [29, 32, 40, 41, 53, 54, 55, 58], "off": [29, 32, 37, 40, 41, 53, 54, 55, 58], "press": [29, 32, 40, 41, 53, 54, 55, 58], "ctrl": [29, 32, 40, 41, 53, 54, 55, 58], "quit": [29, 32, 40, 41, 53, 54, 55, 58], "notebook": [30, 49], "how": [30, 37, 41, 49], "f": [30, 31, 35, 41, 49, 53, 54], "39": [30, 31, 41, 45, 47, 49, 51, 53, 54, 64, 67, 71], "ye": [30, 31, 37, 43], "swap": 30, "digit": [30, 60, 61, 62, 63, 70, 72], "torchvis": [30, 58, 59, 61, 63, 65, 68, 70, 71], "download": [30, 61, 63, 66, 69, 70], "10000": [30, 55, 56, 57], "11": [30, 31, 37, 41, 49, 50, 72], "displai": [30, 31], "loop": 30, "camera": [30, 31, 58, 59, 65], "what": [30, 32, 33, 34, 35, 36, 37, 39], "great": [30, 32, 33, 35, 36, 37, 39, 40], "movi": [30, 32, 33, 35, 36, 39, 40], "tast": [30, 33, 35, 36, 39], "best": [30, 33, 35, 36, 39, 40], "film": [30, 33, 35, 36, 39, 40], "ever": [30, 33, 35, 36, 39, 40], "ve": [30, 33, 35, 36, 39, 40], "never": [30, 33, 35, 36, 39, 40, 41, 45, 47, 51, 53], "watch": [30, 33, 35, 36, 39, 40], "someth": [30, 33, 35, 36, 37, 39, 40], "bad": [30, 33, 35, 36, 37, 39, 40], "len": [30, 35, 36, 40, 58, 59, 64, 65, 67, 68, 71], "17": [30, 39, 54, 55, 56, 57], "18": [30, 37, 49, 54], "29": 30, "1319": 30, "76541": 30, "610": 30, "314": 30, "173": 30, "19": [30, 37, 49], "try": [31, 42, 44, 45, 47, 48, 49, 51, 53, 54], "22474487": 31, "120": 31, "6227660078332259": 31, "4736296010332684": 31, "5178561161676974": 31, "680918560398684": 31, "7265094189091538": 31, "3632547094545769": 31, "2762645695949752": 31, "unknown": 31, "xxx": 31, "lt": [31, 41, 45, 47, 51, 53], "gt": [31, 41, 45, 47, 51, 53], "limit": [32, 40], "interview": 32, "neither": 32, "funni": 32, "nor": 32, "witti": 32, "even": [32, 37], "like": [32, 37], "overal": [32, 37], "distilbert": [32, 33, 39], "uncas": [32, 33, 39], "finetun": [32, 33, 39], "sst": [32, 33, 39], "english": [32, 33, 39], "return_all_scor": [32, 33, 39], "ss": 32, "There": [32, 40, 58], "partit": [32, 37, 39], "3it": 32, "70": 32, "info": [32, 33, 34, 40, 49], "polyjuice_wrapp": [32, 33, 34, 40], "setup": [32, 33, 34, 40], "spaci": [32, 33, 34, 40], "processor": [32, 33, 34, 40, 66, 69], "perplex": [32, 33, 34, 40], "scorer": [32, 33, 34, 40], "ask": [32, 33, 34, 37, 40], "truncat": [32, 33, 34, 40], "predefin": [32, 33, 34, 40], "werkzeug": [32, 40], "idx2label": [33, 58, 59, 64, 65, 67, 68, 71], "build": [33, 34, 41, 61, 63, 66, 69], "def": [33, 34, 35, 36, 40, 43, 49, 55, 56, 57, 61, 63, 64, 66, 67, 69, 70, 71], "_predict": [33, 34], "pred": 33, "els": [33, 35, 36, 37, 40, 58, 60, 61, 62, 63, 68, 70, 71, 72], "unittest": [34, 35, 46, 66, 69, 71], "model_nam": 34, "deepset": 34, "roberta": 34, "squad2": 34, "isinst": [34, 49], "farm": 34, "give": [34, 37], "freedom": 34, "peopl": [34, 37], "switch": 34, "covers": 34, "electr": 34, "vehicl": 34, "emit": 34, "less": [34, 37], "harm": 34, "pollut": 34, "convent": 34, "ultim": 34, "cleaner": [34, 41, 45, 47, 51, 53], "human": [34, 37], "beings": 34, "eletr": 34, "fetch_20newsgroup": [35, 36, 37, 38, 40], "textmodel": [35, 36, 40], "num_embed": [35, 36, 40], "num_class": [35, 36, 40, 60, 62, 72], "super": [35, 36, 40, 61, 63, 70], "embedding_s": [35, 36, 40], "embeddings_initi": 35, "randomuniform": 35, "minval": 35, "maxval": 35, "conv_lay": [35, 36, 40, 61, 63, 70], "conv1d": [35, 36, 40], "activ": [35, 36, 37, 40, 43, 49, 60, 62, 72], "relu": [35, 36, 40, 49, 60, 61, 62, 63, 70, 72], "dropout": [35, 36, 40, 49, 60, 61, 62, 63, 70, 72], "output_lay": [35, 36, 40], "dens": [35, 43, 49, 60, 61, 62, 63, 70, 72], "expand_dim": [35, 49, 60, 62, 64, 67, 72], "axi": [35, 36, 40, 43, 49, 50, 54, 60, 62, 64, 67, 72], "reduce_max": 35, "concat": 35, "relat": [35, 36, 37, 38, 40], "read_csv": [35, 36, 40, 43, 49, 55, 56, 57], "home": [35, 36, 40, 66, 69, 72], "ywz": [35, 36, 40, 66, 69, 72], "labeledtraindata": [35, 36, 40], "tsv": [35, 36, 40], "x_train": [35, 36, 37, 38, 40, 43, 50, 54, 60, 61, 62, 63, 72], "y_train": [35, 36, 37, 38, 40, 43, 50, 54, 60, 61, 62, 63, 72], "astyp": [35, 36, 40, 43, 55, 56, 57, 60, 62, 72], "x_test": [35, 36, 37, 38, 40, 43, 50, 54, 60, 61, 62, 63, 72], "y_test": [35, 36, 37, 38, 40, 43, 50, 54, 60, 61, 62, 63, 72], "max_len": [35, 36, 40], "float32": [35, 36, 40, 43, 49, 60, 62, 72], "1e": [35, 36, 40, 61, 63, 70], "loss_fn": 35, "sparsecategoricalcrossentropi": 35, "from_logit": [35, 43, 60, 62, 72], "train_dataset": 35, "from_tensor_slic": 35, "shuffl": [35, 36, 40, 61, 63, 70], "buffer_s": 35, "1024": 35, "enumer": [35, 61, 63, 70], "gradienttap": 35, "tape": 35, "trainable_weight": 35, "apply_gradi": 35, "zip": [35, 61, 63, 70, 71], "200": [35, 43, 54], "6866752505302429": 35, "4109169542789459": 35, "21237820386886597": 35, "1540527492761612": 35, "08126655220985413": 35, "02999718114733696": 35, "008433952927589417": 35, "009998280555009842": 35, "0030068857595324516": 35, "001554026734083891": 35, "argmax": [35, 36, 40], "accuraci": [35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 60, 61, 62, 63, 70, 72], "f1_score": [35, 36, 37, 38, 40], "8560798903465829": 35, "id_to_word": [35, 36, 40], "util": [36, 40, 43, 60, 61, 62, 63, 70, 72], "trainer": [36, 40], "inputdata": [36, 40, 61, 63, 70], "dataload": [36, 40, 61, 63, 70], "normal_": [36, 40], "modulelist": [36, 40], "unsqueez": [36, 40, 71], "dim": [36, 40, 58, 71], "permut": [36, 40], "devic": [36, 40, 58, 61, 63, 68, 70, 71], "is_avail": [36, 40, 58, 61, 63, 68, 70, 71], "cpu": [36, 40, 58, 61, 63, 68, 70, 71], "optimizer_class": [36, 40], "loss_func": [36, 40, 61, 63, 70], "train_x": [36, 40], "train_i": [36, 40], "complet": [36, 37, 40, 44, 70], "0008": 36, "eval": [36, 40, 61, 63, 70, 71], "data_load": [36, 40], "collate_fn": [36, 40], "collate_func": [36, 40], "detach": [36, 40, 70, 71], "8458027386386188": 36, "advantag": [37, 44, 70], "fast": [37, 44, 70], "disadvantag": [37, 44, 70], "qualiti": [37, 44, 70], "highli": [37, 41, 44, 70], "affect": [37, 44, 70], "factor": [37, 44, 70], "hyperparamet": [37, 44], "ensembl": [37, 38, 46, 50, 53, 54], "alt": [37, 38], "atheism": [37, 38], "soc": [37, 38], "religion": [37, 38], "christian": [37, 38], "newsgroups_train": [37, 38], "newsgroups_test": [37, 38], "tfdif": [37, 38], "train_vector": [37, 38], "test_vector": [37, 38], "randomforestclassifi": [37, 38], "500": [37, 38], "925233644859813": 37, "idx": [37, 38], "83": [37, 38, 66, 69], "0039": 37, "8674698795180723": 37, "subject": [37, 38], "request": 37, "darwin": 37, "fish": 37, "organ": [37, 38], "univers": 37, "mexico": 37, "albuquerqu": 37, "recent": 37, "seen": 37, "anyon": [37, 38], "contact": 37, "email": 37, "me": 37, "john": 37, "dan": 37, "rose": 37, "aros": 37, "nation": [37, 38], "repent": 37, "my": 37, "own": [37, 41, 45, 47, 51, 53], "view": [37, 49], "63": 37, "mcovingt": 37, "covington": 37, "heard": 37, "radio": 37, "todai": 37, "student": 37, "confer": 37, "were": 37, "america": 37, "sin": [37, 38], "sexual": 37, "promiscu": 37, "repli": 37, "ca": 37, "claim": 37, "someon": 37, "am": 37, "fact": 37, "him": 37, "jesu": 37, "equip": 37, "judg": 37, "lewi": 37, "essai": 37, "world": 37, "war": 37, "ii": 37, "leader": 37, "britain": 37, "urg": 37, "horror": 37, "strongli": 37, "disagre": 37, "turn": 37, "behav": 37, "incredibli": 37, "toward": 37, "god": 37, "encourag": 37, "forc": 37, "folk": 37, "particip": 37, "directli": [37, 46], "oppos": 37, "written": 37, "far": 37, "abov": [37, 41, 43, 61, 63, 70], "luxuri": 37, "live": 37, "land": 37, "slaughter": 37, "children": 37, "million": 37, "stricken": 37, "out": 37, "honor": 37, "due": 37, "everi": 37, "ow": 37, "apologi": 37, "bit": [37, 41], "public": 37, "said": [37, 38], "decai": 37, "bibl": 37, "quiz": 37, "distribut": 37, "articl": 37, "healta": 37, "tammi": 37, "r": [37, 58, 59, 64, 65, 66, 67, 68, 69, 71], "heali": 37, "coven": 37, "he": 37, "idol": 37, "worship": 37, "high": 37, "priest": 37, "could": 37, "enter": 37, "holi": 37, "year": 37, "dai": 37, "aton": 37, "familiar": 37, "knowledg": 37, "believ": 37, "translat": 37, "would": 37, "had": 37, "think": 37, "wrong": 37, "again": 37, "just": 37, "suggest": 37, "correct": 37, "dean": 37, "danb": 37, "babcock": 37, "thought": 37, "commun": 37, "compani": 37, "voic": 37, "bil": 37, "bill": 37, "conner": 37, "jame": 37, "felder": 37, "spbach": 37, "wrote": 37, "logic": 37, "alert": 37, "incredul": 37, "hard": 37, "doe": 37, "liar": 37, "pursuas": 37, "look": [37, 49], "koresh": 37, "yourself": 37, "basi": 37, "reject": 37, "account": 37, "thing": 37, "madalyn": 37, "face": 37, "silli": 37, "okai": 37, "disbeliev": 37, "admit": 37, "fallaci": 37, "awar": 37, "reader": 37, "assert": 37, "mam": 37, "mike": 37, "mcangu": 37, "american": 37, "evolut": 37, "tin": 37, "pl9": 37, "53": [37, 41, 45, 47, 51, 53], "tue": 37, "apr": 37, "1993": 37, "gmt": 37, "robert": 37, "singleton": 37, "bob": 37, "sure": 37, "exclus": 37, "lend": 37, "notion": 37, "posterior": 37, "atheist": 37, "pitch": 37, "thu": 37, "necessarili": 37, "reduc": 37, "quantiti": 37, "theist": 37, "divin": 37, "fall": 37, "prei": 37, "ockham": 37, "razor": 37, "phenomenon": 37, "being": 37, "satisfactorili": 37, "independ": 37, "evid": 37, "occam": 37, "law": 37, "natur": 37, "often": 37, "end": 37, "seem": 37, "odd": 37, "simultan": 37, "condemn": 37, "primit": 37, "unscientif": 37, "childish": 37, "yet": [37, 49], "complex": 37, "scientif": 37, "straightforeward": 37, "appar": 37, "cute": 37, "character": 37, "howev": 37, "inconsist": 37, "statement": 37, "still": 37, "unnecessari": 37, "level": 37, "idea": 37, "themselv": 37, "thei": [37, 41], "unnecessarili": 37, "descript": 37, "part": 37, "sfp": 37, "sheila": 37, "patterson": 37, "mari": 37, "assumpt": 37, "cornel": 37, "cit": 37, "22": [37, 41, 45, 47, 51, 53, 54], "mpaul": 37, "marxhausen": 37, "paul": 37, "feel": 37, "better": 37, "phrase": 37, "sai": 37, "parent": 37, "sanctifi": 37, "beyond": 37, "sound": 37, "inabl": 37, "grasp": 37, "grace": 37, "incarn": 37, "through": 37, "alwai": [37, 49], "impress": 37, "chose": 37, "woman": 37, "bring": 37, "himself": 37, "prove": 37, "down": 37, "hi": 37, "perfect": 37, "touch": 37, "ah": 37, "wonder": 37, "ithaca": 37, "ny": 37, "mark": 37, "boston": [37, 50], "asid": 37, "moder": 37, "rick": 37, "granberri": 37, "wo": 37, "quot": 37, "error": 37, "opinion": 37, "writer": 37, "plain": 37, "confus": 37, "come": [37, 49], "lexington": 37, "church": 37, "brought": 37, "team": 37, "actual": 37, "il": 37, "up": [37, 49], "friend": 37, "tell": 37, "go": [37, 66, 69], "northeast": 37, "wast": 37, "talent": 37, "realli": 37, "kind": [37, 53, 54], "insid": 37, "joke": 37, "took": 37, "well": 37, "inde": 37, "misinform": 37, "sun": 37, "ok": 37, "mail": 37, "marshal": 37, "kevin": 37, "death": 37, "penalti": 37, "polit": 37, "virginia": 37, "tech": [37, 41, 45, 47, 51, 53], "scienc": 37, "dept": 37, "blacksburg": 37, "va": 37, "46": 37, "fascin": 37, "argu": 37, "abort": 37, "defend": 37, "homosexu": 37, "popul": [37, 54], "control": 37, "insist": 37, "biolog": 37, "punish": 37, "benedikt": 37, "contardictori": 37, "case": [37, 49], "excel": 37, "growth": 37, "sorri": 37, "escap": 37, "assum": 37, "alik": 37, "vari": 37, "greatli": 37, "attack": 37, "presum": 37, "present": 37, "person": 37, "right": 37, "regardless": 37, "arrog": 37, "individu": 37, "bodi": 37, "domain": 37, "jcj": 37, "becom": [37, 41], "huh": 37, "whuzzat": 37, "muirm": 37, "maxwel": 37, "muir": 37, "candor": 37, "happi": 37, "proven": 37, "problem": 37, "broken": 37, "went": 37, "journei": 37, "lukewarm": 37, "agnostic": 37, "although": 37, "faith": 37, "jeff": 37, "johnson": 37, "9230769230769231": 38, "nntp": 38, "murder": 38, "7it": 39, "51": [39, 41, 43], "0010": 40, "8492442322991249": 40, "tensor": [40, 58, 59, 61, 63, 65, 68], "preprocess_func": [40, 60, 62, 72], "postprocess_func": 40, "state": [41, 45, 47, 51, 53], "gov": [41, 45, 47, 51, 53], "77516": [41, 45, 47, 51, 53], "bachelor": [41, 45, 47, 51, 53], "emp": [41, 45, 47, 51, 53], "inc": [41, 45, 47, 51, 53], "83311": [41, 45, 47, 51, 53], "38": [41, 45, 47, 51, 53], "privat": [41, 45, 47, 51, 53], "215646": [41, 45, 47, 51, 53], "234721": [41, 45, 47, 51, 53], "11th": [41, 45, 47, 51, 53], "338409": [41, 45, 47, 51, 53], "32556": [41, 45, 47, 51, 53], "257302": [41, 45, 47, 51, 53], "assoc": [41, 45, 47, 51, 53], "acdm": [41, 45, 47, 51, 53], "32557": [41, 45, 47, 51, 53], "40": [41, 45, 47, 51, 53], "154374": [41, 45, 47, 51, 53], "32558": [41, 45, 47, 51, 53], "58": [41, 45, 47, 51, 53], "151910": [41, 45, 47, 51, 53], "32559": [41, 45, 47, 51, 53], "201490": [41, 45, 47, 51, 53], "32560": [41, 45, 47, 51, 53], "52": [41, 45, 47, 51, 53, 54], "287927": [41, 45, 47, 51, 53], "marri": [41, 45, 47, 51, 53], "adm": [41, 45, 47, 51, 53], "cleric": [41, 45, 47, 51, 53], "white": [41, 45, 47, 51, 53], "civ": [41, 45, 47, 51, 53], "spous": [41, 45, 47, 51, 53], "exec": [41, 45, 47, 51, 53], "manageri": [41, 45, 47, 51, 53], "husband": [41, 45, 47, 51, 53], "divorc": [41, 45, 47, 51, 53], "handler": [41, 45, 47, 49, 51, 53], "prof": [41, 45, 47, 51, 53], "specialti": [41, 45, 47, 51, 53], "wife": [41, 45, 47, 51, 53], "op": [41, 45, 47, 51, 53], "inspct": [41, 45, 47, 51, 53], "widow": [41, 45, 47, 51, 53], "unmarri": [41, 45, 47, 51, 53], "child": [41, 45, 47, 51, 53], "2174": [41, 45, 47, 51, 53], "50k": [41, 45, 47, 51, 53], "cuba": [41, 45, 47, 51, 53], "15024": [41, 45, 47, 51, 53], "32561": [41, 45, 47, 51, 53], "lead": 41, "potenti": 41, "sociolog": 41, "bia": 41, "observ": [41, 54], "strong": 41, "matrit": 41, "imbalanc": 41, "among": 41, "therefor": 41, "avoid": 41, "rough": 41, "educt": 41, "least": 41, "them": [41, 58, 64, 67], "rel": 41, "low": 41, "12345": 41, "accuracy_scor": [41, 42, 44, 45, 47, 48, 51, 53], "26048": [41, 42, 44, 45, 47, 48, 51, 53], "6513": [41, 42, 44, 45, 47, 48, 51, 53], "8593582066635959": 41, "describ": 41, "longer": [41, 72], "But": 41, "causal": 41, "caus": 41, "unclear": 41, "1653": [41, 44, 45, 51, 52, 53], "1658": [41, 53], "ocup": 41, "confusion_matrix": [41, 53], "roc": [41, 53], "precision_recal": [41, 53], "cumulative_gain": [41, 53], "lift_curv": [41, 53], "108": [42, 44, 45, 47, 48, 51, 53], "8668816213726394": [42, 44, 45, 47, 48, 51, 53], "standardscal": 43, "diabetes_data": 43, "file_path": 43, "to_replac": 43, "No": 43, "polyuria": 43, "polydipsia": 43, "sudden": 43, "weak": 43, "polyphagia": 43, "genit": 43, "thrush": 43, "blur": 43, "itch": 43, "irrit": 43, "delai": 43, "heal": 43, "paresi": 43, "muscl": 43, "stiff": 43, "alopecia": 43, "obes": 43, "x_train_un": 43, "x_test_un": 43, "test_siz": 43, "stratifi": 43, "sc": 43, "fit_transform": 43, "train_tf_model": 43, "to_categor": [43, 60, 62, 72], "sequenti": [43, 60, 61, 62, 63, 70, 72], "softplu": 43, "schedul": 43, "exponentialdecai": 43, "initial_learning_r": 43, "decay_step": 43, "decay_r": 43, "99": [43, 49, 58, 59, 60, 61, 63, 70], "staircas": 43, "sgd": 43, "momentum": 43, "nesterov": 43, "categoricalcrossentropi": [43, 60, 62, 72], "compil": [43, 49, 60, 62, 66, 69, 72], "train_loss": 43, "train_accuraci": 43, "test_loss": 43, "test_accuraci": 43, "4f": 43, "csv": [43, 49, 55, 56, 57], "416": 43, "104": 43, "0631": 43, "9856": [43, 60], "0568": 43, "9808": 43, "necessari": [44, 45, 47, 53, 54], "labels_train": [44, 45, 47, 51], "labels_test": [44, 45, 47, 51], "1953": 44, "8647768803169436": 44, "test_x": [44, 45, 46, 51, 52, 56, 57], "1655": [45, 51], "pprint": 46, "8518347919545525": 46, "fix": 47, "instal": [49, 66, 69], "ml4ir": 49, "ltr": 49, "order": 49, "document": [49, 70], "pointwis": 49, "listwis": 49, "record": 49, "infer": 49, "validityrankingexplain": 49, "singh": 49, "khosla": 49, "anand": 49, "2020": [49, 72], "2004": 49, "13972": 49, "upgrad": 49, "nbformat": 49, "df_train": 49, "file_0": 49, "head": 49, "query_id": 49, "query_text": 49, "text_match_scor": 49, "page_views_scor": 49, "quality_scor": 49, "click": 49, "domain_id": 49, "domain_nam": 49, "name_match": 49, "query_2": 49, "mhs7a7rjb1y4bjt": 49, "473730": 49, "000000": 49, "00000": 49, "domain_2": 49, "063190": 49, "205381": 49, "30103": 49, "query_5": 49, "knjnwv": 49, "368108": 49, "030636": 49, "domain_0": 49, "370628": 49, "041261": 49, "366700": 49, "082535": 49, "333836": 49, "042572": 49, "325021": 49, "046478": 49, "featureconfig": 49, "yaml": 49, "config": 49, "activate_2020": 49, "feature_config": 49, "tfrecord": 49, "usag": 49, "charact": 49, "bilstm": 49, "vocablookup": 49, "modelconfig": 49, "model_config": 49, "read": 49, "architecture_kei": 49, "dnn": 49, "first_dens": 49, "first_dropout": 49, "second_dens": 49, "final_dens": 49, "null": 49, "data_format": 49, "data_dir": 49, "execution_mod": 49, "train_inference_evalu": 49, "loss_kei": 49, "softmax_cross_entropi": 49, "models_dir": 49, "explain_demo_2022": 49, "logs_dir": 49, "log": 49, "run_id": 49, "activate_demo": 49, "readi": [49, 53, 54], "model_dir": 49, "local_io": 49, "localio": 49, "file_io": 49, "fileio": 49, "sequenceexamplefeatureconfig": 49, "relevance_model": 49, "relevancemodel": 49, "tfrecordtypekei": 49, "logger": 49, "getlogg": 49, "get_logg": 49, "setlevel": 49, "autograph": 49, "set_verbos": 49, "tf_cpp_min_log_level": 49, "get_inst": 49, "tfrecord_typ": 49, "sequence_exampl": 49, "feature_config_dict": 49, "read_yaml": 49, "get_train_featur": 49, "saniti": 49, "model_fil": 49, "final": 49, "output_nam": 49, "relevance_scor": 49, "is_compil": 49, "retrain": 49, "kmodel": 49, "load_model": 49, "infer_fn": 49, "signatur": 49, "serving_tfrecord": 49, "tfrecord_help": 49, "get_sequence_example_proto": 49, "features_df": 49, "fillna": 49, "renam": [49, 55, 56, 57], "serving_info": 49, "context_featur": 49, "sequence_featur": 49, "context_feature_nam": 49, "proto": 49, "groupbi": 49, "ranking_scor": 49, "se": 49, "constant": 49, "serializetostr": 49, "predicted_scor": 49, "reset_index": 49, "362720": 49, "tlaud": 49, "venv": 49, "lib": [49, 66, 69, 72], "python3": [49, 66, 69, 72], "site": [49, 66, 69, 72], "ipykernel_launch": 49, "settingwithcopywarn": 49, "loc": 49, "row_index": 49, "col_index": 49, "caveat": 49, "pydata": 49, "user_guid": 49, "versu": 49, "cwd": 49, "sy": 49, "11998416": 49, "19389412": 49, "20375773": 49, "17943792": 49, "11195529": 49, "1909707": 49, "5671": 49, "query_1487": 49, "qcz4xhln": 49, "227694": 49, "5672": 49, "016954": 49, "5673": 49, "query_1490": 49, "wynff89": 49, "474600": 49, "190735": 49, "5674": 49, "620355": 49, "143310": 49, "5675": 49, "508362": 49, "5676": 49, "sample_queri": 49, "wish": 49, "trainabl": 49, "ranking_explain": 49, "21": [49, 54], "23": [49, 54], "top_featur": 49, "dict_kei": 49, "kendalltauresult": 49, "9999999999999999": 49, "pvalu": 49, "002777777777777778": 49, "kendal": 49, "grade": 49, "fig": 49, "ipython_figur": 49, "update_layout": 49, "autos": 49, "1800": 49, "load_boston": 50, "rf": [50, 54], "randomforestregressor": [50, 54], "mserror": [50, 54], "404": 50, "102": 50, "215751067843145": 50, "8446184553968985": 52, "fetch_california_h": 54, "medinc": 54, "houseag": 54, "averoom": 54, "avebedrm": 54, "aveoccup": 54, "latitud": 54, "3252": 54, "41": 54, "984127": 54, "023810": 54, "322": 54, "555556": 54, "37": 54, "88": 54, "3014": 54, "238137": 54, "971880": 54, "2401": 54, "109842": 54, "86": 54, "2574": 54, "288136": 54, "073446": 54, "496": 54, "802260": 54, "85": 54, "6431": 54, "817352": 54, "073059": 54, "558": 54, "547945": 54, "8462": 54, "281853": 54, "081081": 54, "565": 54, "181467": 54, "20635": 54, "5603": 54, "045455": 54, "133333": 54, "845": 54, "560606": 54, "48": 54, "20636": 54, "5568": 54, "114035": 54, "315789": 54, "356": 54, "122807": 54, "49": 54, "20637": 54, "7000": 54, "205543": 54, "120092": 54, "1007": 54, "325635": 54, "43": 54, "20638": 54, "8672": 54, "329513": 54, "171920": 54, "741": 54, "123209": 54, "20639": 54, "3886": 54, "254717": 54, "162264": 54, "1387": 54, "616981": 54, "longitud": 54, "122": 54, "526": 54, "585": 54, "24": 54, "521": 54, "413": 54, "422": 54, "121": 54, "09": 54, "781": 54, "771": 54, "923": 54, "847": 54, "894": 54, "20640": 54, "16512": 54, "4128": 54, "3515599004967849": 54, "255011664583401": 54, "residu": 54, "sythent": [55, 56, 57], "horizont": [55, 56, 57], "1970": [55, 56, 57], "928031": [55, 56, 57], "05": [55, 56, 57], "156620": [55, 56, 57], "390650": [55, 56, 57], "400804": [55, 56, 57], "874490": [55, 56, 57], "02": [55, 56, 57], "04": [55, 56, 57], "55": [55, 56, 57], "362724": [55, 56, 57], "657373": [55, 56, 57], "472341": [55, 56, 57], "033154": [55, 56, 57], "950466": [55, 56, 57], "9150": [55, 56, 57], "9300": [55, 56, 57], "percentil": [55, 56, 57], "90": [55, 56, 57], "anomaly_scor": [55, 56, 57], "sum": [55, 56, 57, 66, 69], "98": [55, 56, 61, 63, 70], "json": [58, 59, 64, 65, 67, 68, 71], "img_1": 58, "dog_cat": [58, 68, 71], "img_2": 58, "img_3": 58, "visul": 58, "imagenet_class_index": [58, 59, 64, 65, 67, 68, 71], "read_fil": [58, 59, 64, 65, 67, 68, 71], "class_idx": [58, 59, 64, 65, 67, 68, 71], "sent": 58, "purpos": 59, "pyplot": [60, 61, 62, 63, 72], "plt": [60, 61, 62, 63, 72], "img_row": [60, 62, 72], "img_col": [60, 62, 72], "load_data": [60, 62, 72], "backend": [60, 62, 72], "image_data_format": [60, 62, 72], "channels_first": [60, 62, 72], "input_shap": [60, 62, 72], "train_img": [60, 62, 70, 72], "conv2d": [60, 61, 62, 63, 70, 72], "maxpooling2d": [60, 62, 72], "pool_siz": [60, 62, 72], "flatten": [60, 61, 62, 63, 70, 72], "validation_data": [60, 62, 72], "469": [60, 62, 72], "5m": [60, 62, 72], "1696": 60, "9492": 60, "val_loss": [60, 62, 72], "0436": 60, "val_accuraci": [60, 62, 72], "9855": [60, 72], "0478": 60, "0352": 60, "9882": 60, "0324": 60, "9896": [60, 62], "0315": 60, "9892": [60, 62], "0223": 60, "9929": 60, "0320": 60, "9887": [60, 62], "0179": 60, "9940": 60, "0314": 60, "9901": 60, "0141": 60, "9952": 60, "0365": 60, "9888": 60, "0113": 60, "9960": 60, "9903": [60, 72], "0109": [60, 62, 72], "9965": 60, "0297": [60, 62], "9918": 60, "0083": 60, "9972": 60, "0337": 60, "0072": [60, 72], "9976": 60, "0382": 60, "9895": [60, 62], "03824701905250549": 60, "9894999861717224": 60, "__len__": [61, 63, 70], "__getitem__": [61, 63, 70], "mnistnet": [61, 63, 70], "maxpool2d": [61, 63, 70], "fc_layer": [61, 63, 70], "320": [61, 63, 70], "train_load": [61, 63, 70], "test_load": [61, 63, 70], "lr": [61, 63, 70], "zero_grad": [61, 63, 70], "backward": [61, 63, 70], "correct_pr": [61, 63, 70], "total_pr": [61, 63, 70], "_": [61, 63, 70], "correct_count": [61, 63, 70], "1f": [61, 63, 70], "97": [61, 63], "1712": 62, "9493": 62, "0509": 62, "9837": 62, "0467": 62, "9857": 62, "0364": 62, "9880": 62, "0331": 62, "0323": [62, 72], "9884": 62, "0226": 62, "9927": 62, "0345": 62, "9890": 62, "0171": 62, "9942": 62, "0371": 62, "0150": 62, "9949": [62, 72], "9906": [62, 72], "9966": 62, "0428": 62, "0101": 62, "9967": 62, "0356": 62, "0086": 62, "9969": 62, "0393": 62, "0065": [62, 72], "9977": 62, "0399": 62, "9898": 62, "03988948091864586": 62, "989799976348877": 62, "mobilenet_v2": [64, 67], "dog_cat_2": [64, 67], "mobilenetv2": [64, 67], "include_top": [64, 67], "img_to_arrai": [64, 67], "preprocess_input": [64, 67], "input_img": [64, 71], "top_indic": [64, 67], "argsort": [64, 67], "243": [64, 67], "242": [64, 67], "boxer": [64, 67], "282": [64, 67], "tabbi": [64, 67], "292": [64, 67], "tiger": [64, 67], "lavi": [66, 69], "releas": [66, 69], "soon": [66, 69], "multi_input": [66, 69], "multiinput": [66, 69], "vision_languag": [66, 69], "blipitm": [66, 69], "load_processor": [66, 69], "anaconda3": [66, 69, 72], "env": [66, 69], "conda_env_py3": [66, 69], "userwarn": [66, 69], "nvidia": [66, 69], "driver": [66, 69], "system": [66, 69], "old": [66, 69, 70], "10010": [66, 69], "updat": [66, 69, 72], "gpu": [66, 69], "url": [66, 69], "aspx": [66, 69], "altern": [66, 69], "trigger": [66, 69], "intern": [66, 69], "c10": [66, 69], "cudafunct": [66, 69], "cpp": [66, 69], "109": [66, 69], "480": [66, 69], "girl_dog": [66, 69], "girl": [66, 69], "plai": [66, 69], "her": [66, 69], "beach": [66, 69], "blip": [66, 69], "pretrained_path": [66, 69], "storag": [66, 69], "googleapi": [66, 69], "sfr": [66, 69], "model_base_retrieval_coco": [66, 69], "pth": [66, 69], "vit": [66, 69], "image_processor": [66, 69], "blip_image_ev": [66, 69], "image_s": [66, 69], "384": [66, 69], "text_processor": [66, 69], "blip_capt": [66, 69], "init_token": [66, 69], "text_encod": [66, 69], "base_model": 66, "crossattent": 66, "attention_probs_lay": 66, "inception_v3": [68, 71], "word_embed": 69, "cl": 69, "96": 70, "align_corn": 70, "sinc": 70, "2665": 70, "8901166666666667": 70, "incept": 71, "probs_top_5": 71, "topk": 71, "93592954": 71, "239": [71, 72], "bernese_mountain_dog": 71, "038448237": 71, "241": 71, "entlebuch": 71, "023756476": 71, "appenzel": 71, "0018181928": 71, "238": 71, "greater_swiss_mountain_dog": 71, "113302e": 71, "06": 71, "214": 71, "gordon_sett": 71, "batch_predict": 71, "prob": 71, "hide_color": 71, "1724": 72, "9487": 72, "0458": 72, "0466": 72, "9852": 72, "0333": 72, "9885": 72, "0298": 72, "9891": 72, "0207": 72, "9933": 72, "0286": 72, "0158": 72, "0295": 72, "9907": 72, "0125": 72, "9962": 72, "0290": 72, "9904": 72, "9963": 72, "0283": 72, "9902": 72, "0090": 72, "9970": 72, "9978": 72, "0317": 72, "9912": 72, "9974": 72, "0359": 72, "9915": 72, "03591015189886093": 72, "9915000200271606": 72, "_deep": 72, "deep_tf": 72, "set_learning_phas": 72, "deprec": 72, "instruct": 72, "pass": 72, "__call__": 72}, "objects": {"": [[1, 0, 0, "-", "omnixai"]], "omnixai": [[2, 0, 0, "-", "data"], [3, 0, 0, "-", "explainers"], [21, 0, 0, "-", "explanations"], [26, 0, 0, "-", "preprocessing"], [27, 0, 0, "-", "visualization"]], "omnixai.data": [[2, 0, 0, "-", "base"], [2, 0, 0, "-", "image"], [2, 0, 0, "-", "tabular"], [2, 0, 0, "-", "text"], [2, 0, 0, "-", "timeseries"]], "omnixai.data.base": [[2, 1, 1, "", "Data"]], "omnixai.data.base.Data": [[2, 2, 1, "", "data_type"], [2, 3, 1, "", "num_samples"], [2, 3, 1, "", "values"]], "omnixai.data.image": [[2, 1, 1, "", "Image"]], "omnixai.data.image.Image": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "image_shape"], [2, 3, 1, "", "num_samples"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pil"], [2, 2, 1, "", "values"]], "omnixai.data.tabular": [[2, 1, 1, "", "Tabular"]], "omnixai.data.tabular.Tabular": [[2, 2, 1, "", "categorical_columns"], [2, 2, 1, "", "columns"], [2, 2, 1, "", "continuous_columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 2, 1, "", "feature_columns"], [2, 3, 1, "", "get_continuous_bounds"], [2, 3, 1, "", "get_continuous_medians"], [2, 3, 1, "", "get_target_column"], [2, 3, 1, "", "iloc"], [2, 3, 1, "", "num_samples"], [2, 3, 1, "", "remove_target_column"], [2, 2, 1, "", "shape"], [2, 2, 1, "", "target_column"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "values"]], "omnixai.data.text": [[2, 1, 1, "", "Text"]], "omnixai.data.text.Text": [[2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "num_samples"], [2, 3, 1, "", "split"], [2, 3, 1, "", "to_str"], [2, 3, 1, "", "to_tokens"], [2, 2, 1, "", "values"]], "omnixai.data.timeseries": [[2, 1, 1, "", "Timeseries"]], "omnixai.data.timeseries.Timeseries": [[2, 2, 1, "", "columns"], [2, 3, 1, "", "copy"], [2, 4, 1, "", "data_type"], [2, 3, 1, "", "from_pd"], [2, 3, 1, "", "get_timestamp_info"], [2, 2, 1, "", "index"], [2, 3, 1, "", "num_samples"], [2, 3, 1, "", "reset_timestamp_index"], [2, 3, 1, "", "restore_timestamp_index"], [2, 2, 1, "", "shape"], [2, 3, 1, "", "to_numpy"], [2, 3, 1, "", "to_pd"], [2, 2, 1, "", "ts_len"], [2, 2, 1, "", "values"]], "omnixai.explainers": [[3, 0, 0, "-", "base"], [4, 0, 0, "-", "data"], [9, 0, 0, "-", "prediction"]], "omnixai.explainers.base": [[3, 1, 1, "", "AutoExplainerBase"], [3, 1, 1, "", "ExplainerABCMeta"], [3, 1, 1, "", "ExplainerBase"]], "omnixai.explainers.base.AutoExplainerBase": [[3, 3, 1, "", "explain"], [3, 3, 1, "", "explain_global"], [3, 2, 1, "", "explainer_names"], [3, 3, 1, "", "list_explainers"]], "omnixai.explainers.base.ExplainerBase": [[3, 3, 1, "", "explain"], [3, 2, 1, "", "explanation_type"]], "omnixai.explainers.data": [[4, 1, 1, "", "ChiSquare"], [4, 1, 1, "", "CorrelationAnalyzer"], [4, 1, 1, "", "DataAnalyzer"], [4, 1, 1, "", "ImbalanceAnalyzer"], [4, 1, 1, "", "MutualInformation"], [4, 0, 0, "-", "auto"], [4, 0, 0, "-", "chi_square"], [4, 0, 0, "-", "correlation"], [4, 0, 0, "-", "imbalance"], [4, 0, 0, "-", "mutual_info"]], "omnixai.explainers.data.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.DataAnalyzer": [[4, 3, 1, "", "explain"], [4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.auto": [[4, 1, 1, "", "DataAnalyzer"]], "omnixai.explainers.data.auto.DataAnalyzer": [[4, 3, 1, "", "explain"], [4, 3, 1, "", "list_explainers"]], "omnixai.explainers.data.chi_square": [[4, 1, 1, "", "ChiSquare"]], "omnixai.explainers.data.chi_square.ChiSquare": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.correlation": [[4, 1, 1, "", "CorrelationAnalyzer"]], "omnixai.explainers.data.correlation.CorrelationAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.imbalance": [[4, 1, 1, "", "ImbalanceAnalyzer"]], "omnixai.explainers.data.imbalance.ImbalanceAnalyzer": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.data.mutual_info": [[4, 1, 1, "", "MutualInformation"]], "omnixai.explainers.data.mutual_info.MutualInformation": [[4, 4, 1, "", "alias"], [4, 3, 1, "", "explain"], [4, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp": [[6, 0, 0, "-", "agnostic"], [5, 0, 0, "-", "auto"], [7, 0, 0, "-", "counterfactual"], [8, 0, 0, "-", "specific"]], "omnixai.explainers.nlp.agnostic": [[6, 0, 0, "-", "l2x"], [6, 0, 0, "-", "lime"], [6, 0, 0, "-", "shap"]], "omnixai.explainers.nlp.agnostic.l2x": [[6, 1, 1, "", "DefaultPredictionModel"], [6, 1, 1, "", "DefaultSelectionModel"], [6, 1, 1, "", "L2XText"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultPredictionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.DefaultSelectionModel": [[6, 3, 1, "", "forward"], [6, 4, 1, "", "training"]], "omnixai.explainers.nlp.agnostic.l2x.L2XText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.lime": [[6, 1, 1, "", "LimeText"]], "omnixai.explainers.nlp.agnostic.lime.LimeText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.agnostic.shap": [[6, 1, 1, "", "ShapText"]], "omnixai.explainers.nlp.agnostic.shap.ShapText": [[6, 4, 1, "", "alias"], [6, 3, 1, "", "explain"], [6, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.auto": [[5, 1, 1, "", "NLPExplainer"]], "omnixai.explainers.nlp.auto.NLPExplainer": [[5, 3, 1, "", "list_explainers"]], "omnixai.explainers.nlp.counterfactual": [[7, 0, 0, "-", "polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice": [[7, 1, 1, "", "Polyjuice"]], "omnixai.explainers.nlp.counterfactual.polyjuice.Polyjuice": [[7, 4, 1, "", "alias"], [7, 3, 1, "", "explain"], [7, 4, 1, "", "explanation_type"]], "omnixai.explainers.nlp.specific": [[8, 0, 0, "-", "ig"]], "omnixai.explainers.nlp.specific.ig": [[8, 1, 1, "", "IntegratedGradientText"]], "omnixai.explainers.nlp.specific.ig.IntegratedGradientText": [[8, 4, 1, "", "alias"], [8, 3, 1, "", "explain"], [8, 4, 1, "", "explanation_type"]], "omnixai.explainers.prediction": [[9, 1, 1, "", "PredictionAnalyzer"]], "omnixai.explainers.prediction.PredictionAnalyzer": [[9, 4, 1, "", "alias"], [9, 3, 1, "", "explain"], [9, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular": [[11, 0, 0, "-", "agnostic"], [10, 0, 0, "-", "auto"], [10, 0, 0, "-", "base"], [12, 0, 0, "-", "counterfactual"], [13, 0, 0, "-", "specific"]], "omnixai.explainers.tabular.agnostic.L2X": [[11, 0, 0, "-", "l2x"]], "omnixai.explainers.tabular.agnostic.L2X.l2x": [[11, 1, 1, "", "DefaultPredictionModel"], [11, 1, 1, "", "DefaultSelectionModel"], [11, 1, 1, "", "L2XTabular"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultPredictionModel": [[11, 3, 1, "", "forward"], [11, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.DefaultSelectionModel": [[11, 3, 1, "", "forward"], [11, 4, 1, "", "training"]], "omnixai.explainers.tabular.agnostic.L2X.l2x.L2XTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic": [[11, 0, 0, "-", "ale"], [11, 0, 0, "-", "lime"], [11, 0, 0, "-", "pdp"], [11, 0, 0, "-", "sensitivity"], [11, 0, 0, "-", "shap"]], "omnixai.explainers.tabular.agnostic.ale": [[11, 1, 1, "", "ALE"]], "omnixai.explainers.tabular.agnostic.ale.ALE": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "cmds"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.lime": [[11, 1, 1, "", "LimeTabular"]], "omnixai.explainers.tabular.agnostic.lime.LimeTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.pdp": [[11, 1, 1, "", "PartialDependenceTabular"]], "omnixai.explainers.tabular.agnostic.pdp.PartialDependenceTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.sensitivity": [[11, 1, 1, "", "SensitivityAnalysisTabular"]], "omnixai.explainers.tabular.agnostic.sensitivity.SensitivityAnalysisTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.agnostic.shap": [[11, 1, 1, "", "ShapTabular"]], "omnixai.explainers.tabular.agnostic.shap.ShapTabular": [[11, 4, 1, "", "alias"], [11, 3, 1, "", "explain"], [11, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.auto": [[10, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.auto.TabularExplainer": [[10, 3, 1, "", "list_explainers"]], "omnixai.explainers.tabular.base": [[10, 1, 1, "", "SklearnBase"], [10, 1, 1, "", "TabularExplainer"]], "omnixai.explainers.tabular.base.SklearnBase": [[10, 3, 1, "", "class_names"], [10, 3, 1, "", "fit"], [10, 3, 1, "", "predict"], [10, 3, 1, "", "predict_proba"]], "omnixai.explainers.tabular.counterfactual": [[12, 0, 0, "-", "ce"]], "omnixai.explainers.tabular.counterfactual.ce": [[12, 1, 1, "", "CounterfactualExplainer"], [12, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualExplainer": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.counterfactual.ce.CounterfactualOptimizer": [[12, 3, 1, "", "optimize"]], "omnixai.explainers.tabular.counterfactual.mace": [[12, 0, 0, "-", "mace"]], "omnixai.explainers.tabular.counterfactual.mace.mace": [[12, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.tabular.counterfactual.mace.mace.MACEExplainer": [[12, 4, 1, "", "alias"], [12, 3, 1, "", "explain"], [12, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific": [[13, 0, 0, "-", "decision_tree"], [13, 0, 0, "-", "ig"], [13, 0, 0, "-", "linear"], [13, 0, 0, "-", "shap_tree"]], "omnixai.explainers.tabular.specific.decision_tree": [[13, 1, 1, "", "TreeBase"], [13, 1, 1, "", "TreeClassifier"], [13, 1, 1, "", "TreeRegressor"]], "omnixai.explainers.tabular.specific.decision_tree.TreeBase": [[13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.decision_tree.TreeClassifier": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.decision_tree.TreeRegressor": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.ig": [[13, 1, 1, "", "IntegratedGradient"], [13, 1, 1, "", "IntegratedGradientTabular"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradient": [[13, 3, 1, "", "compute_integrated_gradients"]], "omnixai.explainers.tabular.specific.ig.IntegratedGradientTabular": [[13, 4, 1, "", "alias"], [13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"]], "omnixai.explainers.tabular.specific.linear": [[13, 1, 1, "", "LinearBase"], [13, 1, 1, "", "LinearRegression"], [13, 1, 1, "", "LogisticRegression"]], "omnixai.explainers.tabular.specific.linear.LinearBase": [[13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.tabular.specific.linear.LinearRegression": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.linear.LogisticRegression": [[13, 4, 1, "", "alias"]], "omnixai.explainers.tabular.specific.shap_tree": [[13, 1, 1, "", "ShapTreeTabular"]], "omnixai.explainers.tabular.specific.shap_tree.ShapTreeTabular": [[13, 4, 1, "", "alias"], [13, 3, 1, "", "explain"], [13, 4, 1, "", "explanation_type"], [13, 3, 1, "", "fit"]], "omnixai.explainers.timeseries": [[15, 0, 0, "-", "agnostic"], [14, 0, 0, "-", "auto"], [16, 0, 0, "-", "counterfactual"]], "omnixai.explainers.timeseries.agnostic": [[15, 0, 0, "-", "shap"]], "omnixai.explainers.timeseries.agnostic.shap": [[15, 1, 1, "", "ShapTimeseries"]], "omnixai.explainers.timeseries.agnostic.shap.ShapTimeseries": [[15, 4, 1, "", "alias"], [15, 3, 1, "", "explain"], [15, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.auto": [[14, 1, 1, "", "TimeseriesExplainer"]], "omnixai.explainers.timeseries.auto.TimeseriesExplainer": [[14, 3, 1, "", "list_explainers"]], "omnixai.explainers.timeseries.counterfactual": [[16, 0, 0, "-", "ce"], [16, 0, 0, "-", "mace"]], "omnixai.explainers.timeseries.counterfactual.ce": [[16, 1, 1, "", "CounterfactualExplainer"], [16, 1, 1, "", "CounterfactualOptimizer"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualExplainer": [[16, 4, 1, "", "alias"], [16, 3, 1, "", "explain"], [16, 4, 1, "", "explanation_type"]], "omnixai.explainers.timeseries.counterfactual.ce.CounterfactualOptimizer": [[16, 3, 1, "", "optimize"]], "omnixai.explainers.timeseries.counterfactual.mace": [[16, 1, 1, "", "MACEExplainer"]], "omnixai.explainers.timeseries.counterfactual.mace.MACEExplainer": [[16, 4, 1, "", "alias"], [16, 3, 1, "", "explain"], [16, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision": [[18, 0, 0, "-", "agnostic"], [17, 0, 0, "-", "auto"], [19, 0, 0, "-", "counterfactual"], [20, 0, 0, "-", "specific"]], "omnixai.explainers.vision.agnostic": [[18, 0, 0, "-", "l2x"], [18, 0, 0, "-", "lime"], [18, 0, 0, "-", "pdp"], [18, 0, 0, "-", "shap"]], "omnixai.explainers.vision.agnostic.l2x": [[18, 1, 1, "", "DefaultPredictionModel"], [18, 1, 1, "", "DefaultSelectionModel"], [18, 1, 1, "", "L2XImage"]], "omnixai.explainers.vision.agnostic.l2x.DefaultPredictionModel": [[18, 3, 1, "", "forward"], [18, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.DefaultSelectionModel": [[18, 3, 1, "", "forward"], [18, 3, 1, "", "postprocess"], [18, 4, 1, "", "training"]], "omnixai.explainers.vision.agnostic.l2x.L2XImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.lime": [[18, 1, 1, "", "LimeImage"]], "omnixai.explainers.vision.agnostic.lime.LimeImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.pdp": [[18, 1, 1, "", "PartialDependenceImage"]], "omnixai.explainers.vision.agnostic.pdp.PartialDependenceImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.agnostic.shap": [[18, 1, 1, "", "ShapImage"]], "omnixai.explainers.vision.agnostic.shap.ShapImage": [[18, 4, 1, "", "alias"], [18, 3, 1, "", "explain"], [18, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.auto": [[17, 1, 1, "", "VisionExplainer"]], "omnixai.explainers.vision.auto.VisionExplainer": [[17, 3, 1, "", "list_explainers"]], "omnixai.explainers.vision.counterfactual": [[19, 0, 0, "-", "ce"]], "omnixai.explainers.vision.counterfactual.ce": [[19, 1, 1, "", "CounterfactualExplainer"]], "omnixai.explainers.vision.counterfactual.ce.CounterfactualExplainer": [[19, 4, 1, "", "alias"], [19, 3, 1, "", "explain"], [19, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific": [[20, 0, 0, "-", "cem"], [20, 0, 0, "-", "ig"]], "omnixai.explainers.vision.specific.cem": [[20, 1, 1, "", "CEMOptimizer"], [20, 1, 1, "", "ContrastiveExplainer"]], "omnixai.explainers.vision.specific.cem.CEMOptimizer": [[20, 3, 1, "", "pn_optimize"], [20, 3, 1, "", "pp_optimize"]], "omnixai.explainers.vision.specific.cem.ContrastiveExplainer": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam": [[20, 0, 0, "-", "gradcam"]], "omnixai.explainers.vision.specific.gradcam.gradcam": [[20, 1, 1, "", "GradCAM"], [20, 1, 1, "", "GradCAMPlus"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAM": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.gradcam.gradcam.GradCAMPlus": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explainers.vision.specific.ig": [[20, 1, 1, "", "IntegratedGradientImage"]], "omnixai.explainers.vision.specific.ig.IntegratedGradientImage": [[20, 4, 1, "", "alias"], [20, 3, 1, "", "explain"], [20, 4, 1, "", "explanation_type"]], "omnixai.explanations": [[21, 0, 0, "-", "base"], [22, 0, 0, "-", "image"], [23, 0, 0, "-", "tabular"], [24, 0, 0, "-", "text"], [25, 0, 0, "-", "timeseries"]], "omnixai.explanations.base": [[21, 1, 1, "", "DashFigure"], [21, 1, 1, "", "ExplanationBase"], [21, 1, 1, "", "PredictedResults"]], "omnixai.explanations.base.DashFigure": [[21, 3, 1, "", "show"], [21, 3, 1, "", "to_html"], [21, 3, 1, "", "to_html_div"]], "omnixai.explanations.base.ExplanationBase": [[21, 3, 1, "", "dump"], [21, 3, 1, "", "dumps"], [21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "load"], [21, 3, 1, "", "loads"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.base.PredictedResults": [[21, 3, 1, "", "get_explanations"], [21, 3, 1, "", "ipython_plot"], [21, 3, 1, "", "plot"], [21, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image": [[22, 0, 0, "-", "contrast"], [22, 0, 0, "-", "counterfactual"], [22, 0, 0, "-", "mask"], [22, 0, 0, "-", "pixel_importance"]], "omnixai.explanations.image.contrast": [[22, 1, 1, "", "ContrastiveExplanation"]], "omnixai.explanations.image.contrast.ContrastiveExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.counterfactual": [[22, 1, 1, "", "CFExplanation"]], "omnixai.explanations.image.counterfactual.CFExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.mask": [[22, 1, 1, "", "MaskExplanation"]], "omnixai.explanations.image.mask.MaskExplanation": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.image.pixel_importance": [[22, 1, 1, "", "PixelImportance"]], "omnixai.explanations.image.pixel_importance.PixelImportance": [[22, 3, 1, "", "add"], [22, 3, 1, "", "get_explanations"], [22, 3, 1, "", "ipython_plot"], [22, 3, 1, "", "plot"], [22, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular": [[23, 0, 0, "-", "correlation"], [23, 0, 0, "-", "counterfactual"], [23, 0, 0, "-", "feature_importance"], [23, 0, 0, "-", "imbalance"], [23, 0, 0, "-", "linear"], [23, 0, 0, "-", "pdp"], [23, 0, 0, "-", "sensitivity"], [23, 0, 0, "-", "tree"]], "omnixai.explanations.tabular.correlation": [[23, 1, 1, "", "CorrelationExplanation"]], "omnixai.explanations.tabular.correlation.CorrelationExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.counterfactual": [[23, 1, 1, "", "CFExplanation"]], "omnixai.explanations.tabular.counterfactual.CFExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance": [[23, 1, 1, "", "FeatureImportance"], [23, 1, 1, "", "GlobalFeatureImportance"]], "omnixai.explanations.tabular.feature_importance.FeatureImportance": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.feature_importance.GlobalFeatureImportance": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.imbalance": [[23, 1, 1, "", "ImbalanceExplanation"]], "omnixai.explanations.tabular.imbalance.ImbalanceExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.linear": [[23, 1, 1, "", "LinearExplanation"]], "omnixai.explanations.tabular.linear.LinearExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.pdp": [[23, 1, 1, "", "PDPExplanation"]], "omnixai.explanations.tabular.pdp.PDPExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.sensitivity": [[23, 1, 1, "", "SensitivityExplanation"]], "omnixai.explanations.tabular.sensitivity.SensitivityExplanation": [[23, 3, 1, "", "add"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.tabular.tree": [[23, 1, 1, "", "TreeExplanation"]], "omnixai.explanations.tabular.tree.TreeExplanation": [[23, 3, 1, "", "add_global"], [23, 3, 1, "", "add_local"], [23, 3, 1, "", "get_explanations"], [23, 3, 1, "", "ipython_plot"], [23, 3, 1, "", "plot"], [23, 3, 1, "", "plotly_plot"]], "omnixai.explanations.text": [[24, 0, 0, "-", "word_importance"]], "omnixai.explanations.text.word_importance": [[24, 1, 1, "", "WordImportance"]], "omnixai.explanations.text.word_importance.WordImportance": [[24, 3, 1, "", "add"], [24, 3, 1, "", "get_explanations"], [24, 3, 1, "", "ipython_plot"], [24, 3, 1, "", "plot"], [24, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries": [[25, 0, 0, "-", "counterfactual"], [25, 0, 0, "-", "feature_importance"]], "omnixai.explanations.timeseries.counterfactual": [[25, 1, 1, "", "CFExplanation"]], "omnixai.explanations.timeseries.counterfactual.CFExplanation": [[25, 3, 1, "", "add"], [25, 3, 1, "", "get_explanations"], [25, 3, 1, "", "ipython_plot"], [25, 3, 1, "", "plot"], [25, 3, 1, "", "plotly_plot"]], "omnixai.explanations.timeseries.feature_importance": [[25, 1, 1, "", "FeatureImportance"]], "omnixai.explanations.timeseries.feature_importance.FeatureImportance": [[25, 3, 1, "", "add"], [25, 3, 1, "", "get_explanations"], [25, 3, 1, "", "ipython_plot"], [25, 3, 1, "", "plot"], [25, 3, 1, "", "plotly_plot"]], "omnixai.preprocessing": [[26, 0, 0, "-", "base"], [26, 0, 0, "-", "encode"], [26, 0, 0, "-", "fill"], [26, 0, 0, "-", "image"], [26, 0, 0, "-", "normalize"], [26, 0, 0, "-", "pipeline"], [26, 0, 0, "-", "tabular"], [26, 0, 0, "-", "text"]], "omnixai.preprocessing.base": [[26, 1, 1, "", "Identity"], [26, 1, 1, "", "TransformBase"]], "omnixai.preprocessing.base.Identity": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.base.TransformBase": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode": [[26, 1, 1, "", "KBins"], [26, 1, 1, "", "LabelEncoder"], [26, 1, 1, "", "OneHot"], [26, 1, 1, "", "Ordinal"]], "omnixai.preprocessing.encode.KBins": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.LabelEncoder": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.OneHot": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.encode.Ordinal": [[26, 2, 1, "", "categories"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.fill": [[26, 1, 1, "", "FillNaN"], [26, 1, 1, "", "FillNaNTabular"]], "omnixai.preprocessing.fill.FillNaN": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.fill.FillNaNTabular": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image": [[26, 1, 1, "", "Normalize"], [26, 1, 1, "", "Resize"], [26, 1, 1, "", "Round2Int"], [26, 1, 1, "", "Scale"]], "omnixai.preprocessing.image.Normalize": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Resize": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Round2Int": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.image.Scale": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize": [[26, 1, 1, "", "MinMax"], [26, 1, 1, "", "Scale"], [26, 1, 1, "", "Standard"]], "omnixai.preprocessing.normalize.MinMax": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Scale": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.normalize.Standard": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.pipeline": [[26, 1, 1, "", "Pipeline"]], "omnixai.preprocessing.pipeline.Pipeline": [[26, 3, 1, "", "dump"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "load"], [26, 4, 1, "", "name"], [26, 3, 1, "", "step"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.tabular": [[26, 1, 1, "", "TabularTransform"]], "omnixai.preprocessing.tabular.TabularTransform": [[26, 2, 1, "", "categories"], [26, 2, 1, "", "class_names"], [26, 3, 1, "", "decompose"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.text": [[26, 1, 1, "", "Tfidf"], [26, 1, 1, "", "Word2Id"]], "omnixai.preprocessing.text.Tfidf": [[26, 3, 1, "", "fit"], [26, 3, 1, "", "get_feature_names"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"]], "omnixai.preprocessing.text.Word2Id": [[26, 4, 1, "", "PAD"], [26, 4, 1, "", "START"], [26, 4, 1, "", "UNK"], [26, 3, 1, "", "fit"], [26, 3, 1, "", "invert"], [26, 3, 1, "", "transform"], [26, 2, 1, "", "vocab_size"]], "omnixai.sampler": [[26, 0, 0, "-", "tabular"]], "omnixai.sampler.tabular": [[26, 1, 1, "", "Sampler"]], "omnixai.sampler.tabular.Sampler": [[26, 3, 1, "", "oversample"], [26, 3, 1, "", "subsample"], [26, 3, 1, "", "undersample"]], "omnixai.visualization": [[27, 0, 0, "-", "dashboard"]], "omnixai.visualization.dashboard": [[27, 1, 1, "", "Dashboard"]], "omnixai.visualization.dashboard.Dashboard": [[27, 3, 1, "", "show"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:property", "3": "py:method", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "property", "Python property"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"welcom": 0, "omnixai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 41], "": 0, "document": 0, "introduct": [0, 1], "capabl": 0, "featur": [0, 29], "comparison": 0, "competitor": 0, "instal": [0, 1], "get": [0, 1], "start": [0, 1], "how": [0, 1], "contribut": [0, 1], "content": 0, "indic": 0, "tabl": 0, "an": 1, "explan": [1, 21, 22, 23, 24, 25, 33, 34, 43, 47, 49, 56, 59, 60, 61, 62, 63], "toolbox": 1, "librari": 1, "design": 1, "more": 1, "exampl": [1, 28, 30, 31], "modul": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "differ": [1, 3], "data": [1, 2, 4, 30, 31], "type": 1, "preprocess": [1, 26, 31], "function": 1, "support": 1, "method": 1, "result": [1, 21], "dashboard": [1, 27], "visual": [1, 27, 66, 69], "packag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "base": [2, 3, 10, 21, 26], "tabular": [2, 10, 11, 12, 13, 23, 26, 28, 30, 31], "imag": [2, 22, 26, 30, 31, 58, 64, 65, 67, 68, 71], "text": [2, 24, 26, 30, 31, 33, 37, 38], "timeseri": [2, 14, 15, 16, 25, 28], "explain": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 28, 37, 44, 70], "task": [3, 66, 69], "auto": [4, 5, 10, 14, 17], "correl": [4, 23], "imbal": [4, 23], "mutual_info": 4, "chi_squar": 4, "nlp": [5, 6, 7, 8, 28], "subpackag": [5, 10, 14, 17], "agnost": [6, 11, 15, 18], "lime": [6, 11, 18, 38, 45, 71], "shap": [6, 11, 15, 18, 39, 51, 57, 72], "l2x": [6, 11, 18, 37, 44, 70], "counterfactu": [7, 12, 16, 19, 22, 23, 25, 33, 34, 43, 47, 56, 59, 60, 61], "polyjuic": 7, "specif": [8, 13, 20], "ig": [8, 13, 20], "predict": [9, 44, 45, 46, 47, 51, 52, 53, 54], "pdp": [11, 18, 23, 48], "al": [11, 42], "sensit": [11, 23, 50], "mace": [12, 16, 47], "ce": [12, 16, 19], "linear": [13, 23], "decision_tre": 13, "shap_tre": 13, "vision": [17, 18, 19, 20, 28], "gradcam": 20, "cem": 20, "three": 21, "categori": 21, "pixel_import": 22, "mask": 22, "contrast": [22, 62, 63], "feature_import": [23, 25], "tree": [23, 52], "word_import": 24, "encod": 26, "normal": 26, "fill": 26, "pipelin": 26, "sampler": 26, "tutori": 28, "code": 28, "basic": 28, "applic": 28, "dataanalyz": 29, "analysi": [29, 32, 39, 50], "object": 30, "time": [30, 55, 56, 57], "seri": [30, 55, 56, 57], "nlpexplain": [32, 40], "sentiment": [32, 39], "classif": [33, 37, 38, 53, 58, 64, 65, 67, 68, 71], "question": 34, "answer": 34, "integr": [35, 36, 67, 68, 69], "gradient": [35, 36, 67, 68, 69], "imdb": [35, 36, 40], "dataset": [35, 36, 40, 43], "tensorflow": [35, 60, 62, 64, 67], "pytorch": [36, 61, 63, 65, 68], "learn": [37, 44, 49, 70], "ml": 41, "workflow": 41, "accumul": 42, "local": 42, "effect": 42, "diabet": 43, "incom": [44, 45, 46, 47, 51, 52, 53], "logist": 46, "regress": [46, 54], "pariti": 48, "depend": 48, "plot": 48, "rank": 49, "expan": 49, "demo": 49, "kei": 49, "takeawai": 49, "per": 49, "queri": 49, "valid": 49, "morri": 50, "decis": 52, "tabularexplain": [53, 54], "hous": 54, "price": 54, "timeseriesexplain": 55, "anomali": [55, 56, 57], "detect": [55, 56, 57], "visionexplain": 58, "imagenet": 59, "mnist": [60, 61, 62, 63, 70, 72], "grad": [64, 65, 66], "cam": [64, 65, 66], "languag": [66, 69]}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 3, "sphinx": 56}})